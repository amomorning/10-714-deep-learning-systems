{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-714 Homework 4\n",
    "\n",
    "In this homework, you will leverage all of the components built in the last three homeworks to solve some modern problems with high performing network structures. We will start by adding a few new ops leveraging our new CPU/CUDA backends. Then, you will implement convolution, and a convolutional neural network to train a classifier on the CIFAR-10 image classification dataset. Then, you will implement recurrent and long-short term memory (LSTM) neural networks, and do word-level prediction language modeling on the Penn Treebank dataset.\n",
    "\n",
    "As always, we will start by copying this notebook and getting the starting code.\n",
    "Reminder: __you must save a copy in drive__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to set up the assignment\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/\n",
    "!mkdir -p 10714\n",
    "%cd /content/drive/MyDrive/10714\n",
    "!git clone https://github.com/dlsys10714/hw4.git\n",
    "%cd /content/drive/MyDrive/10714/hw4\n",
    "\n",
    "!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
    "!pip3 install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/dlsys10714/mugrade.git\n",
      "  Cloning https://github.com/dlsys10714/mugrade.git to /private/var/folders/s9/vjjb0r1d79vgm48fbtfk7g700000gn/T/pip-req-build-_09wfz9l\n",
      "  Running command git clone -q https://github.com/dlsys10714/mugrade.git /private/var/folders/s9/vjjb0r1d79vgm48fbtfk7g700000gn/T/pip-req-build-_09wfz9l\n",
      "  Resolved https://github.com/dlsys10714/mugrade.git to commit 98609ee80ee24bf278455b48aa8d06bd3f5d0430\n",
      "Building wheels for collected packages: mugrade\n",
      "  Building wheel for mugrade (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mugrade: filename=mugrade-1.2-py3-none-any.whl size=3968 sha256=6bd3f57f39d0584151a10336d32433e6fa66e3bf9949234c9d7854622ecac21c\n",
      "  Stored in directory: /private/var/folders/s9/vjjb0r1d79vgm48fbtfk7g700000gn/T/pip-ephem-wheel-cache-wrjol7xz/wheels/8b/ba/3a/621da1207eab160c01968c5e0bd1266f505b9e3f8010376d61\n",
      "Successfully built mugrade\n",
      "Installing collected packages: mugrade\n",
      "Successfully installed mugrade-1.2\n",
      "Collecting pybind11\n",
      "  Downloading pybind11-2.10.1-py3-none-any.whl (216 kB)\n",
      "\u001b[K     |████████████████████████████████| 216 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pybind11\n",
      "Successfully installed pybind11-2.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
    "!pip3 install pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/amo/opt/anaconda3/envs/torch/lib/python3.10/site-packages (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is AppleClang 14.0.0.14000029\n",
      "-- The CXX compiler identification is AppleClang 14.0.0.14000029\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found Python: /Users/amo/opt/anaconda3/bin/python3.9 (found version \"3.9.12\") found components: Development Interpreter Development.Module Development.Embed \n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- Performing Test HAS_FLTO_THIN\n",
      "-- Performing Test HAS_FLTO_THIN - Success\n",
      "-- Found pybind11: /Users/amo/opt/anaconda3/lib/python3.9/site-packages/pybind11/include (found version \"2.10.0\")\n",
      "\u001b[0mCUDA_TOOLKIT_ROOT_DIR not found or specified\u001b[0m\n",
      "-- Could NOT find CUDA (missing: CUDA_TOOLKIT_ROOT_DIR CUDA_NVCC_EXECUTABLE CUDA_INCLUDE_DIRS CUDA_CUDART_LIBRARY) \n",
      "-- Building metal backend\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4/build\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4/python/needle/backend_ndarray/ndarray_backend_cpu.cpython-39-darwin.so\u001b[0m\n",
      "ld: warning: -undefined dynamic_lookup may not work with chained fixups\n",
      "[ 50%] Built target ndarray_backend_cpu\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_metal.dir/src/metal/ndarray_backend_metal.cc.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4/python/needle/backend_ndarray/ndarray_backend_metal.cpython-39-darwin.so\u001b[0m\n",
      "ld: warning: -undefined dynamic_lookup may not work with chained fixups\n",
      "metal: \u001b[0;1;31merror: \u001b[0mno such file or directory: 'src/metal/kernels.metal'\u001b[0m\n",
      "metal: \u001b[0;1;31merror: \u001b[0mno input files\u001b[0m\n",
      "make[3]: *** [/Users/amo/Desktop/learn/10-714-dlsys-2022/hw4/python/needle/backend_ndarray/ndarray_backend_metal.cpython-39-darwin.so] Error 1\n",
      "make[3]: *** Deleting file `/Users/amo/Desktop/learn/10-714-dlsys-2022/hw4/python/needle/backend_ndarray/ndarray_backend_metal.cpython-39-darwin.so'\n",
      "make[2]: *** [CMakeFiles/ndarray_backend_metal.dir/all] Error 2\n",
      "make[1]: *** [all] Error 2\n",
      "make: *** [lib] Error 2\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x cifar-10-batches-py/\n",
      "x cifar-10-batches-py/data_batch_4\n",
      "x cifar-10-batches-py/readme.html\n",
      "x cifar-10-batches-py/test_batch\n",
      "x cifar-10-batches-py/data_batch_3\n",
      "x cifar-10-batches-py/batches.meta\n",
      "x cifar-10-batches-py/data_batch_2\n",
      "x cifar-10-batches-py/data_batch_5\n",
      "x cifar-10-batches-py/data_batch_1\n"
     ]
    }
   ],
   "source": [
    "# Download the datasets you will be using for this assignment\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "!mkdir -p './data/ptb'\n",
    "# Download Penn Treebank dataset\n",
    "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
    "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
    "    if not os.path.exists(os.path.join('./data/ptb', f)):\n",
    "        urllib.request.urlretrieve(ptb_data + f, os.path.join('./data/ptb', f))\n",
    "\n",
    "# Download CIFAR-10 dataset\n",
    "if not os.path.isdir(\"./data/cifar-10-batches-py\"):\n",
    "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"./data/cifar-10-python.tar.gz\")\n",
    "    !tar -xvzf './data/cifar-10-python.tar.gz' -C './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish setting up the assignment, go ahead and fill in all the code in `python/needle/autograd.py` using your solution code from the previous homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ND Backend [10 pts]\n",
    "\n",
    "Fill in the following classes in `python/needle/ops.py`:\n",
    "\n",
    "- `PowerScalar`\n",
    "- `EWiseDiv`\n",
    "- `DivScalar`\n",
    "- `Transpose`\n",
    "- `Reshape`\n",
    "- `BroadcastTo`\n",
    "- `Summation`\n",
    "- `MatMul`\n",
    "- `Negate`\n",
    "- `Log`\n",
    "- `Exp`\n",
    "- `ReLU`\n",
    "- `LogSumExp`\n",
    "- `Tanh` (new)\n",
    "- `Stack` (new)\n",
    "- `Split` (new)\n",
    "\n",
    "Note that for most of these, you already wrote the solutions in the previous homework and you should not need to change your previous solution, however `TanhOp`, `Stack`, and `Split` are newly added. `Stack` concatenates same-sized tensors along a new axis, and `Split` undoes this operation. The gradients of the two operations can be written in terms of each other. We do not directly test `Split`, and only test the backward pass of `Stack` (for which we assume you used `Split`).\n",
    "\n",
    "**Note:** You may want to make your Summation op support sums over multiple axes; you will likely need it for the backward pass of the BroadcastTo op if yours supports broadcasting over multiple axes at a time. However, this is more about ease of use than necessity, and we leave this decision up to you (there are no corresponding tests).\n",
    "\n",
    "**Note:** Depending on your implementations, you may want to ensure that you call `.compact()` before reshaping arrays. (If this is necessary, you will run into corresponding error messages later in the assignment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Found pybind11: /Users/amo/opt/anaconda3/lib/python3.9/site-packages/pybind11/include (found version \"2.10.0\")\n",
      "\u001b[0mCUDA_TOOLKIT_ROOT_DIR not found or specified\u001b[0m\n",
      "-- Could NOT find CUDA (missing: CUDA_TOOLKIT_ROOT_DIR CUDA_NVCC_EXECUTABLE CUDA_INCLUDE_DIRS CUDA_CUDART_LIBRARY) \n",
      "-- Building metal backend\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target ndarray_backend_cpu\u001b[0m\n",
      "[ 50%] Built target ndarray_backend_cpu\n",
      "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target ndarray_backend_metal\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_metal.dir/src/metal/ndarray_backend_metal.cc.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module python/needle/backend_ndarray/ndarray_backend_metal.cpython-39-darwin.so\u001b[0m\n",
      "ld: warning: -undefined dynamic_lookup may not work with chained fixups\n",
      "[100%] Built target ndarray_backend_metal\n"
     ]
    }
   ],
   "source": [
    "!cmake . && make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2525 deselected / 177 selected                          \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_nd_backend.py::test_ewise_fn[cpu-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m        [  0%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cpu-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m      [  1%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cpu-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m        [  1%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cpu-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m      [  2%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cuda-shape0-divide] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [  2%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cuda-shape0-subtract] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [  3%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cuda-shape1-divide] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [  3%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[cuda-shape1-subtract] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [  4%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[metal-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m      [  5%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[metal-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m    [  5%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[metal-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m      [  6%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_ewise_fn[metal-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m    [  6%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cpu-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m       [  7%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cpu-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m     [  7%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cpu-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m       [  8%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cpu-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m     [  9%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cuda-shape0-divide] \u001b[33mSKIPPED\u001b[0m\u001b[32m     [  9%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cuda-shape0-subtract] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 10%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cuda-shape1-divide] \u001b[33mSKIPPED\u001b[0m\u001b[32m     [ 10%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[cuda-shape1-subtract] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 11%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[metal-shape0-divide] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 11%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[metal-shape0-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 12%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[metal-shape1-divide] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 12%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_scalar_fn[metal-shape1-subtract] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 13%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-16-16-16] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 14%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-8-8-8] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 14%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-1-2-3] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 15%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-3-4-5] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 15%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-5-4-3] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 16%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-16-16-32] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 16%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-64-64-64] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 17%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-72-72-72] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 18%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-72-73-74] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 18%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-74-73-72] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 19%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cpu-128-128-128] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 19%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-16-16-16] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 20%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-8-8-8] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m       [ 20%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-1-2-3] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m       [ 21%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-3-4-5] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m       [ 22%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-5-4-3] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m       [ 22%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-16-16-32] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 23%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-64-64-64] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 23%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-72-72-72] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 24%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-72-73-74] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 24%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-74-73-72] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m    [ 25%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[cuda-128-128-128] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-16-16-16] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 26%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-8-8-8] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 27%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-1-2-3] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 27%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-3-4-5] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 28%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-5-4-3] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 28%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-16-16-32] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 29%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-64-64-64] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 29%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-72-72-72] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 30%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-72-73-74] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 31%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-74-73-72] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 31%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_matmul[metal-128-128-128] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 32%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 32%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 33%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m       [ 33%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m       [ 34%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[metal-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 35%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_power[metal-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                [ 35%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 36%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 36%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m         [ 37%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m         [ 37%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[metal-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 38%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_log[metal-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 38%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 39%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 40%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m         [ 40%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m         [ 41%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[metal-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 41%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_exp[metal-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 42%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 42%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 43%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m        [ 44%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m        [ 44%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[metal-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 45%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_relu[metal-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 45%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 46%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 46%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m        [ 47%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m        [ 48%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[metal-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 48%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh[metal-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 49%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[cpu-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 49%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[cpu-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 50%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[cuda-shape0] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[cuda-shape1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[metal-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 51%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_tanh_backward[metal-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 52%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cpu-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 53%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cpu-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 53%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cpu-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 54%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cuda-shape0-0-1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m   [ 54%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cuda-shape1-0-2] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m   [ 55%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[cuda-shape2-2-5] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m   [ 55%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[metal-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 56%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[metal-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 57%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack[metal-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 57%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cpu-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 58%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cpu-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 58%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cpu-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 59%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cuda-shape0-0-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 59%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cuda-shape1-0-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 60%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[cuda-shape2-2-5] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 61%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[metal-shape0-0-1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 61%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[metal-shape1-0-2] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 62%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_stack_backward[metal-shape2-2-5] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 62%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 63%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 63%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 64%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 64%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cuda-shape0-None] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cuda-shape1-0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cuda-shape2-1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[cuda-shape3-2] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[metal-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 67%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[metal-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 68%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[metal-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 68%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation[metal-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 69%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 70%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 71%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 71%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cuda-shape0-None] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cuda-shape1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cuda-shape2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[cuda-shape3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[metal-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[metal-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[metal-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_summation_backward[metal-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[cpu-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[cpu-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[cuda-shape0-shape_to0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[cuda-shape1-shape_to1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[metal-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_broadcast_to[metal-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[cpu-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 80%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[cpu-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 80%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[cuda-shape0-shape_to0] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 81%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[cuda-shape1-shape_to1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 81%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[metal-shape0-shape_to0] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 82%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_reshape[metal-shape1-shape_to1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 83%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-axes0-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 83%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-axes0-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 84%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-axes1-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 84%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-axes1-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m        [ 85%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-None-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 85%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cpu-None-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 86%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-axes0-shape0] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 87%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-axes0-shape1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 87%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-axes1-shape0] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 88%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-axes1-shape1] \u001b[33mSKIPPED\u001b[0m\u001b[32m      [ 88%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-None-shape0] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[cuda-None-shape1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[metal-axes0-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 90%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[metal-axes0-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 90%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[metal-axes1-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 91%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[metal-axes1-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 92%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[metal-None-shape0] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 92%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_transpose[metal-None-shape1] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 93%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cpu-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 93%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cpu-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 94%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cpu-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 94%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cpu-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 95%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cuda-shape0-None] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cuda-shape1-0] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cuda-shape2-1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[cuda-shape3-2] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[metal-shape0-None] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 98%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[metal-shape1-0] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 98%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[metal-shape2-1] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 99%]\u001b[0m\n",
      "tests/test_nd_backend.py::test_logsumexp[metal-shape3-2] \u001b[32mPASSED\u001b[0m\u001b[32m          [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m118 passed\u001b[0m, \u001b[33m59 skipped\u001b[0m, \u001b[33m2525 deselected\u001b[0m\u001b[32m in 3.28s\u001b[0m\u001b[32m ===============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nd_backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_nd_backend.py \n",
      "Submitting new_nd_backend...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "Grader test 15 passed\n",
      "Grader test 16 passed\n",
      "Grader test 17 passed\n",
      "Grader test 18 passed\n",
      "Grader test 19 passed\n",
      "Grader test 20 passed\n",
      "Grader test 21 passed\n",
      "Grader test 22 passed\n",
      "Grader test 23 passed\n",
      "Grader test 24 passed\n",
      "Grader test 25 passed\n",
      "Grader test 26 passed\n",
      "Grader test 27 passed\n",
      "Grader test 28 passed\n",
      "Grader test 29 passed\n",
      "Grader test 30 passed\n",
      "Grader test 31 passed\n",
      "Grader test 32 passed\n",
      "Grader test 33 passed\n",
      "Grader test 34 passed\n",
      "Grader test 35 passed\n",
      "Grader test 36 passed\n",
      "Grader test 37 passed\n",
      "Grader test 38 passed\n",
      "Grader test 39 passed\n",
      "Grader test 40 passed\n",
      "Grader test 41 passed\n",
      "Grader test 42 passed\n",
      "Grader test 43 passed\n",
      "Grader test 44 passed\n",
      "Grader test 45 passed\n",
      "Grader test 46 passed\n",
      "Grader test 47 passed\n",
      "Grader test 48 passed\n",
      "Grader test 49 passed\n",
      "Grader test 50 passed\n",
      "Grader test 51 passed\n",
      "Grader test 52 passed\n",
      "Grader test 53 passed\n",
      "Grader test 54 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 55.16s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"_rDmFVIBecE4PjPfd2IVS\" -k \"new_nd_backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CIFAR-10 dataset [10 points]\n",
    "\n",
    "Next, you will write support for the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) image classification dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50k training images and 10k test images. \n",
    "\n",
    "Start by implementing the `__init__` function in the `CIFAR10Dataset` class. You can read in the link above how to properly read the CIFAR-10 dataset files you downloaded at the beginning of the homework. Also fill in `__getitem__` and `__len__`. Note that the return shape of the data from `__getitem__` should be in order (3, 32, 32).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((2, 3, 3))\n",
    "b = np.zeros((3, 3, 3))\n",
    "c = np.concatenate([a, b], axis=0)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2685 deselected / 17 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_dataset[True] \u001b[32mPASSED\u001b[0m\u001b[32m          [  5%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_dataset[False] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 11%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 17%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 23%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 29%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 35%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 41%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 47%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 52%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[metal-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 64%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[metal-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 70%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[metal-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 76%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[metal-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_conv.py::test_train_cifar10[device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[33m         [ 94%]\u001b[0m\n",
      "tests/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[33m [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "tests/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_cpu]\n",
      "tests/test_conv.py::test_train_cifar10[needle.backend_ndarray.ndarray_backend_metal]\n",
      "  /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4/tests/test_conv.py:472: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "    assert np.linalg.norm(np.array(list(out)) - np.array([0.09375, 3.5892258])) < 1e-2\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m========== \u001b[32m12 passed\u001b[0m, \u001b[33m\u001b[1m5 skipped\u001b[0m, \u001b[33m\u001b[1m2685 deselected\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 9.54s\u001b[0m\u001b[33m ==========\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_cifar_ptb_data.py \n",
      "Submitting cifar10...\n",
      "train:  True\n",
      "Grader test 1 passed\n",
      "[0 1 2]\n",
      "<class 'numpy.ndarray'>\n",
      "[6 9 9]\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "[0 1 2 3 4]\n",
      "<class 'numpy.ndarray'>\n",
      "[6 9 9 4 1]\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "[0 1 2]\n",
      "<class 'numpy.ndarray'>\n",
      "[6 9 9]\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "[0 1 2 3 4]\n",
      "<class 'numpy.ndarray'>\n",
      "[6 9 9 4 1]\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "submit ok\n",
      "train:  False\n",
      "Grader test 10 passed\n",
      "[0 1 2]\n",
      "<class 'numpy.ndarray'>\n",
      "[3 8 8]\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "[0 1 2 3 4]\n",
      "<class 'numpy.ndarray'>\n",
      "[3 8 8 0 6]\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "[0 1 2]\n",
      "<class 'numpy.ndarray'>\n",
      "[3 8 8]\n",
      "Grader test 15 passed\n",
      "Grader test 16 passed\n",
      "[0 1 2 3 4]\n",
      "<class 'numpy.ndarray'>\n",
      "[3 8 8 0 6]\n",
      "Grader test 17 passed\n",
      "Grader test 18 passed\n",
      "submit ok\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 19.30s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"_rDmFVIBecE4PjPfd2IVS\" -k \"cifar10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 3: Convolutional neural network [40 points]\n",
    "\n",
    "Here's an outline of what you will do in this task.\n",
    "\n",
    "In `python/needle/backend_ndarray/ndarray.py`, implement:\n",
    "- `flip`\n",
    "- `pad`\n",
    "\n",
    "In `python/needle/ops.py`, implement (forward and backward):\n",
    "- `Flip`\n",
    "- `Dilate`\n",
    "- `UnDilate`\n",
    "- `Conv`\n",
    "\n",
    "In `python/needle/nn.py`, implement:\n",
    "- `Flatten`\n",
    "- `Conv`\n",
    "\n",
    "In `python/apps/models.py`, fill in the `ResNet9` class.  \n",
    "\n",
    "In `apps/simple_training.py`, fill in:\n",
    "- `epoch_general_cifar10`,\n",
    "- `train_cifar10`\n",
    "- `evaluate_cifar10`\n",
    "\n",
    "We have provided a `BatchNorm2d` implementation for you as a wrapper around your previous `BatchNorm1d` implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding ndarrays\n",
    "\n",
    "Convolution as typically implemented in deep learning libraries cuts down the size of inputs;\n",
    "e.g., a (1, 32, 32, 3) image convolved with a 3x3 filter would give a (1, 30, 30, c) output.\n",
    "A way around this is to pad the input ndarray before performing convolution, e.g., pad with zeros to get a (1, 34, 34, 3) ndarray so that the result is (1, 32, 32, 3). \n",
    "\n",
    "Padding is also required for the backward pass of convolution.\n",
    "\n",
    "You should implement `pad` in `ndarray.py` to closely reflect the behavior of `np.pad`.\n",
    "That is, `pad` should take a tuple of 2-tuples with length equal to the number of dimensions of the array,\n",
    "where each element in the 2-tuple corresponds to \"left padding\" and \"right padding\", respectively.\n",
    "\n",
    "For example, if `A` is a (10, 32, 32, 8) ndarray (think NHWC), then `A.pad( (0, 0), (2, 2), (2, 2), (0, 0) )` would be a (10, 36, 36, 8) ndarray where the \"spatial\" dimension has been padded by two zeros on all sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 36, 36, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones((10, 32, 32, 8))\n",
    "a = np.pad(a, ((0, 0), (2, 2), (2, 2), (0, 0)))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2700 deselected / 2 selected                            \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_pad_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_conv.py::test_pad_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m====================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m2700 deselected\u001b[0m\u001b[32m in 2.29s\u001b[0m\u001b[32m ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"pad_forward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping ndarrays & FlipOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility code for a demonstration below which you can probably ignore. It might be instructive to check out the `offset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads off the underlying data array in order (i.e., offset 0, offset 1, ..., offset n)\n",
    "# i.e., ignoring strides\n",
    "def raw_data(X):\n",
    "    X = np.array(X) # copy, thus compact X\n",
    "    return np.frombuffer(ctypes.string_at(X.ctypes.data, X.nbytes), dtype=X.dtype, count=X.size)\n",
    "\n",
    "# Xold and Xnew should reference the same underlying data\n",
    "def offset(Xold, Xnew):\n",
    "    assert Xold.itemsize == Xnew.itemsize\n",
    "    # compare addresses to the beginning of the arrays\n",
    "    return (Xnew.ctypes.data - Xold.ctypes.data)//Xnew.itemsize\n",
    "\n",
    "def strides(X):\n",
    "    return ', '.join([str(x//X.itemsize) for x in X.strides])\n",
    "\n",
    "def format_array(X, shape):\n",
    "    assert len(shape) == 3, \"I only made this formatting work for ndims = 3\"\n",
    "    def chunks(l, n):\n",
    "        n = max(1, n)\n",
    "        return (l[i:i+n] for i in range(0, len(l), n))\n",
    "    a = [str(x) if x >= 10 else ' ' + str(x) for x in X]\n",
    "    a = ['(' + ' '.join(y) + ')' for y in [x for x in chunks(a, shape[-1])]]\n",
    "    a = ['|' + ' '.join(y) + '|' for y in [x for x in chunks(a, shape[-2])]]\n",
    "    return '  '.join(a)\n",
    "\n",
    "def inspect_array(X, *, is_a_copy_of):\n",
    "    # compacts X, then reads it off in order\n",
    "    print('Data: %s' % format_array(raw_data(X), X.shape))\n",
    "    # compares address of X to copy_of, thus finding X's offset\n",
    "    print('Offset: %s' % offset(is_a_copy_of, X))\n",
    "    print('Strides: %s' % strides(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to implement the backwards pass of 2D convolution, we will (probably) need a function which _flips_\n",
    "axes of ndarrays. We say \"probably\" because you could probably cleverly implement your convolution forward\n",
    "function to avoid this. However, we think it is easiest to think about this if you have the ability to \"flip\" the kernel along its vertical and horizontal dimensions.\n",
    "\n",
    "We will try to build up your intuition for the \"flip\" operation below in order to help you figure out how to implement it in `ndarray.py`. To do that, we explore numpy's `np.flip` function below. One thing to note is that\n",
    "`flip` is typically implemented by using negative strides and changing the _offset_ of the underlying array.\n",
    "\n",
    "For example, flipping an array on _all_ of its axes is equivalent to reversing the array. In this case, you can imagine that we would want all the strides to be negative, and the offset to be the length of the array (to start at the end of the array and \"stride\" backwards).\n",
    "\n",
    "Since we did not explicitly support negative strides in our implementation for the last homework, we will merely call `NDArray.make` with them to make our \"flipped\" array and then immediately call `.compact()`. Other than changing unsigned ints to signed ints in a few places, we suspect your existing `compact` function should not have to change at all to accomodate negative strides. In the .cc and .cu files we distributed, we have already changed the function signatures to reflect this.\n",
    "\n",
    "Alternatively, you could simply implement `flip` in the CPU backend by copying memory, which you _may_ find more intuitive. We suggest following our mini tutorial below to keep your implementation Python-focused, since we believe it is involves approximately the same amount of effort to implement it slightly more naively in C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this array as reference for the other examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |( 1  2  3  4) ( 5  6  7  8)|  |( 9 10 11 12) (13 14 15 16)|  |(17 18 19 20) (21 22 23 24)|\n",
      "Offset: 0\n",
      "Strides: 8, 4, 1\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(1, 25).reshape(3, 2, 4)\n",
    "inspect_array(A, is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have put brackets around each axis of the array. Notice that for this array, the offset is 0 and the strides are all positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what happens when you flip the array along the last axis below. \n",
    "Note that the `inspect_array` function compacts the array after flipping it so you can see the\n",
    "\"logical\" order of the data, and the offset is calculated by comparing the address of the **non**-compacted\n",
    "flipped array with that of `is_copy_of`, i.e., the array `A` we looked at above.\n",
    "\n",
    "That is, we are looking at how numpy calculates the strides and offset for flipped arrays in order\n",
    "to copy this behavior in our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |( 4  3  2  1) ( 8  7  6  5)|  |(12 11 10  9) (16 15 14 13)|  |(20 19 18 17) (24 23 22 21)|\n",
      "Offset: 3\n",
      "Strides: 8, 4, -1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (2,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So flipping the last axis reverses the order of the elements within each 4-dimensional \"cell\", as you can see above. The stride corresponding to the axis we flipped has been negated. And the offset is 3 -- this makes sense, e.g., because we want the new \"first\" element of the array to be 4, which was at index 3 in `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |( 5  6  7  8) ( 1  2  3  4)|  |(13 14 15 16) ( 9 10 11 12)|  |(21 22 23 24) (17 18 19 20)|\n",
      "Offset: 4\n",
      "Strides: 8, -4, 1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (1,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again for the middle axis: we negate the middle stride, and the offset is 4, which seems reasonable since we now want the first element to be 5, which was at index 4 in the original array `A`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |(17 18 19 20) (21 22 23 24)|  |( 9 10 11 12) (13 14 15 16)|  |( 1  2  3  4) ( 5  6  7  8)|\n",
      "Offset: 16\n",
      "Strides: -8, 4, 1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (0,)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to infer the more general algorithm for computing the offset given the axis to flip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe what happens when we flip _all_ axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |(24 23 22 21) (20 19 18 17)|  |(16 15 14 13) (12 11 10  9)|  |( 8  7  6  5) ( 4  3  2  1)|\n",
      "Offset: 23\n",
      "Strides: -8, -4, -1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (0,1,2)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the offset is then sufficient to point to the last element of the array, and this is just the \"reverse order\" version of `A`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we flip just axes 1 and 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: |(21 22 23 24) (17 18 19 20)|  |(13 14 15 16) ( 9 10 11 12)|  |( 5  6  7  8) ( 1  2  3  4)|\n",
      "Offset: 20\n",
      "Strides: -8, -4, 1\n"
     ]
    }
   ],
   "source": [
    "inspect_array(np.flip(A, (0,1)), is_a_copy_of=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The offset is 20. Looking back on our previous offset computations, do you notice something?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "With this exploration of numpy's ndarray flipping functionality, which uses negative strides and a custom offset,\n",
    "try to implement `flip` in `ndarray.py`. You also must implement \"flip\" forward and backward functions in `ops.py`; note that these should be extremely short.\n",
    "\n",
    "**Important:** You should call NDArray.make with the new strides and offset, and then immediately `.compact()` this array. The resulting array is then copied and has positive strides. We want this (less-than-optimal) behavior because we did not account for negative strides in our previous implementation. _Aside:_ If you want, consider where/if negative strides break your implementation. `__getitem__` definitely doesn't work due to how we processed slices; is there anything else? (_Note_: this isn't graded.)\n",
    "\n",
    "Also, if you want to instead add a `flip` operator on the CPU/CUDA backends, that's also okay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Found pybind11: /Users/amo/opt/anaconda3/lib/python3.9/site-packages/pybind11/include (found version \"2.10.0\")\n",
      "\u001b[0mCUDA_TOOLKIT_ROOT_DIR not found or specified\u001b[0m\n",
      "-- Could NOT find CUDA (missing: CUDA_TOOLKIT_ROOT_DIR CUDA_NVCC_EXECUTABLE CUDA_INCLUDE_DIRS CUDA_CUDART_LIBRARY) \n",
      "-- Building metal backend\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target ndarray_backend_cpu\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module python/needle/backend_ndarray/ndarray_backend_cpu.cpython-39-darwin.so\u001b[0m\n",
      "ld: warning: -undefined dynamic_lookup may not work with chained fixups\n",
      "[ 50%] Built target ndarray_backend_cpu\n",
      "\u001b[35m\u001b[1mConsolidate compiler generated dependencies of target ndarray_backend_metal\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_metal.dir/src/metal/ndarray_backend_metal.cc.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module python/needle/backend_ndarray/ndarray_backend_metal.cpython-39-darwin.so\u001b[0m\n",
      "ld: warning: -undefined dynamic_lookup may not work with chained fixups\n",
      "[100%] Built target ndarray_backend_metal\n"
     ]
    }
   ],
   "source": [
    "!cmake . && make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2642 deselected / 60 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params0-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [  3%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params0-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params1-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [  8%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params1-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params2-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [ 13%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params2-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params3-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [ 18%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params3-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params4-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [ 23%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params4-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params5-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [ 28%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params5-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params6-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [ 33%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params6-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params7-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [ 38%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params7-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params8-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [ 43%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params8-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params9-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [ 48%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_forward[params9-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params0-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params0-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params1-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params1-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params2-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params2-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params3-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params3-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params4-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params4-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params5-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params5-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params6-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params6-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params7-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params7-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params8-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params8-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params9-device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_conv.py::test_flip_backward[params9-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m40 passed\u001b[0m, \u001b[33m20 skipped\u001b[0m, \u001b[33m2642 deselected\u001b[0m\u001b[32m in 6.81s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"flip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dilation operator puts zeros between elements of an ndarray. We will need it for computing the backward pass of convolution when the stride of the convolution is greater than 1. As an example, dilation should do the following to a 2x2 matrix when dilated by 1 on both axes:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "\\Longrightarrow\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 2 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "3 & 0 & 4 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To get some intuition for why we need dilation for the backward pass of strided convolution, consider a  `stride=2`, `padding=\"same\"`, `input_channels=output_channels=8` convolution applied to an input of size (10, 32, 32, 8). The resulting output will be of size (10, 16, 16, 8) due to the stride, and thus `out_grad` will have shape (10, 16, 16, 8). Yet, the gradient of the input needs to, of course, have shape (10, 32, 32, 8) -- so we must need to increase the size of `out_grad` in some way. Consider also that you could implement strided convolution as `Conv(x)[:, ::2, ::2, :]`, i.e., only keeping every other pixel in the spatial dimension.\n",
    "\n",
    "\n",
    "Implement `Dilate` in `ops.py`. This function takes two additional parameters (in attrs): the `dilation` amount and the `axes` to dilate. You must also implement the corresponding op `UnDilate`, whose forward pass will be used to implement the gradient of `Dilate`. (This is so we do not have to implement `GetItem` and `SetItem` ops, which can be highly inefficient to backprop through without additional optimizations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2663 deselected / 39 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_dilate_forward[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_forward[device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m        [  5%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_forward[needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params0-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params0-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params1-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params1-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params1-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params2-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params2-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params2-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params3-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params3-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params3-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params4-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params4-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params4-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params5-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params5-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params5-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params6-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params6-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params6-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params7-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params7-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params7-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params8-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params8-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params8-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params9-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params9-device1] \u001b[33mSKIPPED\u001b[0m (N...)\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params9-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params10-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params10-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params10-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params11-needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params11-device1] \u001b[33mSKIPPED\u001b[0m (...)\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_conv.py::test_dilate_backward[params11-needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m26 passed\u001b[0m, \u001b[33m13 skipped\u001b[0m, \u001b[33m2663 deselected\u001b[0m\u001b[32m in 6.06s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"dilate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit new ops (flip/dilation) to mugrade [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_conv.py \n",
      "Submitting new_ops...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 8.28s\u001b[0m\u001b[32m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"_rDmFVIBecE4PjPfd2IVS\" -k \"new_ops\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution forward\n",
    "\n",
    "Implement the forward pass of 2D multi-channel convolution in `ops.py`. You should probably refer to [this notebook](https://github.com/dlsyscourse/public_notebooks/blob/main/convolution_implementation.ipynb) from lecture, which implements 2D multi-channel convolution using im2col in numpy.\n",
    "\n",
    "**Note:** Your convolution op should accept tensors in the NHWC format, as in the example above, and weights in the format (kernel_size, kernel_size, input_channels, output_channels).\n",
    "\n",
    "However, you will need to add two additional features. Your convolution function should accept arguments for `padding` (default 0) and `stride` (default 1). For `padding`, you should simply apply your padding function to the spatial dimensions (i.e., axes 1 and 2). \n",
    "\n",
    "Implementing strided convolution should consist of a relatively small set of changes to your plain convolution implementation.\n",
    "\n",
    "We recommend implementing convolution without stride first, ensuring you pass some of the tests below, and then adding in stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2651 deselected / 51 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape0-W_shape0-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape1-W_shape1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape2-W_shape2-1-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape3-W_shape3-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape4-W_shape4-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape5-W_shape5-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape6-W_shape6-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape7-W_shape7-2-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape8-W_shape8-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape9-W_shape9-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape10-W_shape10-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape11-W_shape11-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape12-W_shape12-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape13-W_shape13-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape14-W_shape14-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape15-W_shape15-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-device1-Z_shape16-W_shape16-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[forward-needle.backend_ndarray.ndarray_backend_metal-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m34 passed\u001b[0m, \u001b[33m17 skipped\u001b[0m, \u001b[33m2651 deselected\u001b[0m\u001b[32m in 2.37s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and forward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the gradients of 2D multi-channel convolution can be technically quite challenging (especially \"rigorously\"). We will try to provide some useful hints here. Basically, we encourage you to make use of the surprising fact that _whatever makes the dimensions work out is typically right_.\n",
    "\n",
    "Ultimately, the backward pass of convolution can be done in terms of the convolution operator itself, with some clever manipulations using `flip`, `dilate`, and multiple applications of `transpose` to both the arguments and the results.\n",
    "\n",
    "In the last section, we essentially implemented convolution as a matrix product: ignoring the various restride and reshape operations, we basically have something like `X @ W`, where `X` is the input and `W` is the weight. We also have `out_grad`, which is the same shape as `X @ W`. Now, you have already implemented the backward pass of matrix multiplication in a previous assignment, and we can use this knowledge to get some insight into the backward pass of convolution. In particular, referencing your matmul backward implementation, you may notice (heuristically speaking here):\n",
    "\n",
    "`X.grad = out_grad @ W.transpose` \\\n",
    "`W.grad = X.transpose @ out_grad`\n",
    "\n",
    "Surprisingly enough, things work out if we just assume that these are also convolutions (and now assuming that `out_grad`, `W`, and `X` are tensors amenable to 2D multi-channel convolution instead of matrices):\n",
    "\n",
    "`X.grad = ≈conv(≈out_grad, ≈W)` \\\n",
    "`W.grad = ≈conv(≈X, ≈out_grad)`\n",
    "\n",
    "In which the \"≈\" indicates that you need to apply some additional operators to these terms in order to get the dimensions to work out, such as permuting/transposing axes, dilating, changing the `padding=` argument to the convolution function, or permuting/transposing axes of the resulting convolution.\n",
    "\n",
    "As we saw on the [last few slides here](https://dlsyscourse.org/slides/conv_nets.pdf) in class, the transpose of a convolution can be found by simply flipping the kernel. Since we're working in 2D instead of 1D, this means flipping the kernel both vertically and horizontally (thus why we implemented `flip`).\n",
    "\n",
    "Summarizing some hints for both `X.grad` and `W.grad`:\n",
    "\n",
    "`X.grad`\n",
    "- The convolution of `out_grad` and `W`, with some operations applied to those\n",
    "- `W` should be flipped over both the kernel dimensions\n",
    "- If the convolution is strided, increase the size of `out_grad` with a corresponding dilation\n",
    "- Do an example to analyze dimensions: note the shape you want for `X.grad`, and think about how you must permute/transpose the arguments and add padding to the convolution to achieve this shape \n",
    "    - This padding depends on both the kernel size and the `padding` argument to the convolution\n",
    "\n",
    "`W.grad`\n",
    "- The convolution of `X` and `out_grad`, with some operations applied to those\n",
    "- The gradients of `W` must be accumulated over the batches; how can you make the conv operator itself do this accumulation?\n",
    "    - Consider turning batches into channels via transpose/permute\n",
    "- Analyze dimensions: how can you modify `X` and `out_grad` so that the shape of their convolution matches the shape of `W`? You may need to transpose/permute the result.\n",
    "    - Remember to account for the `padding` argument passed to convolution\n",
    "\n",
    "General tips\n",
    "- Deal with strided convolutions last (you should be able to just drop in `dilate` when you've passed most of the tests)\n",
    "- Start with the case where `padding=0`, then consider changing `padding` arguments\n",
    "- You can \"permute\" axes with multiple calls to `transpose`\n",
    "\n",
    "It might also be useful to skip ahead to nn.Conv, pass the forward tests, and then use both the tests below and the nn.Conv backward tests to debug your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2651 deselected / 51 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_cpu-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape0-W_shape0-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape1-W_shape1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape2-W_shape2-1-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape3-W_shape3-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape4-W_shape4-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape5-W_shape5-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape6-W_shape6-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape7-W_shape7-2-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape8-W_shape8-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape9-W_shape9-2-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape10-W_shape10-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape11-W_shape11-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape12-W_shape12-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape13-W_shape13-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape14-W_shape14-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape15-W_shape15-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-device1-Z_shape16-W_shape16-1-0] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape0-W_shape0-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape1-W_shape1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape2-W_shape2-1-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape3-W_shape3-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape4-W_shape4-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape5-W_shape5-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape6-W_shape6-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape7-W_shape7-2-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape8-W_shape8-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape9-W_shape9-2-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape10-W_shape10-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape11-W_shape11-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape12-W_shape12-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape13-W_shape13-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape14-W_shape14-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape15-W_shape15-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_conv.py::test_op_conv[backward-needle.backend_ndarray.ndarray_backend_metal-Z_shape16-W_shape16-1-0] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m34 passed\u001b[0m, \u001b[33m17 skipped\u001b[0m, \u001b[33m2651 deselected\u001b[0m\u001b[32m in 2.68s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"op_conv and backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fixing init._calculate_fans for convolution\n",
    "Previously, we have implemented Kaiming uniform/normal initializations, where we essentially assigned `fan_in = input_size` and `fan_out = output_size`.\n",
    "For convolution, this becomes somewhat more detailed, in that you should multiply both of these by the \"receptive field size\", which is in this case just the product of the kernel sizes -- which in our case are always going to be the same, i.e., $k\\times k$ kernels.\n",
    "\n",
    "**You will need to edit your `kaiming_uniform`, etc. init functions to support multidimensional arrays.** In particular, you should add a new `shape` argument which is then passed to, e.g., the underlying `rand` function.\n",
    "\n",
    "You can test this below; though it is not _directly_ graded, it must match ours to pass the nn.Conv mugrade tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2699 deselected / 3 selected                            \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_conv.py::test_init_kaiming_uniform[device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m  [ 66%]\u001b[0m\n",
      "tests/test_conv.py::test_init_kaiming_uniform[needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m================ \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1 skipped\u001b[0m, \u001b[33m2699 deselected\u001b[0m\u001b[32m in 2.44s\u001b[0m\u001b[32m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"kaiming_uniform\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing nn.Conv\n",
    "\n",
    "Essentially, nn.Conv is just a wrapper of the convolution operator we previously implemented\n",
    "which adds a bias term, initializes the weight and bias, and ensures that the padding is set so that the input and output dimensions are the same (in the `stride=1` case, anyways). \n",
    "\n",
    "Importantly, nn.Conv should support NCHW format instead of NHWC format. In particular, we think this makes more sense given our current BatchNorm implementation. You can implement this by applying `transpose` twice to both the input and output.  \n",
    "\n",
    "- Ensure nn.Conv works for (N, C, H, W) tensors even though we implemented the conv op for (N, H, W, C) tensors\n",
    "- Initialize the (k, k, i, o) weight tensor using Kaiming uniform initialization with default settings\n",
    "- Initialize the (o,) bias tensor using uniform initialization on the interval $\\pm$`1.0/(in_channels * kernel_size**2)**0.5`\n",
    "- Calculate the appropriate padding to ensure input and output dimensions are the same\n",
    "- Calculate the convolution, then add the properly-broadcasted bias term if present\n",
    "\n",
    "You can now test your nn.Conv against PyTorch's nn.Conv2d with the two PyTest calls below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2687 deselected / 15 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-4-8-16-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-16-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-8-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_cpu-32-16-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[device1-4-8-16-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m     [ 40%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[device1-32-8-16-3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 46%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[device1-32-8-8-3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m     [ 53%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[device1-32-16-8-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 60%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[device1-32-16-8-3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 66%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_metal-4-8-16-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_metal-32-8-16-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_metal-32-8-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_metal-32-16-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_forward[needle.backend_ndarray.ndarray_backend_metal-32-16-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m================ \u001b[32m\u001b[1m10 passed\u001b[0m, \u001b[33m5 skipped\u001b[0m, \u001b[33m2687 deselected\u001b[0m\u001b[32m in 2.53s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nn_conv_forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2681 deselected / 21 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-4-1-1-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-16-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-8-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_cpu-14-16-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[device1-4-1-1-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m     [ 38%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[device1-14-8-16-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 42%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[device1-14-8-16-3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 47%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[device1-14-8-8-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 52%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[device1-14-8-8-3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 57%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[device1-14-16-8-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 61%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[device1-14-16-8-3-2] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 66%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_metal-4-1-1-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_metal-14-8-16-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_metal-14-8-16-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_metal-14-8-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_metal-14-8-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_metal-14-16-8-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_conv.py::test_nn_conv_backward[needle.backend_ndarray.ndarray_backend_metal-14-16-8-3-2] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m================ \u001b[32m\u001b[1m14 passed\u001b[0m, \u001b[33m7 skipped\u001b[0m, \u001b[33m2681 deselected\u001b[0m\u001b[32m in 2.27s\u001b[0m\u001b[32m ================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"nn_conv_backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit nn.Conv to mugrade [20 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_conv.py \n",
      "Submitting conv_forward...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 15.49s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"_rDmFVIBecE4PjPfd2IVS\" -k \"conv_forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_conv.py \n",
      "Submitting conv_backward...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "Grader test 15 passed\n",
      "Grader test 16 passed\n",
      "Grader test 17 passed\n",
      "Grader test 18 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 25.84s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"_rDmFVIBecE4PjPfd2IVS\" -k \"conv_backward\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementing \"ResNet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now use your convolutional layer to implement a model similar to _ResNet9_, which is known to be a reasonable model for getting good accuracy on CIFAR-10 quickly (see [here](https://github.com/davidcpage/cifar10-fast)). Our main change is that we used striding instead of pooling and divided all of the channels by 4 for the sake of performance (as our framework is not as well-optimized as industry-grade frameworks).\n",
    "\n",
    "In the figure below, before the linear layer, you should \"flatten\" the tensor. We have added a module called `Flatten` in `nn.py` that you can complete and use, or you can simply use `.reshape` in the `forward()` method of your ResNet9.\n",
    "\n",
    "Make sure that you pass the device to all modules in your model; otherwise, you will get errors about mismatched devices when trying to run with CUDA.\n",
    "\n",
    "<center><img src=\"https://github.com/dlsyscourse/hw4/blob/main/ResNet9.png?raw=true\" alt=\"ResNet9\" style=\"width: 400px;\" /></center>\n",
    "\n",
    "We have tried to make it easier to pass the tests here than for previous assignments where you have implemented models. In particular, we are just going to make sure it has the right number of parameters and similar accuracy and loss after 1 or 2 batches of CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2699 deselected / 3 selected                            \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_conv.py::test_resnet9[device1] \u001b[33mSKIPPED\u001b[0m (No GPU)\u001b[32m               [ 66%]\u001b[0m\n",
      "tests/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_metal] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m================ \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1 skipped\u001b[0m, \u001b[33m2699 deselected\u001b[0m\u001b[32m in 2.32s\u001b[0m\u001b[32m =================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"resnet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit ResNet9 to mugrade [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_conv.py \n",
      "Submitting resnet9...\n",
      "Grader test 1 passed\n",
      "[16477  5969 46459 33297 35047  9485 26261 17974 27075  1511 36237 34240\n",
      " 42192 46123 44437  1975  2573  2187 30317 17882 33130 20834 10067 13353\n",
      " 45960 15585 33303 49113  6257 12789 20562 37699 10600 15356 38235  7539\n",
      " 23288 12218 24383 11732 19547 36585 38679  8460  9345 18643  6061  8623\n",
      " 43326 23253 48019 17987  8778 42383  8373 26898 35678 17572 19813  3802\n",
      " 42805  4765 46420 33264 49481 21412 31487  8658 16488 36234  2862  2121\n",
      " 47575 43297 47184 24247 26013 20358  2728  6705  8576 15505 21082 49108\n",
      " 45117 22855 40764 14969 39304 18293 26004 13705 33764 31713 23971 34574\n",
      " 36690 17238  4378 49890 24884  8903 42925 22112 17217  5932 17118 37737\n",
      " 31836 21725 22281 49884 23898 22380   620 20149 23862 17970 33657 12964\n",
      " 22353 43681 12989 46563 21001  2755 13111 49041]\n",
      "<class 'numpy.ndarray'>\n",
      "[7 0 3 5 9 3 3 9 0 3 1 7 3 6 5 9 4 9 2 5 0 0 4 7 5 2 2 5 7 9 5 6 6 2 0 3 2\n",
      " 6 0 0 8 2 3 6 3 5 3 0 9 3 3 9 0 4 5 8 8 3 4 4 1 0 0 8 3 2 6 9 9 4 1 2 7 1\n",
      " 7 1 9 8 9 9 1 2 7 8 3 3 3 8 7 4 8 9 0 9 5 4 4 6 2 5 4 8 1 0 2 8 6 9 5 2 2\n",
      " 5 5 7 6 2 3 1 4 1 6 4 4 2 7 5 5 6]\n",
      "[29316  3708  3838  1546 11018 30992 15379 19419 18570 12660 19694 40285\n",
      " 34536  3281 10856 12240  3181 37837 40123 18338  8163 20078 13652 43357\n",
      "  1632  1064 21420  8558 25894 31734  1531 49718 18841 11178 39264  8285\n",
      " 23421  2829  1287 25242 43232 13700 33461 30752 35231 34347 34110 25331\n",
      "  3051 33028  5448 44182 45230 41069 37036  7913 36506 46830 46912 26414\n",
      "  4211 12489 16743  2016  2031 47530  2395 48051 15675  9655 25465 10467\n",
      " 42168 27094  5258 15986 27951 17000 42240  6920 22339 28707 45665 34248\n",
      " 45406 42073  6935  1591 18899 41413  7221 35612 20784 47768 43492 26764\n",
      "  1306 11859 18938 15952 14120 45162  1947 37682 47076 16695 20148 34786\n",
      " 38434 39749  2011 26110 28968 27588 44661 25116 16504 33261 17284  4516\n",
      " 14301 10147 32853 34002 49177 46164 11432 13321]\n",
      "<class 'numpy.ndarray'>\n",
      "[8 2 9 3 0 1 0 6 3 0 2 4 3 2 8 6 2 7 8 6 8 7 4 8 0 1 3 0 5 6 6 4 4 0 9 3 4\n",
      " 9 1 0 1 3 0 1 9 1 9 1 0 9 5 9 7 5 8 1 0 9 6 2 2 4 2 9 8 4 8 9 6 4 5 9 2 5\n",
      " 7 6 7 6 5 0 6 8 4 8 1 0 6 5 9 8 1 9 3 5 8 0 0 4 7 5 2 8 9 6 9 2 6 6 2 1 3\n",
      " 2 9 9 7 7 7 1 1 0 7 8 6 0 8 4 6 2]\n",
      "Grader test 2 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "tests/test_conv.py::submit_resnet9\n",
      "  /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4/./python/needle/backend_ndarray/ndarray.py:123: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "    array = NDArray(np.array(other), device=device)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m================== \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m9 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 6.94s\u001b[0m\u001b[33m ==================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"_rDmFVIBecE4PjPfd2IVS\" -k \"resnet9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your model on CIFAR-10 using the following code. Note that this is likely going to be quite slow, and also  not all that accurate due to the lack of data augmentation. You should expect it to take around 500s per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0: avg_acc=0.38828, avg_loss=array([1.7065711], dtype=float32), time cost:640.4671869277954\n",
      "train 1: avg_acc=0.49126, avg_loss=array([1.4087456], dtype=float32), time cost:637.5347111225128\n",
      "evaluate: avg_acc = 0.50486, avg_loss = array([1.3618596], dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.50486, array([1.3618596], dtype=float32))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./python')\n",
    "sys.path.append('./apps')\n",
    "import needle as ndl\n",
    "from models import ResNet9\n",
    "from simple_training import train_cifar10, evaluate_cifar10\n",
    "\n",
    "device = ndl.cpu()\n",
    "dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=True)\n",
    "dataloader = ndl.data.DataLoader(\\\n",
    "         dataset=dataset,\n",
    "         batch_size=128,\n",
    "         shuffle=True,\n",
    "      #    collate_fn=ndl.data.collate_ndarray,\n",
    "         device=device,\n",
    "         dtype=\"float32\")\n",
    "model = ResNet9(device=device, dtype=\"float32\")\n",
    "train_cifar10(model, dataloader, n_epochs=2, optimizer=ndl.optim.Adam,\n",
    "      lr=0.001, weight_decay=0.001)\n",
    "evaluate_cifar10(model, dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Recurrent neural network [10 points]\n",
    "\n",
    "**Note:** In the following sections, you may find yourself wanting to index into tensors, i.e., to use getitem or setitem. However, we have not implemented these for tensors in our library; instead, you should use `stack` and `split` operations.\n",
    "\n",
    "In `python/needle/nn.py`, implement `RNNCell`.\n",
    "\n",
    "$h^\\prime = \\text{tanh}(xW_{ih} + b_{ih} + hW_{hh} + b_{hh})$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
    "\n",
    "All weights and biases should be initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$ where $k=\\frac{1}{\\text { hidden\\_size }}$.\n",
    "\n",
    "In `python/needle/nn.py`, implement `RNN`.\n",
    "\n",
    "For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "$h_t = \\text{tanh}(x_tW_{ih} + b_{ih} + h_{(t-1)}W_{hh} + b_{hh})$\n",
    "\n",
    "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $0$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
    "\n",
    "In a multi-layer RNN, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 1742 deselected / 960 selected                          \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-tanh-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cpu-relu-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-1-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-1-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-1-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-12-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-12-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-12-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-True-12-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-1-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-1-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-1-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-12-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-12-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-12-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-True-False-12-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-1-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-1-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-1-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-12-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-12-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-12-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-True-12-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-1-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-1-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-1-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-12-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-12-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-12-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-tanh-False-False-12-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-1-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-1-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-1-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-12-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-12-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-12-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-True-12-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-1-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-1-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-1-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-12-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-12-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-12-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-True-False-12-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-1-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-1-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-1-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-12-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-12-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-12-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-True-12-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-1-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-1-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-1-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-12-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-12-1-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-12-11-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[cuda-relu-False-False-12-11-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-tanh-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-True-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-True-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-True-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-True-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-True-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-True-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-True-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-True-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-True-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-False-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-False-1-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-False-1-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-False-1-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-False-12-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-False-12-1-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-False-12-11-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn_cell[metal-relu-False-False-12-11-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-tanh-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cpu-relu-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-True-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-True-False-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-True-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-tanh-False-False-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-True-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-True-False-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-True-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[cuda-relu-False-False-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-tanh-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_rnn[metal-relu-False-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============== \u001b[32m\u001b[1m640 passed\u001b[0m, \u001b[33m320 skipped\u001b[0m, \u001b[33m1742 deselected\u001b[0m\u001b[32m in 47.78s\u001b[0m\u001b[32m ==============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"test_rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_sequence_models.py \n",
      "Submitting rnn...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 9.51s\u001b[0m\u001b[32m ========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"_rDmFVIBecE4PjPfd2IVS\" -k \"rnn\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Long short-term memory network [10 points]\n",
    "Implement - `Sigmoid`\n",
    "\n",
    "$\\sigma(x) = \\frac{1}{1 + \\text{exp}(-x)}$\n",
    "\n",
    "In `python/needle/nn.py`, implement `Sigmoid`, `LSTMCell` and `LSTM`.\n",
    "\n",
    "\\begin{align}\n",
    "i &= \\sigma(xW_{ii} + b_{ii} + hW_{hi} + b_{hi}) \\\\\n",
    "f &= \\sigma(xW_{if} + b_{if} + hW_{hf} + b_{hf}) \\\\\n",
    "g &= \\text{tanh}(xW_{ig} + b_{ig} + hW_{hg} + b_{hg}) \\\\\n",
    "o &= \\sigma(xW_{io} + b_{io} + hW_{ho} + b_{ho}) \\\\\n",
    "c^\\prime &= f * c + i * g \\\\\n",
    "h^\\prime &= o * \\text{tanh}(c^\\prime)\n",
    "\\end{align}\n",
    "\n",
    "where $\\sigma$ is the sigmoid function, and $i$, $f$, $g$, $o$ are the input, forget, cell, and output gates, respectively. \n",
    "\n",
    "All weights and biases should be initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$ where $k=\\frac{1}{\\text{hidden\\_size}}$.\n",
    "\n",
    "Now implement `LSTM` in `python/needle/nn.py`, which applies a multi-layer LSTM RNN to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "\\begin{align}\n",
    "i_t &= \\sigma(x_tW_{ii} + b_{ii} + h_{(t-1)}W_{hi} + b_{hi}) \\\\\n",
    "f_t &= \\sigma(x_tW_{if} + b_{if} + h_{(t-1)}W_{hf} + b_{hf}) \\\\\n",
    "g_t &= \\text{tanh}(x_tW_{ig} + b_{ig} + h_{(t-1)}W_{hg} + b_{hg}) \\\\\n",
    "o_t &= \\sigma(x_tW_{io} + b_{io} + h_{(t-1)}W_{ho} + b_{ho}) \\\\\n",
    "c_t &= f * c_{(t-1)} + i * g \\\\\n",
    "h_t &= o * \\text{tanh}(c_t)\n",
    "\\end{align},\n",
    "where $h_t$ is the hidden state at time $t$, $c_t$ is the cell state at time $t$, $x_t$ is the input at time $t$, $h_{(t-1)}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $i_t$, $f_t$, $g_t$, $o_t$ are the input, forget, cell, and output gates at time $t$ respectively. \n",
    "\n",
    "In a multi-layer LSTM, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2318 deselected / 384 selected                          \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  0%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  1%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  3%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  5%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  7%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [  9%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 15%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 17%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 18%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 19%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 20%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 21%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 22%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 23%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 24%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 25%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 26%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 27%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 28%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 29%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 30%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 31%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 32%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 33%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 34%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 35%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 36%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 37%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 38%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 39%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 40%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-True-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 41%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 42%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 43%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 44%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 45%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 46%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 47%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 48%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 49%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-True-False-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 50%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 51%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 52%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 53%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 54%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 55%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 56%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 57%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-True-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 58%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 59%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 60%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 61%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-1-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-1-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 62%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-1-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-1-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-1-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-1-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 63%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-1-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-1-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-1-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-11-1-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 64%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-11-1-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-11-1-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-11-1-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-11-15-1-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 65%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-11-15-1-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-11-15-2-1] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[cuda-False-False-12-11-15-2-13] \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 68%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 69%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 70%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 71%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 72%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 73%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 74%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-True-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 76%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-1-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-1-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-1-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-1-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 79%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-1-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-1-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-1-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-1-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-1-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-11-1-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-11-1-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-11-1-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-11-1-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-11-15-1-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-11-15-1-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-11-15-2-1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-True-False-12-11-15-2-13] \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 83%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 84%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 85%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 86%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 87%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 88%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 89%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 90%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 91%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 92%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 93%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 94%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 95%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 96%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 97%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-1-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-1-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-1-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-1-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 98%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-15-1-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-15-1-13] \u001b[31mFAILED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-15-2-1] \u001b[31mFAILED\u001b[0m\u001b[31m [ 99%]\u001b[0m\n",
      "tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-15-2-13] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-1-1-1-1-1] ______________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[0.579159]]], dtype=float32)\n",
      "c_         = tensor([[[-0.2588]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[5.8351725e-05]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0635]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4384ad5b0>\n",
      "model_     = LSTM(1, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0635]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.6757026]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.6757026]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4384ad5b0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.6757026]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4384ad5b0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.6757026]]),)\n",
      "        y          = needle.Tensor([[-1.6757026]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.6757026]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384ad9d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.6757026]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.19035845  0.20960225 -0.47231153 -0.14016253]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384ad9d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.2849276  -0.21998334  0.05357134  0.2532822 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.2849276  -0.21998334  0.05357134  0.2532822 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4384addc0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.2849276  -0.21998334  0.05357134  0.2532822 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4384addc0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4384ad0a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4384ad0a0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4384af0a0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4384af0a0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-1-1-1-1-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.53751177]]], dtype=float32)\n",
      "c_         = tensor([[[0.6928]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-2.11547]]], dtype=float32)\n",
      "h_         = tensor([[[0.4138]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb461efe0a0>\n",
      "model_     = LSTM(1, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0040]],\n",
      "\n",
      "        [[ 0.2270]],\n",
      "\n",
      "        [[ 0.0476]],\n",
      "\n",
      "        [[ 0.2075]],\n",
      "\n",
      "        [[ 0.3009]],\n",
      "\n",
      "        ...5]],\n",
      "\n",
      "        [[ 0.4497]],\n",
      "\n",
      "        [[ 0.3577]],\n",
      "\n",
      "        [[ 0.4433]],\n",
      "\n",
      "        [[ 0.4138]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 1.6002307 ]],\n",
      "\n",
      "       [[-0.88279897]],\n",
      "\n",
      "       [[ 1.6471438 ]],\n",
      "\n",
      "       [[-0.20943418]],\n",
      "\n",
      "       [[-0.632112...]],\n",
      "\n",
      "       [[-1.4330328 ]],\n",
      "\n",
      "       [[-0.71343356]],\n",
      "\n",
      "       [[-1.2937164 ]],\n",
      "\n",
      "       [[-1.0726469 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.6002307 ]]\n",
      "\n",
      " [[-0.88279897]]\n",
      "\n",
      " [[ 1.6471438 ]]\n",
      "\n",
      " [[-0.20943418]]\n",
      "\n",
      " [[-0.63211286]]\n",
      "\n",
      " [[-0.4361938...]]\n",
      "\n",
      " [[-0.10951173]]\n",
      "\n",
      " [[-0.42618635]]\n",
      "\n",
      " [[-1.4330328 ]]\n",
      "\n",
      " [[-0.71343356]]\n",
      "\n",
      " [[-1.2937164 ]]\n",
      "\n",
      " [[-1.0726469 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461efe0a0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 1.6002307 ]]\n",
      "\n",
      " [[-0.88279897]]\n",
      "\n",
      " [[ 1.6471438 ]]\n",
      "\n",
      " [[-0.20943418]]\n",
      "\n",
      " [[-0.63211286]]\n",
      "\n",
      " [[-0.43619382...835159 ]]\n",
      "\n",
      " [[-0.10951173]]\n",
      "\n",
      " [[-0.42618635]]\n",
      "\n",
      " [[-1.4330328 ]]\n",
      "\n",
      " [[-0.71343356]]\n",
      "\n",
      " [[-1.2937164 ]]\n",
      "\n",
      " [[-1.0726469 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461efe0a0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[1.6002307]]), needle.Tensor([[-0.88279897]]), needle.Tensor([[1.6471438]]), needle....e.Tensor([[-1.4330328]]), needle.Tensor([[-0.71343356]]), needle.Tensor([[-1.2937164]]), needle.Tensor([[-1.0726469]]))\n",
      "        y          = needle.Tensor([[1.6002307]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[1.6002307]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461efee20>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[1.6002307]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.5534321  1.4428172 -0.3276332 -1.4740962]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461efee20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.3169763  -0.8897457   0.32111728 -0.4277606 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.3169763  -0.8897457   0.32111728 -0.4277606 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4384b52b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.3169763  -0.8897457   0.32111728 -0.4277606 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4384b52b0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4384b53d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4384b53d0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4384b5520>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4384b5520>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-1-1-1-2-1] ______________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[0.34652507]],\n",
      "\n",
      "       [[0.17763314]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0086]],\n",
      "\n",
      "        [[-0.2203]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[0.8337595]],\n",
      "\n",
      "       [[0.5514119]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0059]],\n",
      "\n",
      "        [[-0.1122]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb471d5ebb0>\n",
      "model_     = LSTM(1, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.1122]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.19438581]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.19438581]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d5ebb0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.19438581]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d5ebb0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.19438581]]),)\n",
      "        y          = needle.Tensor([[-0.19438581]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.19438581]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d5e520>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.19438581]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.16652614 -0.17157072  0.0472187   0.18120135]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d5e520>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.36346006 -0.6639625   0.7376183  -0.25718772]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.36346006 -0.6639625   0.7376183  -0.25718772]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471d5e6d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.36346006 -0.6639625   0.7376183  -0.25718772]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471d5e6d0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d5e790>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d5e790>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471d5e7c0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471d5e7c0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-1-1-1-2-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[ 1.4650596]],\n",
      "\n",
      "       [[-0.4911329]]], dtype=float32)\n",
      "c_         = tensor([[[0.3312]],\n",
      "\n",
      "        [[0.6471]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[0.22649288]],\n",
      "\n",
      "       [[0.93680954]]], dtype=float32)\n",
      "h_         = tensor([[[0.0876]],\n",
      "\n",
      "        [[0.1910]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb471d4ac40>\n",
      "model_     = LSTM(1, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[0.0512]],\n",
      "\n",
      "        [[0.0939]],\n",
      "\n",
      "        [[0.1251]],\n",
      "\n",
      "        [[0.1367]],\n",
      "\n",
      "        [[0.1395]],\n",
      "\n",
      "        [[0.1....1768]],\n",
      "\n",
      "        [[0.1794]],\n",
      "\n",
      "        [[0.1812]],\n",
      "\n",
      "        [[0.1858]],\n",
      "\n",
      "        [[0.1910]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.32335782]],\n",
      "\n",
      "       [[ 0.555403  ]],\n",
      "\n",
      "       [[ 1.2638099 ]],\n",
      "\n",
      "       [[-2.3957744 ]],\n",
      "\n",
      "       [[-1.396450...]],\n",
      "\n",
      "       [[-1.3844652 ]],\n",
      "\n",
      "       [[ 0.7059018 ]],\n",
      "\n",
      "       [[ 0.27700138]],\n",
      "\n",
      "       [[ 0.5082034 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.32335782]]\n",
      "\n",
      " [[ 0.555403  ]]\n",
      "\n",
      " [[ 1.2638099 ]]\n",
      "\n",
      " [[-2.3957744 ]]\n",
      "\n",
      " [[-1.3964502 ]]\n",
      "\n",
      " [[-0.0474948...]]\n",
      "\n",
      " [[-0.5271232 ]]\n",
      "\n",
      " [[ 0.29190674]]\n",
      "\n",
      " [[-1.3844652 ]]\n",
      "\n",
      " [[ 0.7059018 ]]\n",
      "\n",
      " [[ 0.27700138]]\n",
      "\n",
      " [[ 0.5082034 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d4ac40>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.32335782]]\n",
      "\n",
      " [[ 0.555403  ]]\n",
      "\n",
      " [[ 1.2638099 ]]\n",
      "\n",
      " [[-2.3957744 ]]\n",
      "\n",
      " [[-1.3964502 ]]\n",
      "\n",
      " [[-0.04749482...989412 ]]\n",
      "\n",
      " [[-0.5271232 ]]\n",
      "\n",
      " [[ 0.29190674]]\n",
      "\n",
      " [[-1.3844652 ]]\n",
      "\n",
      " [[ 0.7059018 ]]\n",
      "\n",
      " [[ 0.27700138]]\n",
      "\n",
      " [[ 0.5082034 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d4ac40>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.32335782]]), needle.Tensor([[0.555403]]), needle.Tensor([[1.2638099]]), needle.Te...edle.Tensor([[-1.3844652]]), needle.Tensor([[0.7059018]]), needle.Tensor([[0.27700138]]), needle.Tensor([[0.5082034]]))\n",
      "        y          = needle.Tensor([[0.32335782]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.32335782]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d4adf0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[0.32335782]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.03102896  0.23873761  0.08596339 -0.2609159 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d4adf0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.76000047 -0.34590197 -0.29316497  0.7412642 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.76000047 -0.34590197 -0.29316497  0.7412642 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb481276c10>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.76000047 -0.34590197 -0.29316497  0.7412642 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb481276c10>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4812767c0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4812767c0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4812765e0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4812765e0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-1-1-15-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-1.3707252 ],\n",
      "        [ 1.2478577 ],\n",
      "        [ 0.07071956],\n",
      "        [ 1.4252213 ],\n",
      "        [ 0.19226728],\n",
      "   ...54764843],\n",
      "        [-0.40473205],\n",
      "        [-0.59927094],\n",
      "        [-0.0950083 ],\n",
      "        [ 0.2696344 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0686],\n",
      "         [-0.3722],\n",
      "         [ 0.4158],\n",
      "         [ 0.5664],\n",
      "         [ 0.5954],\n",
      "         [ 0.7520]... [ 0.6205],\n",
      "         [ 0.2664],\n",
      "         [ 0.2069],\n",
      "         [-0.0407],\n",
      "         [ 0.1385]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 1.3360966 ],\n",
      "        [ 1.0390723 ],\n",
      "        [ 0.34625205],\n",
      "        [ 0.15740094],\n",
      "        [-0.82243955],\n",
      "   ...2188939 ],\n",
      "        [-0.47995338],\n",
      "        [ 1.4396482 ],\n",
      "        [-1.4375857 ],\n",
      "        [-0.83504134]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0316],\n",
      "         [-0.1921],\n",
      "         [ 0.1343],\n",
      "         [ 0.1486],\n",
      "         [ 0.1481],\n",
      "         [ 0.1001]... [ 0.1464],\n",
      "         [ 0.0993],\n",
      "         [ 0.0808],\n",
      "         [-0.0185],\n",
      "         [ 0.0568]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb471d4ffa0>\n",
      "model_     = LSTM(1, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0316],\n",
      "         [-0.1921],\n",
      "         [ 0.1343],\n",
      "         [ 0.1486],\n",
      "         [ 0.1481],\n",
      "         [ 0.1001]... [ 0.1464],\n",
      "         [ 0.0993],\n",
      "         [ 0.0808],\n",
      "         [-0.0185],\n",
      "         [ 0.0568]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.483543  ],\n",
      "        [-2.2067502 ],\n",
      "        [-0.34384874],\n",
      "        [ 0.20071687],\n",
      "        [ 0.34050444],\n",
      "   ...47794795],\n",
      "        [-0.7421381 ],\n",
      "        [-0.88238734],\n",
      "        [-1.4232846 ],\n",
      "        [-1.0364214 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.483543  ]\n",
      "  [-2.2067502 ]\n",
      "  [-0.34384874]\n",
      "  [ 0.20071687]\n",
      "  [ 0.34050444]\n",
      "  [ 1.9862165 ]\n",
      "  [-1.4...[-0.06021696]\n",
      "  [-1.5535648 ]\n",
      "  [ 0.47794795]\n",
      "  [-0.7421381 ]\n",
      "  [-0.88238734]\n",
      "  [-1.4232846 ]\n",
      "  [-1.0364214 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d4ffa0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.483543  ]\n",
      "  [-2.2067502 ]\n",
      "  [-0.34384874]\n",
      "  [ 0.20071687]\n",
      "  [ 0.34050444]\n",
      "  [ 1.9862165 ]\n",
      "  [-1.41...38 ]\n",
      "  [-0.06021696]\n",
      "  [-1.5535648 ]\n",
      "  [ 0.47794795]\n",
      "  [-0.7421381 ]\n",
      "  [-0.88238734]\n",
      "  [-1.4232846 ]\n",
      "  [-1.0364214 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d4ffa0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.483543  ]\n",
      " [-2.2067502 ]\n",
      " [-0.34384874]\n",
      " [ 0.20071687]\n",
      " [ 0.34050444]\n",
      " [ 1.98621....3041238 ]\n",
      " [-0.06021696]\n",
      " [-1.5535648 ]\n",
      " [ 0.47794795]\n",
      " [-0.7421381 ]\n",
      " [-0.88238734]\n",
      " [-1.4232846 ]\n",
      " [-1.0364214 ]]),)\n",
      "        y          = needle.Tensor([[-1.483543  ]\n",
      " [-2.2067502 ]\n",
      " [-0.34384874]\n",
      " [ 0.20071687]\n",
      " [ 0.34050444]\n",
      " [ 1.9862165 ]\n",
      " [-1.4191685 ]\n",
      " [-1.3041238 ]\n",
      " [-0.06021696]\n",
      " [-1.5535648 ]\n",
      " [ 0.47794795]\n",
      " [-0.7421381 ]\n",
      " [-0.88238734]\n",
      " [-1.4232846 ]\n",
      " [-1.0364214 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.483543  ]\n",
      " [-2.2067502 ]\n",
      " [-0.34384874]\n",
      " [ 0.20071687]\n",
      " [ 0.34050444]\n",
      " [ 1.9862165 ]\n",
      " [-1.4191685 ...-0.06021696]\n",
      " [-1.5535648 ]\n",
      " [ 0.47794795]\n",
      " [-0.7421381 ]\n",
      " [-0.88238734]\n",
      " [-1.4232846 ]\n",
      " [-1.0364214 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d4f7f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.483543  ]\n",
      " [-2.2067502 ]\n",
      " [-0.34384874]\n",
      " [ 0.20071687]\n",
      " [ 0.34050444]\n",
      " [ 1.9862165 ]\n",
      " [-1.4191685 ]\n",
      " [-1.3041238 ]\n",
      " [-0.06021696]\n",
      " [-1.5535648 ]\n",
      " [ 0.47794795]\n",
      " [-0.7421381 ]\n",
      " [-0.88238734]\n",
      " [-1.4232846 ]\n",
      " [-1.0364214 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.37773100e-02 -4.81700934e-02 -8.94165158e-01  6.50427759e-01]\n",
      " [-2.04935614e-02 -7.16523603e-02 -1....2 -4.62135263e-02 -8.57846081e-01  6.24008775e-01]\n",
      " [-9.62499809e-03 -3.36522199e-02 -6.24674797e-01  4.54396844e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d4f7f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.14105797  0.02862608  0.8589362  -0.5039753 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.14105797  0.02862608  0.8589362  -0.5039753 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471d4f220>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.14105797  0.02862608  0.8589362  -0.5039753 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471d4f220>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d4f070>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d4f070>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471d4f280>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471d4f280>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-1-1-15-1-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 0.13900448],\n",
      "        [-1.1376783 ],\n",
      "        [ 0.10464983],\n",
      "        [ 0.9095135 ],\n",
      "        [ 0.08797343],\n",
      "   ...05047984],\n",
      "        [-0.8314941 ],\n",
      "        [-0.9208684 ],\n",
      "        [ 1.5288042 ],\n",
      "        [ 0.81024534]]], dtype=float32)\n",
      "c_         = tensor([[[0.1493],\n",
      "         [0.4068],\n",
      "         [0.3398],\n",
      "         [0.4153],\n",
      "         [0.2914],\n",
      "         [0.6262],\n",
      "    ...      [0.3288],\n",
      "         [0.2923],\n",
      "         [0.3871],\n",
      "         [0.3667],\n",
      "         [0.4084]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.6784809 ],\n",
      "        [ 0.39848065],\n",
      "        [-0.35647243],\n",
      "        [ 0.8302122 ],\n",
      "        [ 1.2503301 ],\n",
      "   ...553107  ],\n",
      "        [-0.7789196 ],\n",
      "        [-0.9449094 ],\n",
      "        [-0.05765881],\n",
      "        [-0.38625294]]], dtype=float32)\n",
      "h_         = tensor([[[0.0530],\n",
      "         [0.2177],\n",
      "         [0.1423],\n",
      "         [0.1968],\n",
      "         [0.1151],\n",
      "         [0.3519],\n",
      "    ...      [0.1476],\n",
      "         [0.1177],\n",
      "         [0.1815],\n",
      "         [0.1674],\n",
      "         [0.2165]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4611b0d30>\n",
      "model_     = LSTM(1, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[0.1639],\n",
      "         [0.1686],\n",
      "         [0.1467],\n",
      "         [0.1885],\n",
      "         [0.1612],\n",
      "         [0.1635],\n",
      "    ...      [0.1476],\n",
      "         [0.1177],\n",
      "         [0.1815],\n",
      "         [0.1674],\n",
      "         [0.2165]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-2.9230586e-01],\n",
      "        [-4.2865148e-01],\n",
      "        [ 1.9022152e-01],\n",
      "        [-1.0351212e+00],\n",
      "        [-2.13...       [ 1.3813200e+00],\n",
      "        [ 1.9144771e-01],\n",
      "        [ 4.5609969e-01],\n",
      "        [-5.6214869e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-2.9230586e-01]\n",
      "  [-4.2865148e-01]\n",
      "  [ 1.9022152e-01]\n",
      "  [-1.0351212e+00]\n",
      "  [-2.1332932e-01]\n",
      "  [-2.80...5.3054249e-01]\n",
      "  [ 7.3530287e-01]\n",
      "  [ 1.3813200e+00]\n",
      "  [ 1.9144771e-01]\n",
      "  [ 4.5609969e-01]\n",
      "  [-5.6214869e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4611b0d30>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-2.9230586e-01]\n",
      "  [-4.2865148e-01]\n",
      "  [ 1.9022152e-01]\n",
      "  [-1.0351212e+00]\n",
      "  [-2.1332932e-01]\n",
      "  [-2.809...1]\n",
      "  [ 5.3054249e-01]\n",
      "  [ 7.3530287e-01]\n",
      "  [ 1.3813200e+00]\n",
      "  [ 1.9144771e-01]\n",
      "  [ 4.5609969e-01]\n",
      "  [-5.6214869e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4611b0d30>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.29230586]\n",
      " [-0.42865148]\n",
      " [ 0.19022152]\n",
      " [-1.0351212 ]\n",
      " [-0.21332932]\n",
      " [-0.28091...0.28758967]\n",
      " [-0.45695075]\n",
      " [ 0.5305425 ]\n",
      " [ 0.73530287]\n",
      " [ 1.38132   ]\n",
      " [ 0.1914477 ]\n",
      " [ 0.4560997 ]\n",
      " [-0.5621487 ]]))\n",
      "        y          = needle.Tensor([[-0.29230586]\n",
      " [-0.42865148]\n",
      " [ 0.19022152]\n",
      " [-1.0351212 ]\n",
      " [-0.21332932]\n",
      " [-0.28091285]\n",
      " [-1.0452365 ]\n",
      " [ 1.7658826 ]\n",
      " [ 1.8692515 ]\n",
      " [-0.19721912]\n",
      " [-0.3543213 ]\n",
      " [ 0.35575294]\n",
      " [ 2.4393952 ]\n",
      " [ 0.20366816]\n",
      " [-1.231826  ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.29230586]\n",
      " [-0.42865148]\n",
      " [ 0.19022152]\n",
      " [-1.0351212 ]\n",
      " [-0.21332932]\n",
      " [-0.28091285]\n",
      " [-1.0452365 ... 1.8692515 ]\n",
      " [-0.19721912]\n",
      " [-0.3543213 ]\n",
      " [ 0.35575294]\n",
      " [ 2.4393952 ]\n",
      " [ 0.20366816]\n",
      " [-1.231826  ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4611b0bb0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.29230586]\n",
      " [-0.42865148]\n",
      " [ 0.19022152]\n",
      " [-1.0351212 ]\n",
      " [-0.21332932]\n",
      " [-0.28091285]\n",
      " [-1.0452365 ]\n",
      " [ 1.7658826 ]\n",
      " [ 1.8692515 ]\n",
      " [-0.19721912]\n",
      " [-0.3543213 ]\n",
      " [ 0.35575294]\n",
      " [ 2.4393952 ]\n",
      " [ 0.20366816]\n",
      " [-1.231826  ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.01049629  0.22812133  0.09835219  0.07484767]\n",
      " [ 0.01539227  0.33452818  0.14422841  0.10976025]\n",
      " [...6  -0.6246301 ]\n",
      " [-0.00731343 -0.1589467  -0.06852825 -0.05215115]\n",
      " [ 0.04423312  0.96134156  0.41447264  0.31542063]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4611b0bb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.07264984  0.6298256   0.87229013 -0.7691189 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.07264984  0.6298256   0.87229013 -0.7691189 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4384adcd0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.07264984  0.6298256   0.87229013 -0.7691189 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4384adcd0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4384ad910>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4384ad910>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4384ad730>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4384ad730>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-1-1-15-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 1.3143774 ],\n",
      "        [-1.3869822 ],\n",
      "        [-1.4683915 ],\n",
      "        [ 1.5517778 ],\n",
      "        [-0.12907764],\n",
      "   ...47890487],\n",
      "        [ 0.13272753],\n",
      "        [-0.35589778],\n",
      "        [ 0.23279317],\n",
      "        [ 0.27942163]]], dtype=float32)\n",
      "c_         = tensor([[[-0.1877],\n",
      "         [-0.5776],\n",
      "         [-0.0705],\n",
      "         [-0.5438],\n",
      "         [-0.0286],\n",
      "         [-0.4950]... [-0.3196],\n",
      "         [-0.3215],\n",
      "         [-0.3153],\n",
      "         [-0.2974],\n",
      "         [-0.3272]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-1.23713958e+00],\n",
      "        [ 1.47008336e+00],\n",
      "        [-1.09344125e+00],\n",
      "        [-4.80610788e-01],\n",
      "        [-...   [ 1.69701278e+00],\n",
      "        [-3.35490555e-01],\n",
      "        [-1.71005821e+00],\n",
      "        [ 7.23888576e-01]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0471],\n",
      "         [-0.3223],\n",
      "         [-0.0131],\n",
      "         [-0.2857],\n",
      "         [-0.0047],\n",
      "         [-0.2375]... [-0.1927],\n",
      "         [-0.1940],\n",
      "         [-0.1899],\n",
      "         [-0.1781],\n",
      "         [-0.1977]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb450740c40>\n",
      "model_     = LSTM(1, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.1947],\n",
      "         [-0.1639],\n",
      "         [-0.1986],\n",
      "         [-0.1679],\n",
      "         [-0.1996],\n",
      "         [-0.1732]... [-0.1927],\n",
      "         [-0.1940],\n",
      "         [-0.1899],\n",
      "         [-0.1781],\n",
      "         [-0.1977]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.68007505],\n",
      "        [-1.3288813 ],\n",
      "        [ 1.1961994 ],\n",
      "        [-1.1013582 ],\n",
      "        [ 1.3969883 ],\n",
      "   ...4903667 ],\n",
      "        [ 0.60719055],\n",
      "        [ 0.2587269 ],\n",
      "        [-0.51507175],\n",
      "        [ 1.0523154 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.68007505]\n",
      "  [-1.3288813 ]\n",
      "  [ 1.1961994 ]\n",
      "  [-1.1013582 ]\n",
      "  [ 1.3969883 ]\n",
      "  [-0.8003915 ]\n",
      "  [-1.2...[ 0.7043951 ]\n",
      "  [-0.1610807 ]\n",
      "  [ 0.4903667 ]\n",
      "  [ 0.60719055]\n",
      "  [ 0.2587269 ]\n",
      "  [-0.51507175]\n",
      "  [ 1.0523154 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450740c40>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.68007505]\n",
      "  [-1.3288813 ]\n",
      "  [ 1.1961994 ]\n",
      "  [-1.1013582 ]\n",
      "  [ 1.3969883 ]\n",
      "  [-0.8003915 ]\n",
      "  [-1.26...944]\n",
      "  [ 0.7043951 ]\n",
      "  [-0.1610807 ]\n",
      "  [ 0.4903667 ]\n",
      "  [ 0.60719055]\n",
      "  [ 0.2587269 ]\n",
      "  [-0.51507175]\n",
      "  [ 1.0523154 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450740c40>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.68007505]\n",
      " [-1.3288813 ]\n",
      " [ 1.1961994 ]\n",
      " [-1.1013582 ]\n",
      " [ 1.3969883 ]\n",
      " [-0.80039....34671944]\n",
      " [ 0.7043951 ]\n",
      " [-0.1610807 ]\n",
      " [ 0.4903667 ]\n",
      " [ 0.60719055]\n",
      " [ 0.2587269 ]\n",
      " [-0.51507175]\n",
      " [ 1.0523154 ]]),)\n",
      "        y          = needle.Tensor([[ 0.68007505]\n",
      " [-1.3288813 ]\n",
      " [ 1.1961994 ]\n",
      " [-1.1013582 ]\n",
      " [ 1.3969883 ]\n",
      " [-0.8003915 ]\n",
      " [-1.266306  ]\n",
      " [ 0.34671944]\n",
      " [ 0.7043951 ]\n",
      " [-0.1610807 ]\n",
      " [ 0.4903667 ]\n",
      " [ 0.60719055]\n",
      " [ 0.2587269 ]\n",
      " [-0.51507175]\n",
      " [ 1.0523154 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.68007505]\n",
      " [-1.3288813 ]\n",
      " [ 1.1961994 ]\n",
      " [-1.1013582 ]\n",
      " [ 1.3969883 ]\n",
      " [-0.8003915 ]\n",
      " [-1.266306  ... 0.7043951 ]\n",
      " [-0.1610807 ]\n",
      " [ 0.4903667 ]\n",
      " [ 0.60719055]\n",
      " [ 0.2587269 ]\n",
      " [-0.51507175]\n",
      " [ 1.0523154 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450740d30>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.68007505]\n",
      " [-1.3288813 ]\n",
      " [ 1.1961994 ]\n",
      " [-1.1013582 ]\n",
      " [ 1.3969883 ]\n",
      " [-0.8003915 ]\n",
      " [-1.266306  ]\n",
      " [ 0.34671944]\n",
      " [ 0.7043951 ]\n",
      " [-0.1610807 ]\n",
      " [ 0.4903667 ]\n",
      " [ 0.60719055]\n",
      " [ 0.2587269 ]\n",
      " [-0.51507175]\n",
      " [ 1.0523154 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.28378996 -0.0449695   0.3765762  -0.52840126]\n",
      " [ 0.5545317   0.08787137 -0.73583794  1.0325074 ]\n",
      " [...17 -0.20102431]\n",
      " [ 0.21493538  0.03405877 -0.28520933  0.40019783]\n",
      " [-0.43912292 -0.06958364  0.58269584 -0.81762266]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450740d30>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.10918856 -0.04839349 -0.38730597  0.32240844]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.10918856 -0.04839349 -0.38730597  0.32240844]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450740670>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.10918856 -0.04839349 -0.38730597  0.32240844]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450740670>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450740880>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450740880>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4507409a0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4507409a0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-1-1-15-2-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-1.3362435 ],\n",
      "        [-2.2063823 ],\n",
      "        [-1.1832916 ],\n",
      "        [-1.041647  ],\n",
      "        [-0.17808057],\n",
      "   ...240119  ],\n",
      "        [ 0.28450975],\n",
      "        [ 1.0984862 ],\n",
      "        [ 1.8058966 ],\n",
      "        [-1.9751514 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.1673],\n",
      "         [-0.1284],\n",
      "         [-0.2490],\n",
      "         [-0.1254],\n",
      "         [-0.3401],\n",
      "         [-0.2482]... [-1.0157],\n",
      "         [-0.9967],\n",
      "         [-1.0197],\n",
      "         [-1.0123],\n",
      "         [-1.0309]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-1.41693771e-01],\n",
      "        [ 1.05332983e+00],\n",
      "        [ 3.35458994e+00],\n",
      "        [-6.11714959e-01],\n",
      "        [-...   [ 5.55415571e-01],\n",
      "        [ 9.99960899e-01],\n",
      "        [-1.42429158e-01],\n",
      "        [ 3.36643815e-01]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0517],\n",
      "         [-0.0388],\n",
      "         [-0.0791],\n",
      "         [-0.0379],\n",
      "         [-0.1193],\n",
      "         [-0.0840]... [-0.5130],\n",
      "         [-0.5058],\n",
      "         [-0.5162],\n",
      "         [-0.5113],\n",
      "         [-0.5186]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb462025160>\n",
      "model_     = LSTM(1, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.3183],\n",
      "         [-0.3228],\n",
      "         [-0.3260],\n",
      "         [-0.3228],\n",
      "         [-0.3170],\n",
      "         [-0.3261]... [-0.5130],\n",
      "         [-0.5058],\n",
      "         [-0.5162],\n",
      "         [-0.5113],\n",
      "         [-0.5186]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.5597048 ],\n",
      "        [-0.3338515 ],\n",
      "        [-1.2714827 ],\n",
      "        [-0.32399356],\n",
      "        [ 0.7433915 ],\n",
      "   ...12395725],\n",
      "        [ 1.1958755 ],\n",
      "        [-1.931123  ],\n",
      "        [ 0.43082467],\n",
      "        [-1.2871314 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.5597048 ]\n",
      "  [-0.3338515 ]\n",
      "  [-1.2714827 ]\n",
      "  [-0.32399356]\n",
      "  [ 0.7433915 ]\n",
      "  [-1.3103282 ]\n",
      "  [-0.2...[-0.7069747 ]\n",
      "  [-0.903122  ]\n",
      "  [-0.12395725]\n",
      "  [ 1.1958755 ]\n",
      "  [-1.931123  ]\n",
      "  [ 0.43082467]\n",
      "  [-1.2871314 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb462025160>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.5597048 ]\n",
      "  [-0.3338515 ]\n",
      "  [-1.2714827 ]\n",
      "  [-0.32399356]\n",
      "  [ 0.7433915 ]\n",
      "  [-1.3103282 ]\n",
      "  [-0.28...9  ]\n",
      "  [-0.7069747 ]\n",
      "  [-0.903122  ]\n",
      "  [-0.12395725]\n",
      "  [ 1.1958755 ]\n",
      "  [-1.931123  ]\n",
      "  [ 0.43082467]\n",
      "  [-1.2871314 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb462025160>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.5597048 ]\n",
      " [-0.3338515 ]\n",
      " [-1.2714827 ]\n",
      " [-0.32399356]\n",
      " [ 0.7433915 ]\n",
      " [-1.31032...0.644739  ]\n",
      " [-0.7069747 ]\n",
      " [-0.903122  ]\n",
      " [-0.12395725]\n",
      " [ 1.1958755 ]\n",
      " [-1.931123  ]\n",
      " [ 0.43082467]\n",
      " [-1.2871314 ]]))\n",
      "        y          = needle.Tensor([[ 0.5597048 ]\n",
      " [-0.3338515 ]\n",
      " [-1.2714827 ]\n",
      " [-0.32399356]\n",
      " [ 0.7433915 ]\n",
      " [-1.3103282 ]\n",
      " [-0.2853685 ]\n",
      " [ 1.0339994 ]\n",
      " [-0.32103276]\n",
      " [-2.1777136 ]\n",
      " [-1.0327684 ]\n",
      " [ 0.63715744]\n",
      " [ 1.5484103 ]\n",
      " [-0.9308987 ]\n",
      " [-0.43700534]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.5597048 ]\n",
      " [-0.3338515 ]\n",
      " [-1.2714827 ]\n",
      " [-0.32399356]\n",
      " [ 0.7433915 ]\n",
      " [-1.3103282 ]\n",
      " [-0.2853685 ...-0.32103276]\n",
      " [-2.1777136 ]\n",
      " [-1.0327684 ]\n",
      " [ 0.63715744]\n",
      " [ 1.5484103 ]\n",
      " [-0.9308987 ]\n",
      " [-0.43700534]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462025490>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.5597048 ]\n",
      " [-0.3338515 ]\n",
      " [-1.2714827 ]\n",
      " [-0.32399356]\n",
      " [ 0.7433915 ]\n",
      " [-1.3103282 ]\n",
      " [-0.2853685 ]\n",
      " [ 1.0339994 ]\n",
      " [-0.32103276]\n",
      " [-2.1777136 ]\n",
      " [-1.0327684 ]\n",
      " [ 0.63715744]\n",
      " [ 1.5484103 ]\n",
      " [-0.9308987 ]\n",
      " [-0.43700534]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.04990926 -0.24901362  0.37041196 -0.05084304]\n",
      " [ 0.02976977  0.1485311  -0.22094253  0.03032674]\n",
      " [...2  -0.14065608]\n",
      " [ 0.08300889  0.41415843 -0.6160677   0.08456194]\n",
      " [ 0.03896807  0.19442442 -0.28920963  0.03969714]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462025490>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.33152115 -0.48158062  0.35995555 -0.5188767 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.33152115 -0.48158062  0.35995555 -0.5188767 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461d4abb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.33152115 -0.48158062  0.35995555 -0.5188767 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461d4abb0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461d4a760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461d4a760>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461d4ab50>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461d4ab50>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-1-11-1-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.9206971]]], dtype=float32)\n",
      "c_         = tensor([[[-0.2260]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[1.0968431]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0138]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4721e30d0>\n",
      "model_     = LSTM(11, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0138]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.6236312 , -0.04422519, -0.7587827 , -0.28098294,\n",
      "         -0.08014349,  1.1358511 , -1.8212322 , -0.632759  ,\n",
      "          0.40474984, -0.32080263,  0.9196959 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.6236312  -0.04422519 -0.7587827  -0.28098294 -0.08014349\n",
      "    1.1358511  -1.8212322  -0.632759    0.40474984 -0.32080263\n",
      "    0.9196959 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4721e30d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.6236312  -0.04422519 -0.7587827  -0.28098294 -0.08014349\n",
      "    1.1358511  -1.8212322  -0.632759    0.40474984 -0.32080263\n",
      "    0.9196959 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4721e30d0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.6236312  -0.04422519 -0.7587827  -0.28098294 -0.08014349  1.1358511\n",
      "  -1.8212322  -0.632759    0.40474984 -0.32080263  0.9196959 ]]),)\n",
      "        y          = needle.Tensor([[-1.6236312  -0.04422519 -0.7587827  -0.28098294 -0.08014349  1.1358511\n",
      "  -1.8212322  -0.632759    0.40474984 -0.32080263  0.9196959 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.6236312  -0.04422519 -0.7587827  -0.28098294 -0.08014349  1.1358511\n",
      "  -1.8212322  -0.632759    0.40474984 -0.32080263  0.9196959 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4721e3790>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.6236312  -0.04422519 -0.7587827  -0.28098294 -0.08014349  1.1358511\n",
      "  -1.8212322  -0.632759    0.40474984 -0.32080263  0.9196959 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.11723152  2.5031233   0.246265   -2.4455583 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4721e3790>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.6361567   0.87358594 -0.19667912  0.14697433]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.6361567   0.87358594 -0.19667912  0.14697433]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4721e3a00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.6361567   0.87358594 -0.19667912  0.14697433]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4721e3a00>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4721e3ee0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4721e3ee0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4721e3a30>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4721e3a30>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-1-11-1-1-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.30033585]]], dtype=float32)\n",
      "c_         = tensor([[[0.3819]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[1.0067283]]], dtype=float32)\n",
      "h_         = tensor([[[0.3204]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb461d807f0>\n",
      "model_     = LSTM(11, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.4221]],\n",
      "\n",
      "        [[-0.2542]],\n",
      "\n",
      "        [[-0.4839]],\n",
      "\n",
      "        [[ 0.4132]],\n",
      "\n",
      "        [[ 0.1368]],\n",
      "\n",
      "        ...5]],\n",
      "\n",
      "        [[ 0.6395]],\n",
      "\n",
      "        [[ 0.1724]],\n",
      "\n",
      "        [[-0.5416]],\n",
      "\n",
      "        [[ 0.3204]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 2.0781677 , -0.8113666 ,  0.3902965 , -0.58998793,\n",
      "          0.26397878, -0.11748459,  1.5724404 , -1.202666...   1.1281692 , -1.7322283 , -1.420966  ,  1.5631576 ,\n",
      "         -0.09454669,  2.100951  , -0.7627848 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 2.0781677  -0.8113666   0.3902965  -0.58998793  0.26397878\n",
      "   -0.11748459  1.5724404  -1.2026662   ....08430025 -0.06944778  1.1281692\n",
      "   -1.7322283  -1.420966    1.5631576  -0.09454669  2.100951\n",
      "   -0.7627848 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461d807f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 2.0781677  -0.8113666   0.3902965  -0.58998793  0.26397878\n",
      "   -0.11748459  1.5724404  -1.2026662   0...9046  0.08430025 -0.06944778  1.1281692\n",
      "   -1.7322283  -1.420966    1.5631576  -0.09454669  2.100951\n",
      "   -0.7627848 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461d807f0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 2.0781677  -0.8113666   0.3902965  -0.58998793  0.26397878 -0.11748459\n",
      "   1.572440...689046  0.08430025 -0.06944778  1.1281692  -1.7322283\n",
      "  -1.420966    1.5631576  -0.09454669  2.100951   -0.7627848 ]]))\n",
      "        y          = needle.Tensor([[ 2.0781677  -0.8113666   0.3902965  -0.58998793  0.26397878 -0.11748459\n",
      "   1.5724404  -1.2026662   0.7927681   0.8529676  -1.3091865 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 2.0781677  -0.8113666   0.3902965  -0.58998793  0.26397878 -0.11748459\n",
      "   1.5724404  -1.2026662   0.7927681   0.8529676  -1.3091865 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461d80e50>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 2.0781677  -0.8113666   0.3902965  -0.58998793  0.26397878 -0.11748459\n",
      "   1.5724404  -1.2026662   0.7927681   0.8529676  -1.3091865 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 2.3539767 -1.291658  -1.017976   0.9479058]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461d80e50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.875018    0.35032213 -0.65320015 -0.87134564]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.875018    0.35032213 -0.65320015 -0.87134564]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4588c7c40>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.875018    0.35032213 -0.65320015 -0.87134564]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4588c7c40>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4588c72e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4588c72e0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4588c76a0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4588c76a0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-1-11-1-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[0.02456808]],\n",
      "\n",
      "       [[1.3280851 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.5081]],\n",
      "\n",
      "        [[-0.1316]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.9354561 ]],\n",
      "\n",
      "       [[-0.83520967]]], dtype=float32)\n",
      "h_         = tensor([[[-0.1075]],\n",
      "\n",
      "        [[-0.1002]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb480eb82e0>\n",
      "model_     = LSTM(11, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.1002]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.6313985 , -0.5630485 ,  0.26587877,  0.39055446,\n",
      "         -0.73208183, -0.4549412 ,  0.03380091,  0.2695871 ,\n",
      "         -0.6766418 ,  0.25395584,  1.1506048 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.6313985  -0.5630485   0.26587877  0.39055446 -0.73208183\n",
      "   -0.4549412   0.03380091  0.2695871  -0.6766418   0.25395584\n",
      "    1.1506048 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480eb82e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.6313985  -0.5630485   0.26587877  0.39055446 -0.73208183\n",
      "   -0.4549412   0.03380091  0.2695871  -0.6766418   0.25395584\n",
      "    1.1506048 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480eb82e0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.6313985  -0.5630485   0.26587877  0.39055446 -0.73208183 -0.4549412\n",
      "   0.03380091  0.2695871  -0.6766418   0.25395584  1.1506048 ]]),)\n",
      "        y          = needle.Tensor([[ 0.6313985  -0.5630485   0.26587877  0.39055446 -0.73208183 -0.4549412\n",
      "   0.03380091  0.2695871  -0.6766418   0.25395584  1.1506048 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.6313985  -0.5630485   0.26587877  0.39055446 -0.73208183 -0.4549412\n",
      "   0.03380091  0.2695871  -0.6766418   0.25395584  1.1506048 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480eb8850>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.6313985  -0.5630485   0.26587877  0.39055446 -0.73208183 -0.4549412\n",
      "   0.03380091  0.2695871  -0.6766418   0.25395584  1.1506048 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.78031814  1.5367919  -0.8065888  -1.303947  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480eb8850>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.2272135  -0.69532907 -0.29623353 -0.0300225 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.2272135  -0.69532907 -0.29623353 -0.0300225 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480eb81c0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.2272135  -0.69532907 -0.29623353 -0.0300225 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480eb81c0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb430221ca0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb430221ca0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb430221370>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb430221370>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-1-11-1-2-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-1.3481313]],\n",
      "\n",
      "       [[-2.33484  ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.8470]],\n",
      "\n",
      "        [[ 0.3904]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[1.7432896]],\n",
      "\n",
      "       [[0.845863 ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.3216]],\n",
      "\n",
      "        [[ 0.1925]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb458a7f2b0>\n",
      "model_     = LSTM(11, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[0.0589]],\n",
      "\n",
      "        [[0.0467]],\n",
      "\n",
      "        [[0.1121]],\n",
      "\n",
      "        [[0.1719]],\n",
      "\n",
      "        [[0.1916]],\n",
      "\n",
      "        [[0.1....1511]],\n",
      "\n",
      "        [[0.1221]],\n",
      "\n",
      "        [[0.0542]],\n",
      "\n",
      "        [[0.1334]],\n",
      "\n",
      "        [[0.1925]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 1.6656092e+00, -1.3631028e-01,  3.0155131e-01, -4.4901845e-01,\n",
      "         -5.3456479e-01, -2.0191545e+00,  2.0...3420042e-01,  8.8468052e-02, -3.6828390e-01,\n",
      "         -1.0911382e+00, -3.6824065e-01, -1.2225406e+00]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.6656092e+00 -1.3631028e-01  3.0155131e-01 -4.4901845e-01\n",
      "   -5.3456479e-01 -2.0191545e+00  2.0850...  4.9480733e-01 -1.3420042e-01  8.8468052e-02 -3.6828390e-01\n",
      "   -1.0911382e+00 -3.6824065e-01 -1.2225406e+00]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458a7f2b0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 1.6656092e+00 -1.3631028e-01  3.0155131e-01 -4.4901845e-01\n",
      "   -5.3456479e-01 -2.0191545e+00  2.08509...e-01\n",
      "    4.9480733e-01 -1.3420042e-01  8.8468052e-02 -3.6828390e-01\n",
      "   -1.0911382e+00 -3.6824065e-01 -1.2225406e+00]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458a7f2b0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.6656092  -0.13631028  0.3015513  -0.44901845 -0.5345648  -2.0191545\n",
      "   0.2085099...91101 -0.22938207 -0.20180391  0.49480733 -0.13420042\n",
      "   0.08846805 -0.3682839  -1.0911382  -0.36824065 -1.2225406 ]]))\n",
      "        y          = needle.Tensor([[ 1.6656092  -0.13631028  0.3015513  -0.44901845 -0.5345648  -2.0191545\n",
      "   0.2085099   0.7928143   1.276457   -0.49576175  1.2341311 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.6656092  -0.13631028  0.3015513  -0.44901845 -0.5345648  -2.0191545\n",
      "   0.2085099   0.7928143   1.276457   -0.49576175  1.2341311 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458a7f730>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 1.6656092  -0.13631028  0.3015513  -0.44901845 -0.5345648  -2.0191545\n",
      "   0.2085099   0.7928143   1.276457   -0.49576175  1.2341311 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[0.17993611 1.359242   3.6524768  1.291507  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458a7f730>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.7356485  -0.8344302   0.10473835 -0.08730137]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.7356485  -0.8344302   0.10473835 -0.08730137]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471770610>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.7356485  -0.8344302   0.10473835 -0.08730137]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471770610>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4717708b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4717708b0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4717704f0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4717704f0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-1-11-15-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-0.10054879],\n",
      "        [ 0.2918725 ],\n",
      "        [ 1.6507258 ],\n",
      "        [ 0.08840126],\n",
      "        [ 0.18274552],\n",
      "   ...00326893],\n",
      "        [ 0.5893151 ],\n",
      "        [-0.90116906],\n",
      "        [-1.3239888 ],\n",
      "        [ 1.7221136 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0037],\n",
      "         [ 0.2095],\n",
      "         [ 0.5263],\n",
      "         [-0.4643],\n",
      "         [-0.1763],\n",
      "         [-0.5817]... [-0.2020],\n",
      "         [-0.5375],\n",
      "         [ 0.1084],\n",
      "         [-0.1971],\n",
      "         [-0.0440]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.5904229 ],\n",
      "        [-0.5809773 ],\n",
      "        [-1.0493408 ],\n",
      "        [ 0.1878587 ],\n",
      "        [-1.5846231 ],\n",
      "   ...384782  ],\n",
      "        [-2.5333977 ],\n",
      "        [ 1.7065932 ],\n",
      "        [-0.05527167],\n",
      "        [ 0.2389233 ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0011],\n",
      "         [ 0.0598],\n",
      "         [ 0.3818],\n",
      "         [-0.1625],\n",
      "         [-0.1463],\n",
      "         [-0.4092]... [-0.1684],\n",
      "         [-0.3093],\n",
      "         [ 0.0491],\n",
      "         [-0.0178],\n",
      "         [-0.0035]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb46123c100>\n",
      "model_     = LSTM(11, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0011],\n",
      "         [ 0.0598],\n",
      "         [ 0.3818],\n",
      "         [-0.1625],\n",
      "         [-0.1463],\n",
      "         [-0.4092]... [-0.1684],\n",
      "         [-0.3093],\n",
      "         [ 0.0491],\n",
      "         [-0.0178],\n",
      "         [-0.0035]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 2.7137520e+00,  5.7211286e-01, -4.6766111e-01,  1.1092497e+00,\n",
      "         -8.2207817e-01, -1.6646749e-01, -1.1...2384862e-01, -1.6657708e+00, -1.1364845e+00,\n",
      "         -4.0751055e-01, -9.1843480e-01,  6.2575686e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 2.7137520e+00  5.7211286e-01 -4.6766111e-01  1.1092497e+00\n",
      "   -8.2207817e-01 -1.6646749e-01 -1.1684... -2.1852746e+00  6.2384862e-01 -1.6657708e+00 -1.1364845e+00\n",
      "   -4.0751055e-01 -9.1843480e-01  6.2575686e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46123c100>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 2.7137520e+00  5.7211286e-01 -4.6766111e-01  1.1092497e+00\n",
      "   -8.2207817e-01 -1.6646749e-01 -1.16842...e+00\n",
      "   -2.1852746e+00  6.2384862e-01 -1.6657708e+00 -1.1364845e+00\n",
      "   -4.0751055e-01 -9.1843480e-01  6.2575686e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46123c100>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 2.7137520e+00  5.7211286e-01 -4.6766111e-01  1.1092497e+00\n",
      "  -8.2207817e-01 -1.664...1e+00\n",
      "  -2.1852746e+00  6.2384862e-01 -1.6657708e+00 -1.1364845e+00\n",
      "  -4.0751055e-01 -9.1843480e-01  6.2575686e-01]]),)\n",
      "        y          = needle.Tensor([[ 2.7137520e+00  5.7211286e-01 -4.6766111e-01  1.1092497e+00\n",
      "  -8.2207817e-01 -1.6646749e-01 -1.1684218...381e+00\n",
      "  -2.1852746e+00  6.2384862e-01 -1.6657708e+00 -1.1364845e+00\n",
      "  -4.0751055e-01 -9.1843480e-01  6.2575686e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 2.7137520e+00  5.7211286e-01 -4.6766111e-01  1.1092497e+00\n",
      "  -8.2207817e-01 -1.6646749e-01 -1.168421...52746e+00  6.2384862e-01 -1.6657708e+00 -1.1364845e+00\n",
      "  -4.0751055e-01 -9.1843480e-01  6.2575686e-01]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46123c400>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 2.7137520e+00  5.7211286e-01 -4.6766111e-01  1.1092497e+00\n",
      "  -8.2207817e-01 -1.6646749e-01 -1.1684218...381e+00\n",
      "  -2.1852746e+00  6.2384862e-01 -1.6657708e+00 -1.1364845e+00\n",
      "  -4.0751055e-01 -9.1843480e-01  6.2575686e-01]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.5892863  -1.266954    0.27684745 -0.32763693]\n",
      " [ 0.4599657  -3.0360172   0.6624156  -0.4219851 ]\n",
      " [...34  0.29554185]\n",
      " [-0.18682492  0.46791655 -0.10753176 -1.8227217 ]\n",
      " [-3.1601942  -3.91751    -1.6056203  -1.9578403 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46123c400>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.03914702  0.9034473  -0.80107677 -0.8050028 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.03914702  0.9034473  -0.80107677 -0.8050028 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46123c220>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.03914702  0.9034473  -0.80107677 -0.8050028 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46123c220>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46123c250>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46123c250>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46123ca00>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46123ca00>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-1-11-15-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 0.53346   ],\n",
      "        [ 1.3126761 ],\n",
      "        [-0.21284898],\n",
      "        [ 0.3744067 ],\n",
      "        [ 0.44571787],\n",
      "   ...473989  ],\n",
      "        [ 0.1645939 ],\n",
      "        [-0.64809984],\n",
      "        [ 0.75606483],\n",
      "        [-0.03217886]]], dtype=float32)\n",
      "c_         = tensor([[[-0.1210],\n",
      "         [-0.0515],\n",
      "         [-0.5133],\n",
      "         [-0.2415],\n",
      "         [-0.3146],\n",
      "         [-0.2871]... [-1.1478],\n",
      "         [-0.7871],\n",
      "         [-0.8818],\n",
      "         [-0.3153],\n",
      "         [-0.3679]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.5088953 ],\n",
      "        [ 0.68505466],\n",
      "        [-0.89979994],\n",
      "        [ 0.02926098],\n",
      "        [-0.57074326],\n",
      "   ...3318834 ],\n",
      "        [ 1.6847912 ],\n",
      "        [-0.32072183],\n",
      "        [-0.5841695 ],\n",
      "        [-0.404892  ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.1141],\n",
      "         [-0.0449],\n",
      "         [-0.4083],\n",
      "         [-0.1537],\n",
      "         [-0.0996],\n",
      "         [-0.1491]... [-0.1568],\n",
      "         [-0.6068],\n",
      "         [-0.5696],\n",
      "         [-0.0134],\n",
      "         [-0.3031]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb458ce4d00>\n",
      "model_     = LSTM(11, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-7.2905e-02],\n",
      "         [ 2.6481e-02],\n",
      "         [ 1.7987e-03],\n",
      "         [ 1.0549e-02],\n",
      "         [-1.6675e-01]...     [-6.0681e-01],\n",
      "         [-5.6962e-01],\n",
      "         [-1.3392e-02],\n",
      "         [-3.0306e-01]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 1.8974866 , -0.2252862 , -0.15537003, ...,  0.7124116 ,\n",
      "          1.0353329 , -0.18207757],\n",
      "        [ 0.2728...\n",
      "        [ 0.39850545,  0.09571352,  1.0330473 , ...,  0.11794502,\n",
      "          1.3050722 ,  0.02088927]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.8974866  -0.2252862  -0.15537003 ...  0.7124116   1.0353329\n",
      "   -0.18207757]\n",
      "  [ 0.2728002   0.283...  1.5191321\n",
      "    0.37606683]\n",
      "  [ 0.39850545  0.09571352  1.0330473  ...  0.11794502  1.3050722\n",
      "    0.02088927]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458ce4d00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 1.8974866  -0.2252862  -0.15537003 ...  0.7124116   1.0353329\n",
      "   -0.18207757]\n",
      "  [ 0.2728002   0.2835...327026   1.5191321\n",
      "    0.37606683]\n",
      "  [ 0.39850545  0.09571352  1.0330473  ...  0.11794502  1.3050722\n",
      "    0.02088927]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458ce4d00>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.8974866  -0.2252862  -0.15537003  0.8656857   0.10618412  0.4083569\n",
      "  -0.4008136...49e+00\n",
      "   6.1562115e-01  5.5805796e-01  8.2092041e-01  6.8264782e-01\n",
      "   1.1794502e-01  1.3050722e+00  2.0889273e-02]]))\n",
      "        y          = needle.Tensor([[ 1.8974866  -0.2252862  -0.15537003  0.8656857   0.10618412  0.4083569\n",
      "  -0.40081364 -1.9413226   0.71...703043   0.61362725 -0.5637117  -1.4507917   0.8187375\n",
      "  -0.4992597   1.044791   -0.19751014  0.29930085 -1.0194579 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.8974866  -0.2252862  -0.15537003  0.8656857   0.10618412  0.4083569\n",
      "  -0.40081364 -1.9413226   0.7...2725 -0.5637117  -1.4507917   0.8187375\n",
      "  -0.4992597   1.044791   -0.19751014  0.29930085 -1.0194579 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458ce4910>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 1.8974866  -0.2252862  -0.15537003  0.8656857   0.10618412  0.4083569\n",
      "  -0.40081364 -1.9413226   0.71...703043   0.61362725 -0.5637117  -1.4507917   0.8187375\n",
      "  -0.4992597   1.044791   -0.19751014  0.29930085 -1.0194579 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.25203264  0.4704466   0.1852211  -0.98264444]\n",
      " [-1.9367265  -0.5092996   1.444899    0.31156728]\n",
      " [...52  2.1622028 ]\n",
      " [-0.16578662 -2.1532345  -1.773738   -1.2441243 ]\n",
      " [-1.0668957   1.0009973  -1.465508    2.3311496 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458ce4910>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.33788896 -0.11970484  0.95487976  0.8775773 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.33788896 -0.11970484  0.95487976  0.8775773 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4382efa90>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.33788896 -0.11970484  0.95487976  0.8775773 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4382efa90>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4382ef1f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4382ef1f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4382eff70>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4382eff70>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-1-11-15-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 0.67318547],\n",
      "        [ 1.0640497 ],\n",
      "        [ 0.11004057],\n",
      "        [-0.26116937],\n",
      "        [-0.3755889 ],\n",
      "   ...98072827],\n",
      "        [-0.15348555],\n",
      "        [-0.15255934],\n",
      "        [ 1.2506845 ],\n",
      "        [-0.22407557]]], dtype=float32)\n",
      "c_         = tensor([[[-0.8248],\n",
      "         [-0.5381],\n",
      "         [-0.8913],\n",
      "         [ 0.3980],\n",
      "         [-0.7019],\n",
      "         [ 0.1468]... [ 0.4444],\n",
      "         [ 0.4343],\n",
      "         [ 0.4272],\n",
      "         [ 0.4352],\n",
      "         [ 0.4338]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 1.1579603 ],\n",
      "        [-0.6776174 ],\n",
      "        [-2.1216354 ],\n",
      "        [ 0.5958209 ],\n",
      "        [-0.21494308],\n",
      "   ...1577755 ],\n",
      "        [-0.41437107],\n",
      "        [-1.3025541 ],\n",
      "        [-0.23002617],\n",
      "        [-0.511592  ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.4662],\n",
      "         [-0.4682],\n",
      "         [-0.1298],\n",
      "         [ 0.0962],\n",
      "         [-0.5022],\n",
      "         [ 0.0202]... [ 0.3101],\n",
      "         [ 0.3085],\n",
      "         [ 0.3070],\n",
      "         [ 0.3087],\n",
      "         [ 0.3084]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb471d09ca0>\n",
      "model_     = LSTM(11, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[0.3006],\n",
      "         [0.3005],\n",
      "         [0.3078],\n",
      "         [0.3105],\n",
      "         [0.2996],\n",
      "         [0.3098],\n",
      "    ...      [0.3101],\n",
      "         [0.3085],\n",
      "         [0.3070],\n",
      "         [0.3087],\n",
      "         [0.3084]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.53792566,  0.61636853, -0.39643323, -0.55842847,\n",
      "          0.89752233, -0.25670433,  0.9901089 , -0.907230...   0.96343213,  1.1909009 , -0.78398985, -0.88997173,\n",
      "          1.0557877 , -0.71663326, -0.87050384]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.53792566  0.61636853 -0.39643323 -0.55842847  0.89752233\n",
      "   -0.25670433  0.9901089  -0.90723085  ...02721  -0.83127445  0.96343213\n",
      "    1.1909009  -0.78398985 -0.88997173  1.0557877  -0.71663326\n",
      "   -0.87050384]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d09ca0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.53792566  0.61636853 -0.39643323 -0.55842847  0.89752233\n",
      "   -0.25670433  0.9901089  -0.90723085  1...5  0.7502721  -0.83127445  0.96343213\n",
      "    1.1909009  -0.78398985 -0.88997173  1.0557877  -0.71663326\n",
      "   -0.87050384]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d09ca0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.53792566  0.61636853 -0.39643323 -0.55842847  0.89752233 -0.25670433\n",
      "   0.990108...92175  0.7502721  -0.83127445  0.96343213  1.1909009\n",
      "  -0.78398985 -0.88997173  1.0557877  -0.71663326 -0.87050384]]),)\n",
      "        y          = needle.Tensor([[-0.53792566  0.61636853 -0.39643323 -0.55842847  0.89752233 -0.25670433\n",
      "   0.9901089  -0.90723085  1.1...6592175  0.7502721  -0.83127445  0.96343213  1.1909009\n",
      "  -0.78398985 -0.88997173  1.0557877  -0.71663326 -0.87050384]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.53792566  0.61636853 -0.39643323 -0.55842847  0.89752233 -0.25670433\n",
      "   0.9901089  -0.90723085  1....721  -0.83127445  0.96343213  1.1909009\n",
      "  -0.78398985 -0.88997173  1.0557877  -0.71663326 -0.87050384]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d091c0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.53792566  0.61636853 -0.39643323 -0.55842847  0.89752233 -0.25670433\n",
      "   0.9901089  -0.90723085  1.1...6592175  0.7502721  -0.83127445  0.96343213  1.1909009\n",
      "  -0.78398985 -0.88997173  1.0557877  -0.71663326 -0.87050384]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.33979478 -0.8938087  -0.6698202   0.80546385]\n",
      " [-1.1888051   2.6364346  -0.4903406   3.013257  ]\n",
      " [...8   1.1795212 ]\n",
      " [ 0.19693509  1.3461461   1.117981    0.46061286]\n",
      " [-0.99912554 -1.3362882  -3.655148   -1.562562  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d091c0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.95078886  0.70791805 -0.83395696  0.06966472]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.95078886  0.70791805 -0.83395696  0.06966472]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461dbe2e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.95078886  0.70791805 -0.83395696  0.06966472]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461dbe2e0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461dbed30>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461dbed30>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461dbee50>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461dbee50>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-1-11-15-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-0.5276724 ],\n",
      "        [ 0.1602263 ],\n",
      "        [ 0.8675607 ],\n",
      "        [ 0.60278195],\n",
      "        [ 0.62123907],\n",
      "   ...20855924],\n",
      "        [-1.0026654 ],\n",
      "        [-1.3880243 ],\n",
      "        [ 0.79729724],\n",
      "        [ 0.7556002 ]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.5360],\n",
      "         [-0.3705],\n",
      "         [-0.8271],\n",
      "         [ 0.1904],\n",
      "         [ 0.2864],\n",
      "         [-0.7029]... [-0.0852],\n",
      "         [-0.1041],\n",
      "         [-0.0782],\n",
      "         [-0.1258],\n",
      "         [-0.0692]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.87347966],\n",
      "        [-0.6478791 ],\n",
      "        [ 0.00766587],\n",
      "        [ 0.7891993 ],\n",
      "        [-1.0347457 ],\n",
      "   ...52119327],\n",
      "        [-0.38083056],\n",
      "        [ 0.13579878],\n",
      "        [ 0.60601723],\n",
      "        [ 0.33757564]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.2969],\n",
      "         [-0.2109],\n",
      "         [-0.2816],\n",
      "         [ 0.1646],\n",
      "         [ 0.1251],\n",
      "         [-0.4455]... [-0.0619],\n",
      "         [-0.0733],\n",
      "         [-0.0558],\n",
      "         [-0.0885],\n",
      "         [-0.0509]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb48127ffd0>\n",
      "model_     = LSTM(11, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0679],\n",
      "         [-0.1124],\n",
      "         [-0.0682],\n",
      "         [-0.0156],\n",
      "         [-0.0501],\n",
      "         [-0.1135]... [-0.0619],\n",
      "         [-0.0733],\n",
      "         [-0.0558],\n",
      "         [-0.0885],\n",
      "         [-0.0509]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 7.38279521e-01,  1.26232076e+00, -9.68323529e-01, ...,\n",
      "         -4.54690963e-01,  6.35986105e-02,  1.1918246...02182734e+00,  1.41525996e+00, ...,\n",
      "          1.32033360e+00,  2.36761700e-02,  1.20358229e+00]]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 7.38279521e-01  1.26232076e+00 -9.68323529e-01 ... -4.54690963e-01\n",
      "    6.35986105e-02  1.19182460e-...0]\n",
      "  [ 1.45797551e+00  1.02182734e+00  1.41525996e+00 ...  1.32033360e+00\n",
      "    2.36761700e-02  1.20358229e+00]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48127ffd0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 7.38279521e-01  1.26232076e+00 -9.68323529e-01 ... -4.54690963e-01\n",
      "    6.35986105e-02  1.19182460e-0...2743e+00]\n",
      "  [ 1.45797551e+00  1.02182734e+00  1.41525996e+00 ...  1.32033360e+00\n",
      "    2.36761700e-02  1.20358229e+00]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48127ffd0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.7382795   1.2623208  -0.9683235   0.5564666   0.988567    0.19761421\n",
      "   0.139315...  -2.43822598e+00 -5.65633655e-01  2.81555742e-01 -1.25411725e+00\n",
      "   1.32033360e+00  2.36761700e-02  1.20358229e+00]]))\n",
      "        y          = needle.Tensor([[ 0.7382795   1.2623208  -0.9683235   0.5564666   0.988567    0.19761421\n",
      "   0.13931556  0.18103701 -0.4...86005   0.2029469  -0.7552892   0.01629994  0.19944234\n",
      "  -1.1549497   0.8719267  -1.6697733   0.37977782 -0.4875797 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.7382795   1.2623208  -0.9683235   0.5564666   0.988567    0.19761421\n",
      "   0.13931556  0.18103701 -0....69  -0.7552892   0.01629994  0.19944234\n",
      "  -1.1549497   0.8719267  -1.6697733   0.37977782 -0.4875797 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb48127f790>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.7382795   1.2623208  -0.9683235   0.5564666   0.988567    0.19761421\n",
      "   0.13931556  0.18103701 -0.4...86005   0.2029469  -0.7552892   0.01629994  0.19944234\n",
      "  -1.1549497   0.8719267  -1.6697733   0.37977782 -0.4875797 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.2417769e+00  3.1896582e+00  2.1842171e-02 -1.2429242e-01]\n",
      " [ 5.4841238e-01  2.8757603e+00 -3.080644...0861e-01  3.9385920e+00  2.6092601e+00 -1.2531281e-03]\n",
      " [ 9.0639877e-01 -5.7102162e-01 -7.5526953e-02  4.9160843e+00]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb48127f790>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.8400382  -0.38101757 -0.55352724 -0.9026655 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.8400382  -0.38101757 -0.55352724 -0.9026655 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4620dcc10>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.8400382  -0.38101757 -0.55352724 -0.9026655 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4620dcc10>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4620dc3a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4620dc3a0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4620dcf70>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4620dcf70>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-12-1-1-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 12\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-1.2143726 ,  0.6803972 , -0.6843765 , -0.17865047,\n",
      "          0.36609545, -2.5460613 ,  0.77846044, -0.14964499,\n",
      "          0.08648206,  0.31932437,  0.32277638, -1.1477108 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0102, -0.0773, -0.1014, -0.0400,  0.1581, -0.0508, -0.1742,\n",
      "           0.0845,  0.0865,  0.0911,  0.0703, -0.1117]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-1.7902088 ,  0.36403605,  0.32917723, -1.1167905 ,\n",
      "          1.6678609 , -0.7571338 , -0.5731643 , -0.18878958,\n",
      "          0.5633721 ,  1.554244  ,  1.0815274 , -1.23054   ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0054, -0.0363, -0.0441, -0.0229,  0.0677, -0.0252, -0.0800,\n",
      "           0.0455,  0.0449,  0.0432,  0.0304, -0.0640]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4620251f0>\n",
      "model_     = LSTM(1, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0054, -0.0363, -0.0441, -0.0229,  0.0677, -0.0252, -0.0800,\n",
      "           0.0455,  0.0449,  0.0432,  0.0304, -0.0640]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[0.12673706]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[0.12673706]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4620251f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[0.12673706]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4620251f0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.12673706]]),)\n",
      "        y          = needle.Tensor([[0.12673706]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.12673706]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462025460>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[0.12673706]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.02524674  0.0002054  -0.02794172 -0.02569477  0.0090234   0.00609034\n",
      "   0.02565356  0.01224503 -0.0...667658  0.00397428 -0.03557375  0.01199627\n",
      "  -0.03433803  0.00861572 -0.0029658  -0.00912367 -0.02319633 -0.03582986]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462025460>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 1.73428208e-01 -2.85475284e-01  5.46851158e-02 -1.90090626e-01\n",
      "   1.54837042e-01 -9.57247615e-02  5.3...01  9.54339504e-02 -2.60507435e-01 -1.18685991e-01\n",
      "   2.88460851e-02 -8.77146721e-02 -1.77973598e-01  1.07365280e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 1.73428208e-01 -2.85475284e-01  5.46851158e-02 -1.90090626e-01\n",
      "   1.54837042e-01 -9.57247615e-02  5....4339504e-02 -2.60507435e-01 -1.18685991e-01\n",
      "   2.88460851e-02 -8.77146721e-02 -1.77973598e-01  1.07365280e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb462025760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 1.73428208e-01 -2.85475284e-01  5.46851158e-02 -1.90090626e-01\n",
      "   1.54837042e-01 -9.57247615e-02  5....4339504e-02 -2.60507435e-01 -1.18685991e-01\n",
      "   2.88460851e-02 -8.77146721e-02 -1.77973598e-01  1.07365280e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb462025760>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb462025910>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb462025910>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb462025fd0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb462025fd0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-1-1-1-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.23032749,  3.3192766 ,  1.6733304 , -0.94281584,\n",
      "          2.2677605 , -0.92971724, -0.90582347, -0.16047326,\n",
      "          0.1867998 ,  1.8778855 ,  0.33974817, -1.3394643 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.3270, -0.1461,  0.1572, -0.2128,  0.2309,  0.2195,  0.0239,\n",
      "           0.2437, -0.1118, -0.1783,  0.4194, -0.4435]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.59089166, -0.32212147,  0.11169576, -1.4850364 ,\n",
      "         -0.7710254 ,  2.8311477 ,  1.5221413 ,  0.20153765,\n",
      "          0.28655955, -0.21827145,  0.38508052, -0.84708023]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.1585, -0.0699,  0.0916, -0.0996,  0.1048,  0.1086,  0.0152,\n",
      "           0.1136, -0.0412, -0.1102,  0.2257, -0.2450]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb461d80910>\n",
      "model_     = LSTM(1, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0762, -0.0693,  0.0716, -0.0934, -0.0242, -0.0077,  0.0379,\n",
      "           0.0094,  0.0128, -0.0121,  0.0859,...,  0.1048,  0.1086,  0.0152,\n",
      "           0.1136, -0.0412, -0.1102,  0.2257, -0.2450]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.24221969]],\n",
      "\n",
      "       [[-0.10247523]],\n",
      "\n",
      "       [[ 0.61766386]],\n",
      "\n",
      "       [[ 0.6526417 ]],\n",
      "\n",
      "       [[ 0.521158...]],\n",
      "\n",
      "       [[ 0.9246411 ]],\n",
      "\n",
      "       [[ 1.8818521 ]],\n",
      "\n",
      "       [[ 0.5404791 ]],\n",
      "\n",
      "       [[ 1.480018  ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.24221969]]\n",
      "\n",
      " [[-0.10247523]]\n",
      "\n",
      " [[ 0.61766386]]\n",
      "\n",
      " [[ 0.6526417 ]]\n",
      "\n",
      " [[ 0.52115804]]\n",
      "\n",
      " [[ 1.8824434...]]\n",
      "\n",
      " [[ 0.28816572]]\n",
      "\n",
      " [[ 2.3034143 ]]\n",
      "\n",
      " [[ 0.9246411 ]]\n",
      "\n",
      " [[ 1.8818521 ]]\n",
      "\n",
      " [[ 0.5404791 ]]\n",
      "\n",
      " [[ 1.480018  ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461d80910>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.24221969]]\n",
      "\n",
      " [[-0.10247523]]\n",
      "\n",
      " [[ 0.61766386]]\n",
      "\n",
      " [[ 0.6526417 ]]\n",
      "\n",
      " [[ 0.52115804]]\n",
      "\n",
      " [[ 1.8824434 ...114512 ]]\n",
      "\n",
      " [[ 0.28816572]]\n",
      "\n",
      " [[ 2.3034143 ]]\n",
      "\n",
      " [[ 0.9246411 ]]\n",
      "\n",
      " [[ 1.8818521 ]]\n",
      "\n",
      " [[ 0.5404791 ]]\n",
      "\n",
      " [[ 1.480018  ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461d80910>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.24221969]]), needle.Tensor([[-0.10247523]]), needle.Tensor([[0.61766386]]), need... needle.Tensor([[0.9246411]]), needle.Tensor([[1.8818521]]), needle.Tensor([[0.5404791]]), needle.Tensor([[1.480018]]))\n",
      "        y          = needle.Tensor([[-0.24221969]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.24221969]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461d807f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.24221969]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.06156544  0.06166886  0.05469001 -0.00892956 -0.02360148 -0.0641839\n",
      "   0.0379168  -0.03731249  0.06...368244  0.06723204 -0.01245795 -0.04797403\n",
      "  -0.05875821  0.05219761  0.05598174 -0.06514465 -0.00123022 -0.03119083]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461d807f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.15999483 -0.10717429 -0.0437649  -0.2128981  -0.0774601   0.04923803\n",
      "  -0.0637262  -0.21396294  0.0...031817 -0.18758483 -0.05365466  0.11161861\n",
      "   0.25404823 -0.00727266  0.04806495  0.28450853 -0.06495494 -0.12660518]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.15999483 -0.10717429 -0.0437649  -0.2128981  -0.0774601   0.04923803\n",
      "  -0.0637262  -0.21396294  0....-0.18758483 -0.05365466  0.11161861\n",
      "   0.25404823 -0.00727266  0.04806495  0.28450853 -0.06495494 -0.12660518]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480ee0f10>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.15999483 -0.10717429 -0.0437649  -0.2128981  -0.0774601   0.04923803\n",
      "  -0.0637262  -0.21396294  0....-0.18758483 -0.05365466  0.11161861\n",
      "   0.25404823 -0.00727266  0.04806495  0.28450853 -0.06495494 -0.12660518]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480ee0f10>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480ee0310>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480ee0310>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480ee0610>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480ee0610>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-True-12-1-1-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 12\n",
      "bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.32249662,  1.0555838 , -1.3021044 , -0.02815305,\n",
      "         -0.7796125 ,  0.0381686 , -0.19542204, -0.563860...3964794,  0.48647165,  0.94937944,\n",
      "          1.2389077 ,  0.6534343 , -0.5394534 ,  0.5852179 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0238, -0.0457, -0.0302, -0.0724, -0.0947, -0.1204,  0.1334,\n",
      "          -0.1092,  0.0415,  0.1854, -0.1805,...,  0.0212,  0.0062,  0.1129,\n",
      "           0.1001,  0.1986, -0.1379,  0.0541, -0.0340]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.64645433,  1.7942977 , -0.13839282, -0.39057076,\n",
      "          0.22331028, -0.18427955,  0.87231976,  1.067838...697597 , -0.02941784, -2.562062  ,\n",
      "         -0.35006425, -1.0243299 ,  0.4467614 ,  0.01202928]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0146, -0.0228, -0.0131, -0.0363, -0.0450, -0.0591,  0.0726,\n",
      "          -0.0456,  0.0247,  0.0872, -0.0920,...,  0.0097,  0.0032,  0.0556,\n",
      "           0.0388,  0.0830, -0.0808,  0.0224, -0.0192]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb450aeea90>\n",
      "model_     = LSTM(1, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0175,  0.0339, -0.0264, -0.0279,  0.0097,  0.0032,  0.0556,\n",
      "           0.0388,  0.0830, -0.0808,  0.0224, -0.0192]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.342141]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.342141]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450aeea90>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.342141]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450aeea90>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.342141]]),)\n",
      "        y          = needle.Tensor([[-0.342141]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.342141]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450aee850>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.342141]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.05401143 -0.04131649  0.04110228  0.09489945 -0.08369366 -0.05727135\n",
      "  -0.0016569  -0.02670737 -0.0...277555  0.0265987   0.03862772 -0.08161317\n",
      "   0.03016478  0.00365428  0.06360482 -0.08727726 -0.00490322  0.04916447]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450aee850>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 2.82270908e-01  1.47829324e-01 -1.40912011e-01  5.91474175e-02\n",
      "  -2.59189010e-02 -1.60216197e-01  2.2...01 -1.55819356e-02  1.92943752e-01  1.83075279e-01\n",
      "   2.23732114e-01 -2.50275910e-01  1.97946310e-01 -1.94319695e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 2.82270908e-01  1.47829324e-01 -1.40912011e-01  5.91474175e-02\n",
      "  -2.59189010e-02 -1.60216197e-01  2....5819356e-02  1.92943752e-01  1.83075279e-01\n",
      "   2.23732114e-01 -2.50275910e-01  1.97946310e-01 -1.94319695e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb45889d520>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 2.82270908e-01  1.47829324e-01 -1.40912011e-01  5.91474175e-02\n",
      "  -2.59189010e-02 -1.60216197e-01  2....5819356e-02  1.92943752e-01  1.83075279e-01\n",
      "   2.23732114e-01 -2.50275910e-01  1.97946310e-01 -1.94319695e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb45889d520>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb45889d6d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb45889d6d0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb45889d1c0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb45889d1c0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-1-1-2-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[ 0.7585114 , -0.6570497 ,  0.589907  ,  0.88159543,\n",
      "          0.7767357 , -0.68879193,  0.28152636, -0.515513...537383 ,  0.23477288,  1.0350507 ,\n",
      "         -0.44941562, -0.39077058, -1.7593112 , -0.4110001 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.2163, -0.4017,  0.0687, -0.1837, -0.4182,  0.1876, -0.2025,\n",
      "          -0.2315, -0.1456,  0.1534, -0.1256,...,  0.1329,  0.1699, -0.0744,\n",
      "           0.0263,  0.0571,  0.3586,  0.2216,  0.0036]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 1.341666  ,  0.603759  ,  0.481902  , -1.9179672 ,\n",
      "         -0.5642417 ,  0.956618  ,  0.92632365, -0.869031...8410504, -0.01430421,  0.07677379,\n",
      "         -0.32566714, -0.5206902 ,  0.93269867,  0.14656785]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0762, -0.1848,  0.0330, -0.0827, -0.2121,  0.0996, -0.1144,\n",
      "          -0.1213, -0.0464,  0.0809, -0.0597,...,  0.0627,  0.0882, -0.0431,\n",
      "           0.0140,  0.0285,  0.1713,  0.1136,  0.0014]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb461c25f40>\n",
      "model_     = LSTM(1, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 6.1285e-02, -1.1296e-02,  1.0595e-02,  3.6389e-02,  3.4256e-02,\n",
      "           5.0077e-02, -8.9295e-03, -1.6895...2, -4.3144e-02,  1.4009e-02,  2.8453e-02,  1.7130e-01,\n",
      "           1.1357e-01,  1.3871e-03]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.28488743]],\n",
      "\n",
      "       [[ 0.19393966]],\n",
      "\n",
      "       [[-0.39831948]],\n",
      "\n",
      "       [[-1.6857074 ]],\n",
      "\n",
      "       [[ 0.172445...]],\n",
      "\n",
      "       [[ 0.02527166]],\n",
      "\n",
      "       [[-0.49877495]],\n",
      "\n",
      "       [[ 0.34411788]],\n",
      "\n",
      "       [[-1.2970291 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.28488743]]\n",
      "\n",
      " [[ 0.19393966]]\n",
      "\n",
      " [[-0.39831948]]\n",
      "\n",
      " [[-1.6857074 ]]\n",
      "\n",
      " [[ 0.17244591]]\n",
      "\n",
      " [[ 0.6145235...]]\n",
      "\n",
      " [[-1.2086884 ]]\n",
      "\n",
      " [[ 0.69645494]]\n",
      "\n",
      " [[ 0.02527166]]\n",
      "\n",
      " [[-0.49877495]]\n",
      "\n",
      " [[ 0.34411788]]\n",
      "\n",
      " [[-1.2970291 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461c25f40>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.28488743]]\n",
      "\n",
      " [[ 0.19393966]]\n",
      "\n",
      " [[-0.39831948]]\n",
      "\n",
      " [[-1.6857074 ]]\n",
      "\n",
      " [[ 0.17244591]]\n",
      "\n",
      " [[ 0.61452353...643213 ]]\n",
      "\n",
      " [[-1.2086884 ]]\n",
      "\n",
      " [[ 0.69645494]]\n",
      "\n",
      " [[ 0.02527166]]\n",
      "\n",
      " [[-0.49877495]]\n",
      "\n",
      " [[ 0.34411788]]\n",
      "\n",
      " [[-1.2970291 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461c25f40>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.28488743]]), needle.Tensor([[0.19393966]]), needle.Tensor([[-0.39831948]]), need...e.Tensor([[0.02527166]]), needle.Tensor([[-0.49877495]]), needle.Tensor([[0.34411788]]), needle.Tensor([[-1.2970291]]))\n",
      "        y          = needle.Tensor([[-0.28488743]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.28488743]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461c25430>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.28488743]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.00978285 -0.08179382 -0.03782309  0.07933574 -0.01708032 -0.03731274\n",
      "   0.00189161 -0.0497278   0.0...113796  0.00369939  0.02782582  0.03732673\n",
      "   0.04902302  0.02525763 -0.07693437  0.01634284 -0.02694011  0.07305668]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461c25430>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.17471212  0.03560135  0.25629485  0.12854621 -0.23592623  0.16046065\n",
      "   0.1690175  -0.13197085 -0.0...900934 -0.03069896 -0.03675506  0.28511125\n",
      "  -0.2745462  -0.23504002 -0.01536825 -0.23590946  0.23504639  0.19675642]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.17471212  0.03560135  0.25629485  0.12854621 -0.23592623  0.16046065\n",
      "   0.1690175  -0.13197085 -0....-0.03069896 -0.03675506  0.28511125\n",
      "  -0.2745462  -0.23504002 -0.01536825 -0.23590946  0.23504639  0.19675642]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461f69100>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.17471212  0.03560135  0.25629485  0.12854621 -0.23592623  0.16046065\n",
      "   0.1690175  -0.13197085 -0....-0.03069896 -0.03675506  0.28511125\n",
      "  -0.2745462  -0.23504002 -0.01536825 -0.23590946  0.23504639  0.19675642]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461f69100>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461f69b50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461f69b50>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461f69700>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461f69700>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-1-15-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 1.4448324e+00,  8.1624255e-02, -4.6977472e-01,  3.0628366e-02,\n",
      "         -9.5436144e-01,  1.6742816e+00, -6.9...0e-01,  8.7325960e-02,\n",
      "          1.3086264e+00,  8.0236596e-01, -4.5276016e-01,  6.6189296e-03]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.1730,  0.0994, -0.0499,  0.1021,  0.1155, -0.0444,  0.0195,\n",
      "          -0.0829, -0.0210, -0.0121,  0.0173,...,  0.0849, -0.0296, -0.0094,\n",
      "          -0.1198, -0.0098,  0.0063, -0.0101,  0.1335]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 2.2248704 , -0.7336258 , -0.75019145,  1.3574817 ,\n",
      "         -0.85774577,  1.0172747 , -0.22953668,  1.367123...158504 , -0.44477925,  1.080459  ,\n",
      "         -0.7453344 , -0.46324438, -0.12980026, -1.2244325 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0812,  0.0575, -0.0232,  0.0491,  0.0514, -0.0248,  0.0124,\n",
      "          -0.0423, -0.0121, -0.0069,  0.0090,...,  0.0389, -0.0156, -0.0060,\n",
      "          -0.0605, -0.0055,  0.0037, -0.0050,  0.0619]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb471d09190>\n",
      "model_     = LSTM(1, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0812,  0.0575, -0.0232,  0.0491,  0.0514, -0.0248,  0.0124,\n",
      "          -0.0423, -0.0121, -0.0069,  0.0090,...,  0.0389, -0.0156, -0.0060,\n",
      "          -0.0605, -0.0055,  0.0037, -0.0050,  0.0619]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.18813652],\n",
      "        [-0.21915407],\n",
      "        [ 1.4761609 ],\n",
      "        [-0.21684474],\n",
      "        [ 0.39215505],\n",
      "   ...2996723 ],\n",
      "        [-0.55781615],\n",
      "        [-0.3271009 ],\n",
      "        [ 0.5138356 ],\n",
      "        [-0.68686   ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.18813652]\n",
      "  [-0.21915407]\n",
      "  [ 1.4761609 ]\n",
      "  [-0.21684474]\n",
      "  [ 0.39215505]\n",
      "  [-0.15725742]\n",
      "  [ 0.2...[ 0.20497344]\n",
      "  [ 0.5728404 ]\n",
      "  [ 0.2996723 ]\n",
      "  [-0.55781615]\n",
      "  [-0.3271009 ]\n",
      "  [ 0.5138356 ]\n",
      "  [-0.68686   ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d09190>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.18813652]\n",
      "  [-0.21915407]\n",
      "  [ 1.4761609 ]\n",
      "  [-0.21684474]\n",
      "  [ 0.39215505]\n",
      "  [-0.15725742]\n",
      "  [ 0.20...845]\n",
      "  [ 0.20497344]\n",
      "  [ 0.5728404 ]\n",
      "  [ 0.2996723 ]\n",
      "  [-0.55781615]\n",
      "  [-0.3271009 ]\n",
      "  [ 0.5138356 ]\n",
      "  [-0.68686   ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d09190>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.18813652]\n",
      " [-0.21915407]\n",
      " [ 1.4761609 ]\n",
      " [-0.21684474]\n",
      " [ 0.39215505]\n",
      " [-0.15725....21334845]\n",
      " [ 0.20497344]\n",
      " [ 0.5728404 ]\n",
      " [ 0.2996723 ]\n",
      " [-0.55781615]\n",
      " [-0.3271009 ]\n",
      " [ 0.5138356 ]\n",
      " [-0.68686   ]]),)\n",
      "        y          = needle.Tensor([[-0.18813652]\n",
      " [-0.21915407]\n",
      " [ 1.4761609 ]\n",
      " [-0.21684474]\n",
      " [ 0.39215505]\n",
      " [-0.15725742]\n",
      " [ 0.20431705]\n",
      " [-0.21334845]\n",
      " [ 0.20497344]\n",
      " [ 0.5728404 ]\n",
      " [ 0.2996723 ]\n",
      " [-0.55781615]\n",
      " [-0.3271009 ]\n",
      " [ 0.5138356 ]\n",
      " [-0.68686   ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.18813652]\n",
      " [-0.21915407]\n",
      " [ 1.4761609 ]\n",
      " [-0.21684474]\n",
      " [ 0.39215505]\n",
      " [-0.15725742]\n",
      " [ 0.20431705... 0.20497344]\n",
      " [ 0.5728404 ]\n",
      " [ 0.2996723 ]\n",
      " [-0.55781615]\n",
      " [-0.3271009 ]\n",
      " [ 0.5138356 ]\n",
      " [-0.68686   ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d094f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.18813652]\n",
      " [-0.21915407]\n",
      " [ 1.4761609 ]\n",
      " [-0.21684474]\n",
      " [ 0.39215505]\n",
      " [-0.15725742]\n",
      " [ 0.20431705]\n",
      " [-0.21334845]\n",
      " [ 0.20497344]\n",
      " [ 0.5728404 ]\n",
      " [ 0.2996723 ]\n",
      " [-0.55781615]\n",
      " [-0.3271009 ]\n",
      " [ 0.5138356 ]\n",
      " [-0.68686   ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.02987783  0.05293023 -0.00782283  0.03765763 -0.00553938 -0.02292436\n",
      "  -0.04159504 -0.04620211 -0.0...11270734  0.18271513  0.06807331 -0.177223\n",
      "   0.02178336 -0.01860592 -0.10671417  0.0344429  -0.15049897  0.16178623]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d094f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 1.21257901e-01  1.63350731e-01 -1.62807092e-01  2.33017325e-01\n",
      "  -1.73017055e-01  2.72509575e-01  2.8...01 -1.23132765e-01 -2.88662136e-01  1.24515682e-01\n",
      "  -2.62180060e-01 -2.77771682e-01 -7.52260834e-02  2.07009912e-03]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 1.21257901e-01  1.63350731e-01 -1.62807092e-01  2.33017325e-01\n",
      "  -1.73017055e-01  2.72509575e-01  2....3132765e-01 -2.88662136e-01  1.24515682e-01\n",
      "  -2.62180060e-01 -2.77771682e-01 -7.52260834e-02  2.07009912e-03]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471d09a30>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 1.21257901e-01  1.63350731e-01 -1.62807092e-01  2.33017325e-01\n",
      "  -1.73017055e-01  2.72509575e-01  2....3132765e-01 -2.88662136e-01  1.24515682e-01\n",
      "  -2.62180060e-01 -2.77771682e-01 -7.52260834e-02  2.07009912e-03]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471d09a30>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d09940>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d09940>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471d09640>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471d09640>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-1-15-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-1.03202391e+00,  3.08170646e-01, -7.85363853e-01,\n",
      "          1.36632955e+00,  1.72468281e+00,  2.02264413e-01...,  6.72432065e-01, -6.82245642e-02,\n",
      "          2.40360171e-01,  2.99982041e-01, -2.78492904e+00]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0450, -0.1494, -0.5171,  0.0463,  0.3383,  0.5429, -0.3679,\n",
      "           0.3691, -0.2165,  0.2073, -0.0888,...,  0.3601,  0.5545, -0.3798,\n",
      "           0.3948, -0.2299,  0.2539, -0.0879,  0.5474]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 2.10205   ,  0.00801077,  1.5527456 , -0.10138781,\n",
      "         -0.66940993, -0.10163388, -0.22142355, -1.387962...709939 ,  0.16331348, -0.45489112,\n",
      "         -1.4984769 ,  0.04610643,  0.11587146, -0.28876388]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0149, -0.0724, -0.2426,  0.0211,  0.1314,  0.2638, -0.1843,\n",
      "           0.1779, -0.1145,  0.1062, -0.0532,...,  0.1437,  0.2719, -0.1943,\n",
      "           0.1884, -0.1203,  0.1290, -0.0519,  0.2152]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb47201ac70>\n",
      "model_     = LSTM(1, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 3.8669e-02, -1.2214e-02, -5.4301e-02,  ..., -1.6313e-02,\n",
      "          -1.3785e-03,  8.1489e-02],\n",
      "         [ 1....2324e-02, -6.2755e-02, -2.5310e-01,  ...,  1.2904e-01,\n",
      "          -5.1916e-02,  2.1522e-01]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.99352497],\n",
      "        [ 0.4411566 ],\n",
      "        [-0.19735135],\n",
      "        [ 2.0146198 ],\n",
      "        [ 2.005107  ],\n",
      "   ...8570305 ],\n",
      "        [ 0.7589633 ],\n",
      "        [ 1.4492257 ],\n",
      "        [-1.3373641 ],\n",
      "        [ 0.2735991 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.99352497]\n",
      "  [ 0.4411566 ]\n",
      "  [-0.19735135]\n",
      "  [ 2.0146198 ]\n",
      "  [ 2.005107  ]\n",
      "  [-0.84114105]\n",
      "  [-0.8...[ 1.1111915 ]\n",
      "  [-1.7038666 ]\n",
      "  [ 0.8570305 ]\n",
      "  [ 0.7589633 ]\n",
      "  [ 1.4492257 ]\n",
      "  [-1.3373641 ]\n",
      "  [ 0.2735991 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb47201ac70>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.99352497]\n",
      "  [ 0.4411566 ]\n",
      "  [-0.19735135]\n",
      "  [ 2.0146198 ]\n",
      "  [ 2.005107  ]\n",
      "  [-0.84114105]\n",
      "  [-0.82...581]\n",
      "  [ 1.1111915 ]\n",
      "  [-1.7038666 ]\n",
      "  [ 0.8570305 ]\n",
      "  [ 0.7589633 ]\n",
      "  [ 1.4492257 ]\n",
      "  [-1.3373641 ]\n",
      "  [ 0.2735991 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb47201ac70>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.99352497]\n",
      " [ 0.4411566 ]\n",
      " [-0.19735135]\n",
      " [ 2.0146198 ]\n",
      " [ 2.005107  ]\n",
      " [-0.84114...0.23243581]\n",
      " [ 1.1111915 ]\n",
      " [-1.7038666 ]\n",
      " [ 0.8570305 ]\n",
      " [ 0.7589633 ]\n",
      " [ 1.4492257 ]\n",
      " [-1.3373641 ]\n",
      " [ 0.2735991 ]]))\n",
      "        y          = needle.Tensor([[-0.99352497]\n",
      " [ 0.4411566 ]\n",
      " [-0.19735135]\n",
      " [ 2.0146198 ]\n",
      " [ 2.005107  ]\n",
      " [-0.84114105]\n",
      " [-0.8285616 ]\n",
      " [ 0.35088727]\n",
      " [-1.0344353 ]\n",
      " [ 0.43839684]\n",
      " [-1.1810398 ]\n",
      " [ 1.0151222 ]\n",
      " [ 1.1895659 ]\n",
      " [ 0.15887988]\n",
      " [-1.1652992 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.99352497]\n",
      " [ 0.4411566 ]\n",
      " [-0.19735135]\n",
      " [ 2.0146198 ]\n",
      " [ 2.005107  ]\n",
      " [-0.84114105]\n",
      " [-0.8285616 ...-1.0344353 ]\n",
      " [ 0.43839684]\n",
      " [-1.1810398 ]\n",
      " [ 1.0151222 ]\n",
      " [ 1.1895659 ]\n",
      " [ 0.15887988]\n",
      " [-1.1652992 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb47201a610>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.99352497]\n",
      " [ 0.4411566 ]\n",
      " [-0.19735135]\n",
      " [ 2.0146198 ]\n",
      " [ 2.005107  ]\n",
      " [-0.84114105]\n",
      " [-0.8285616 ]\n",
      " [ 0.35088727]\n",
      " [-1.0344353 ]\n",
      " [ 0.43839684]\n",
      " [-1.1810398 ]\n",
      " [ 1.0151222 ]\n",
      " [ 1.1895659 ]\n",
      " [ 0.15887988]\n",
      " [-1.1652992 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 3.26802544e-02  1.09633438e-01 -7.21352175e-02  4.80166115e-02\n",
      "  -2.70109594e-01 -3.88680175e-02  1.3...01 -1.12358242e-01 -2.83115774e-01  8.82083029e-02\n",
      "   4.43414003e-02 -1.79367419e-02  1.65990546e-01  2.76582301e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb47201a610>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.99504399e-03  8.48848820e-02  7.87760913e-02  1.24190837e-01\n",
      "  -5.34748435e-02  5.77902496e-02 -5.2...02  3.20764184e-02 -2.06742316e-01 -1.53100356e-01\n",
      "  -8.90027434e-02 -2.20888853e-03 -2.67476737e-02 -7.17445761e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.99504399e-03  8.48848820e-02  7.87760913e-02  1.24190837e-01\n",
      "  -5.34748435e-02  5.77902496e-02 -5....0764184e-02 -2.06742316e-01 -1.53100356e-01\n",
      "  -8.90027434e-02 -2.20888853e-03 -2.67476737e-02 -7.17445761e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461dbe580>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.99504399e-03  8.48848820e-02  7.87760913e-02  1.24190837e-01\n",
      "  -5.34748435e-02  5.77902496e-02 -5....0764184e-02 -2.06742316e-01 -1.53100356e-01\n",
      "  -8.90027434e-02 -2.20888853e-03 -2.67476737e-02 -7.17445761e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461dbe580>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461dbe970>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461dbe970>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461dbe700>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461dbe700>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-1-15-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 0.01848162,  0.5298088 ,  0.22189699, -0.54078656,\n",
      "          0.7479878 , -2.1757126 ,  0.51387316,  1.901720...376125 , -0.32039896,  0.5212414 ,\n",
      "          1.1801182 ,  1.4065926 ,  0.8083276 ,  1.2864897 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0613, -0.0016, -0.1023,  0.0323, -0.1003,  0.1296,  0.0307,\n",
      "          -0.0520, -0.0306,  0.0019,  0.2105,...,  0.0343,  0.0943,  0.1715,\n",
      "           0.0260,  0.2070,  0.1063,  0.0990,  0.1684]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.8851025 , -1.2351218 ,  0.11935711,  0.5995266 ,\n",
      "         -1.2196044 , -0.05999555,  1.6333812 ,  1.371682...817614 ,  0.84275484,  0.16025534,\n",
      "         -0.43580824, -0.9920921 ,  0.14199243,  0.25976828]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0285, -0.0007, -0.0459,  0.0139, -0.0566,  0.0734,  0.0164,\n",
      "          -0.0315, -0.0179,  0.0010,  0.1120,...,  0.0194,  0.0474,  0.0674,\n",
      "           0.0151,  0.0912,  0.0475,  0.0509,  0.0768]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb48128faf0>\n",
      "model_     = LSTM(1, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0622, -0.0138, -0.0368,  0.0292,  0.0191,  0.0472,  0.0674,\n",
      "           0.0176,  0.0909,  0.0495,  0.0535,...,  0.0194,  0.0474,  0.0674,\n",
      "           0.0151,  0.0912,  0.0475,  0.0509,  0.0768]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.39761582],\n",
      "        [ 0.6080518 ],\n",
      "        [-1.7670374 ],\n",
      "        [-0.747617  ],\n",
      "        [-1.2547512 ],\n",
      "   ...90097946],\n",
      "        [ 0.6595683 ],\n",
      "        [-1.2082695 ],\n",
      "        [-2.1282547 ],\n",
      "        [-0.7484016 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.39761582]\n",
      "  [ 0.6080518 ]\n",
      "  [-1.7670374 ]\n",
      "  [-0.747617  ]\n",
      "  [-1.2547512 ]\n",
      "  [-1.1728827 ]\n",
      "  [ 1.6...[-1.089047  ]\n",
      "  [-0.7539046 ]\n",
      "  [-0.90097946]\n",
      "  [ 0.6595683 ]\n",
      "  [-1.2082695 ]\n",
      "  [-2.1282547 ]\n",
      "  [-0.7484016 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48128faf0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.39761582]\n",
      "  [ 0.6080518 ]\n",
      "  [-1.7670374 ]\n",
      "  [-0.747617  ]\n",
      "  [-1.2547512 ]\n",
      "  [-1.1728827 ]\n",
      "  [ 1.62...04 ]\n",
      "  [-1.089047  ]\n",
      "  [-0.7539046 ]\n",
      "  [-0.90097946]\n",
      "  [ 0.6595683 ]\n",
      "  [-1.2082695 ]\n",
      "  [-2.1282547 ]\n",
      "  [-0.7484016 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48128faf0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.39761582]\n",
      " [ 0.6080518 ]\n",
      " [-1.7670374 ]\n",
      " [-0.747617  ]\n",
      " [-1.2547512 ]\n",
      " [-1.17288....2413004 ]\n",
      " [-1.089047  ]\n",
      " [-0.7539046 ]\n",
      " [-0.90097946]\n",
      " [ 0.6595683 ]\n",
      " [-1.2082695 ]\n",
      " [-2.1282547 ]\n",
      " [-0.7484016 ]]),)\n",
      "        y          = needle.Tensor([[-0.39761582]\n",
      " [ 0.6080518 ]\n",
      " [-1.7670374 ]\n",
      " [-0.747617  ]\n",
      " [-1.2547512 ]\n",
      " [-1.1728827 ]\n",
      " [ 1.6283569 ]\n",
      " [ 0.2413004 ]\n",
      " [-1.089047  ]\n",
      " [-0.7539046 ]\n",
      " [-0.90097946]\n",
      " [ 0.6595683 ]\n",
      " [-1.2082695 ]\n",
      " [-2.1282547 ]\n",
      " [-0.7484016 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.39761582]\n",
      " [ 0.6080518 ]\n",
      " [-1.7670374 ]\n",
      " [-0.747617  ]\n",
      " [-1.2547512 ]\n",
      " [-1.1728827 ]\n",
      " [ 1.6283569 ...-1.089047  ]\n",
      " [-0.7539046 ]\n",
      " [-0.90097946]\n",
      " [ 0.6595683 ]\n",
      " [-1.2082695 ]\n",
      " [-2.1282547 ]\n",
      " [-0.7484016 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb48128fdc0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.39761582]\n",
      " [ 0.6080518 ]\n",
      " [-1.7670374 ]\n",
      " [-0.747617  ]\n",
      " [-1.2547512 ]\n",
      " [-1.1728827 ]\n",
      " [ 1.6283569 ]\n",
      " [ 0.2413004 ]\n",
      " [-1.089047  ]\n",
      " [-0.7539046 ]\n",
      " [-0.90097946]\n",
      " [ 0.6595683 ]\n",
      " [-1.2082695 ]\n",
      " [-2.1282547 ]\n",
      " [-0.7484016 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.38312569e-02 -6.21769801e-02  7.82029405e-02  3.28137204e-02\n",
      "  -8.52716985e-05 -4.14166637e-02  1.0...01  1.94833547e-01  1.04556240e-01 -5.84515445e-02\n",
      "  -5.97118810e-02  1.82971045e-01  7.86487386e-03 -1.79489385e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb48128fdc0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.25596792  0.0787769   0.15384561 -0.04238629  0.06624553  0.12588352\n",
      "   0.09863061 -0.01000628 -0.2...698447  0.06627929  0.01562071 -0.26305145\n",
      "   0.12551048 -0.16823295 -0.10824136 -0.21443556 -0.17523885  0.218562  ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.25596792  0.0787769   0.15384561 -0.04238629  0.06624553  0.12588352\n",
      "   0.09863061 -0.01000628 -0.... 0.06627929  0.01562071 -0.26305145\n",
      "   0.12551048 -0.16823295 -0.10824136 -0.21443556 -0.17523885  0.218562  ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb48128f400>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.25596792  0.0787769   0.15384561 -0.04238629  0.06624553  0.12588352\n",
      "   0.09863061 -0.01000628 -0.... 0.06627929  0.01562071 -0.26305145\n",
      "   0.12551048 -0.16823295 -0.10824136 -0.21443556 -0.17523885  0.218562  ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb48128f400>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb48128f4f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb48128f4f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb48128f310>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb48128f310>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-1-15-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-1.3679065 , -0.35908186,  1.0516677 , -1.433794  ,\n",
      "         -0.7306263 , -1.1862705 ,  0.22004478,  0.410891...3657725,  0.46693924,  1.9384413 ,\n",
      "         -0.37032044, -0.73889   , -0.48494577, -0.7407783 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 2.4095e-01, -1.2339e-01, -2.7949e-02,  3.2426e-01, -1.9246e-01,\n",
      "          -2.1821e-01, -3.5272e-03,  4.4996...1, -3.0517e-01, -6.7183e-02,  1.7260e-01, -1.8700e-01,\n",
      "          -3.5973e-01,  1.9944e-01]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-1.1599996 ,  0.7643311 , -1.0964658 ,  0.48540822,\n",
      "          1.6108185 ,  1.5309883 , -0.5863131 , -0.296754...024167 , -0.42507637, -0.39670444,\n",
      "          0.59633785,  0.6348231 , -0.6005893 ,  0.8931888 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 9.5194e-02, -7.7276e-02, -1.0989e-02,  1.6605e-01, -8.3909e-02,\n",
      "          -1.0516e-01, -1.5123e-03,  2.3653...2, -1.6816e-01, -3.5421e-02,  7.8497e-02, -8.9511e-02,\n",
      "          -1.6428e-01,  1.1138e-01]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb480ec8550>\n",
      "model_     = LSTM(1, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0143,  0.0146,  0.0698,  ..., -0.0161, -0.1029,  0.0533],\n",
      "         [ 0.0114,  0.0142,  0.0695,  ..., -0.0...62,  0.1079],\n",
      "         [ 0.0795,  0.0469,  0.1397,  ..., -0.0895, -0.1643,  0.1114]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 1.3709227e+00],\n",
      "        [ 1.9256637e+00],\n",
      "        [ 1.7925212e-01],\n",
      "        [ 1.4865847e-01],\n",
      "        [-8.31...       [ 1.8575697e+00],\n",
      "        [-9.5670128e-01],\n",
      "        [-1.1865731e+00],\n",
      "        [-1.6980100e-02]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.3709227e+00]\n",
      "  [ 1.9256637e+00]\n",
      "  [ 1.7925212e-01]\n",
      "  [ 1.4865847e-01]\n",
      "  [-8.3122694e-01]\n",
      "  [-5.85...1.5179930e+00]\n",
      "  [-1.5116774e-02]\n",
      "  [ 1.8575697e+00]\n",
      "  [-9.5670128e-01]\n",
      "  [-1.1865731e+00]\n",
      "  [-1.6980100e-02]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480ec8550>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 1.3709227e+00]\n",
      "  [ 1.9256637e+00]\n",
      "  [ 1.7925212e-01]\n",
      "  [ 1.4865847e-01]\n",
      "  [-8.3122694e-01]\n",
      "  [-5.858...1]\n",
      "  [ 1.5179930e+00]\n",
      "  [-1.5116774e-02]\n",
      "  [ 1.8575697e+00]\n",
      "  [-9.5670128e-01]\n",
      "  [-1.1865731e+00]\n",
      "  [-1.6980100e-02]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480ec8550>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.3709227 ]\n",
      " [ 1.9256637 ]\n",
      " [ 0.17925212]\n",
      " [ 0.14865847]\n",
      " [-0.83122694]\n",
      " [-0.58581...1.6398548 ]\n",
      " [ 0.9708962 ]\n",
      " [ 1.517993  ]\n",
      " [-0.01511677]\n",
      " [ 1.8575697 ]\n",
      " [-0.9567013 ]\n",
      " [-1.1865731 ]\n",
      " [-0.0169801 ]]))\n",
      "        y          = needle.Tensor([[ 1.3709227 ]\n",
      " [ 1.9256637 ]\n",
      " [ 0.17925212]\n",
      " [ 0.14865847]\n",
      " [-0.83122694]\n",
      " [-0.58581644]\n",
      " [-0.44591832]\n",
      " [-0.32400542]\n",
      " [-0.00269995]\n",
      " [ 0.12099339]\n",
      " [-1.3711178 ]\n",
      " [ 1.2334483 ]\n",
      " [-0.3580929 ]\n",
      " [ 1.6688515 ]\n",
      " [ 0.64672893]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.3709227 ]\n",
      " [ 1.9256637 ]\n",
      " [ 0.17925212]\n",
      " [ 0.14865847]\n",
      " [-0.83122694]\n",
      " [-0.58581644]\n",
      " [-0.44591832...-0.00269995]\n",
      " [ 0.12099339]\n",
      " [-1.3711178 ]\n",
      " [ 1.2334483 ]\n",
      " [-0.3580929 ]\n",
      " [ 1.6688515 ]\n",
      " [ 0.64672893]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480ec8f10>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 1.3709227 ]\n",
      " [ 1.9256637 ]\n",
      " [ 0.17925212]\n",
      " [ 0.14865847]\n",
      " [-0.83122694]\n",
      " [-0.58581644]\n",
      " [-0.44591832]\n",
      " [-0.32400542]\n",
      " [-0.00269995]\n",
      " [ 0.12099339]\n",
      " [-1.3711178 ]\n",
      " [ 1.2334483 ]\n",
      " [-0.3580929 ]\n",
      " [ 1.6688515 ]\n",
      " [ 0.64672893]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.35335997e-01 -4.73087244e-02 -1.02954954e-01  1.75042197e-01\n",
      "  -2.07095876e-01  3.33431929e-01  1.5...01  7.00805429e-03 -8.69347155e-02 -1.84932351e-01\n",
      "  -4.39906009e-02 -1.81663543e-01  1.61391497e-01 -8.66903216e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480ec8f10>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.19103572 -0.0710707   0.11291489 -0.02983528 -0.09627932  0.05378345\n",
      "   0.12720686  0.0468899   0.1...77444   0.20613724  0.13688698  0.07574317\n",
      "  -0.17848504  0.27499735 -0.06514658  0.28807777  0.22188383 -0.20527261]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.19103572 -0.0710707   0.11291489 -0.02983528 -0.09627932  0.05378345\n",
      "   0.12720686  0.0468899   0.... 0.20613724  0.13688698  0.07574317\n",
      "  -0.17848504  0.27499735 -0.06514658  0.28807777  0.22188383 -0.20527261]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46123ceb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.19103572 -0.0710707   0.11291489 -0.02983528 -0.09627932  0.05378345\n",
      "   0.12720686  0.0468899   0.... 0.20613724  0.13688698  0.07574317\n",
      "  -0.17848504  0.27499735 -0.06514658  0.28807777  0.22188383 -0.20527261]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46123ceb0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46123cd90>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46123cd90>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46123cc10>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46123cc10>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-11-1-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.09978506, -0.86414194, -0.8378446 , -0.2104733 ,\n",
      "         -1.0597615 , -0.19088945, -0.76265043, -2.1177328 ,\n",
      "         -1.142214  ,  0.9441027 , -0.9063928 , -2.0165644 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.5132,  0.0814,  0.3324,  0.3274, -0.2471, -0.4341,  0.2108,\n",
      "           0.1925,  0.1901, -0.1218, -0.2892,  0.1352]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.8077729 ,  0.6398363 , -0.4025672 ,  0.3061623 ,\n",
      "         -0.63103706, -1.6301317 ,  0.7397621 , -0.14640144,\n",
      "         -1.7184981 , -0.09965104, -0.4312839 , -1.3277241 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.2497,  0.0197,  0.1083,  0.2507, -0.1407, -0.2082,  0.1280,\n",
      "           0.0676,  0.1358, -0.0839, -0.2221,  0.0665]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb471cfb9a0>\n",
      "model_     = LSTM(11, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.2497,  0.0197,  0.1083,  0.2507, -0.1407, -0.2082,  0.1280,\n",
      "           0.0676,  0.1358, -0.0839, -0.2221,  0.0665]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.3580854 ,  0.5403724 , -0.11788208, -2.88316   ,\n",
      "          0.31332028, -1.0056278 , -0.20461948, -0.3824949 ,\n",
      "          0.4506996 ,  0.95320845, -0.91766894]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.3580854   0.5403724  -0.11788208 -2.88316     0.31332028\n",
      "   -1.0056278  -0.20461948 -0.3824949   0.4506996   0.95320845\n",
      "   -0.91766894]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471cfb9a0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.3580854   0.5403724  -0.11788208 -2.88316     0.31332028\n",
      "   -1.0056278  -0.20461948 -0.3824949   0.4506996   0.95320845\n",
      "   -0.91766894]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471cfb9a0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.3580854   0.5403724  -0.11788208 -2.88316     0.31332028 -1.0056278\n",
      "  -0.20461948 -0.3824949   0.4506996   0.95320845 -0.91766894]]),)\n",
      "        y          = needle.Tensor([[-1.3580854   0.5403724  -0.11788208 -2.88316     0.31332028 -1.0056278\n",
      "  -0.20461948 -0.3824949   0.4506996   0.95320845 -0.91766894]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.3580854   0.5403724  -0.11788208 -2.88316     0.31332028 -1.0056278\n",
      "  -0.20461948 -0.3824949   0.4506996   0.95320845 -0.91766894]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471cfbb20>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.3580854   0.5403724  -0.11788208 -2.88316     0.31332028 -1.0056278\n",
      "  -0.20461948 -0.3824949   0.4506996   0.95320845 -0.91766894]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.2360645   0.79740447  0.11388934 -0.83491266 -0.4557466   0.7453372\n",
      "   0.38369945 -0.81366783  0.36...68098   1.2309833   0.22487175 -0.15261021\n",
      "   0.26070437 -0.36149058  0.5613277   0.7574477   1.307512   -0.02297578]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471cfbb20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 6.59478605e-02  2.51733482e-01 -1.14478022e-01 -2.15704292e-01\n",
      "  -2.38090754e-03  2.69771039e-01 -1.0...01  8.07759166e-03  2.03377247e-01 -1.06114149e-02\n",
      "   7.61020184e-03 -1.79254398e-01 -1.91889286e-01 -1.32789746e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 6.59478605e-02  2.51733482e-01 -1.14478022e-01 -2.15704292e-01\n",
      "  -2.38090754e-03  2.69771039e-01 -1....7759166e-03  2.03377247e-01 -1.06114149e-02\n",
      "   7.61020184e-03 -1.79254398e-01 -1.91889286e-01 -1.32789746e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471cfb400>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 6.59478605e-02  2.51733482e-01 -1.14478022e-01 -2.15704292e-01\n",
      "  -2.38090754e-03  2.69771039e-01 -1....7759166e-03  2.03377247e-01 -1.06114149e-02\n",
      "   7.61020184e-03 -1.79254398e-01 -1.91889286e-01 -1.32789746e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471cfb400>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471cfb820>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471cfb820>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471cfb130>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471cfb130>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-11-1-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.2804845 , -0.21182428, -2.4028535 , -0.65176934,\n",
      "         -0.11261329,  0.54265106, -0.32992548,  0.7366137 ,\n",
      "         -0.37263775, -0.25787163,  0.27603352,  0.26068887]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.3710,  0.3432, -0.2321,  0.1993,  0.2607,  0.5723,  0.4231,\n",
      "           0.4787, -0.2400, -0.3219,  0.2148, -0.6454]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.29784065, -0.3766388 ,  1.4737097 ,  0.23761922,\n",
      "         -1.0005925 , -1.0299463 ,  1.9223555 , -0.7497915 ,\n",
      "         -1.7830478 , -1.0852689 , -0.30158752,  0.68016243]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.1394,  0.1603, -0.0609,  0.1447,  0.1278,  0.3215,  0.1957,\n",
      "           0.1902, -0.0754, -0.2487,  0.0576, -0.3265]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb430221490>\n",
      "model_     = LSTM(11, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0750, -0.1310,  0.0888,  0.0774,  0.1070,  0.0451,  0.0389,\n",
      "           0.0276, -0.0606, -0.0666, -0.0326,...,  0.1278,  0.3215,  0.1957,\n",
      "           0.1902, -0.0754, -0.2487,  0.0576, -0.3265]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.44826213,  0.60082287, -1.521895  , -1.6108898 ,\n",
      "         -0.41736475, -0.40062165,  1.7009839 , -0.420820...  -0.12001643,  2.2111955 , -0.39980173,  1.248416  ,\n",
      "          0.01903787, -0.21992728, -0.68808246]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.44826213  0.60082287 -1.521895   -1.6108898  -0.41736475\n",
      "   -0.40062165  1.7009839  -0.4208207  -...83074   0.09480342 -0.12001643\n",
      "    2.2111955  -0.39980173  1.248416    0.01903787 -0.21992728\n",
      "   -0.68808246]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb430221490>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.44826213  0.60082287 -1.521895   -1.6108898  -0.41736475\n",
      "   -0.40062165  1.7009839  -0.4208207  -0...4  1.3083074   0.09480342 -0.12001643\n",
      "    2.2111955  -0.39980173  1.248416    0.01903787 -0.21992728\n",
      "   -0.68808246]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb430221490>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.44826213  0.60082287 -1.521895   -1.6108898  -0.41736475 -0.40062165\n",
      "   1.700983...580874  1.3083074   0.09480342 -0.12001643  2.2111955\n",
      "  -0.39980173  1.248416    0.01903787 -0.21992728 -0.68808246]]))\n",
      "        y          = needle.Tensor([[ 0.44826213  0.60082287 -1.521895   -1.6108898  -0.41736475 -0.40062165\n",
      "   1.7009839  -0.4208207  -0.12600051  0.6028041   1.4388118 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.44826213  0.60082287 -1.521895   -1.6108898  -0.41736475 -0.40062165\n",
      "   1.7009839  -0.4208207  -0.12600051  0.6028041   1.4388118 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb430221160>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.44826213  0.60082287 -1.521895   -1.6108898  -0.41736475 -0.40062165\n",
      "   1.7009839  -0.4208207  -0.12600051  0.6028041   1.4388118 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.34046596 -0.58214945  0.6483116   0.5567999   0.9229122  -0.59917474\n",
      "  -1.052028   -0.3221886  -0.0...977916 -1.2541965  -1.0502875   0.42253163\n",
      "  -0.8195295   0.02685719 -0.2082443  -0.46818227  1.6828068   0.5053301 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb430221160>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.11118802 -0.19795519  0.08488807 -0.11448072  0.13530427 -0.13632569\n",
      "   0.11301222  0.03069693  0.1...393739  0.23922819 -0.2279722  -0.21371964\n",
      "  -0.05075049 -0.02813086  0.08556128 -0.23462087  0.06267151 -0.17939198]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.11118802 -0.19795519  0.08488807 -0.11448072  0.13530427 -0.13632569\n",
      "   0.11301222  0.03069693  0.... 0.23922819 -0.2279722  -0.21371964\n",
      "  -0.05075049 -0.02813086  0.08556128 -0.23462087  0.06267151 -0.17939198]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461c25dc0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.11118802 -0.19795519  0.08488807 -0.11448072  0.13530427 -0.13632569\n",
      "   0.11301222  0.03069693  0.... 0.23922819 -0.2279722  -0.21371964\n",
      "  -0.05075049 -0.02813086  0.08556128 -0.23462087  0.06267151 -0.17939198]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461c25dc0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461c255e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461c255e0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461c253d0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461c253d0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-11-1-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.22674032,  0.4003479 ,  0.5784149 , -0.4156462 ,\n",
      "         -1.4147658 ,  0.22350419, -1.0778795 ,  0.078376...6608505, -1.0439132 ,  0.87322867,\n",
      "         -1.6906037 , -1.8192003 , -0.46457845, -1.2369461 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.1024, -0.2732, -0.4582,  0.0992,  0.0758,  0.0340,  0.0607,\n",
      "          -0.2664,  0.1723,  0.0207, -0.0731,...,  0.0906, -0.0728, -0.0695,\n",
      "          -0.1922, -0.1913, -0.0255, -0.0532,  0.1498]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.9350507 , -3.0772827 , -0.12475554,  1.5324782 ,\n",
      "          1.0089625 , -1.2537241 , -0.50287265, -1.031305...154694 , -1.0013086 , -1.0465691 ,\n",
      "         -0.1099433 , -0.38056186,  2.186942  , -1.5218667 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0469, -0.1364, -0.1196,  0.0517,  0.0248,  0.0101,  0.0343,\n",
      "          -0.1464,  0.0854,  0.0099, -0.0426,...,  0.0462, -0.0403, -0.0324,\n",
      "          -0.1143, -0.0788, -0.0109, -0.0291,  0.0865]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb480d8cee0>\n",
      "model_     = LSTM(11, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0293, -0.0407, -0.0432,  0.0439,  0.0462, -0.0403, -0.0324,\n",
      "          -0.1143, -0.0788, -0.0109, -0.0291,  0.0865]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.3100054 , -1.0678679 ,  0.5204003 ,  1.6372986 ,\n",
      "         -0.65794206,  0.05121964, -0.37797913, -1.0111783 ,\n",
      "         -0.7128026 ,  0.7007648 , -1.1622875 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.3100054  -1.0678679   0.5204003   1.6372986  -0.65794206\n",
      "    0.05121964 -0.37797913 -1.0111783  -0.7128026   0.7007648\n",
      "   -1.1622875 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480d8cee0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.3100054  -1.0678679   0.5204003   1.6372986  -0.65794206\n",
      "    0.05121964 -0.37797913 -1.0111783  -0.7128026   0.7007648\n",
      "   -1.1622875 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480d8cee0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.3100054  -1.0678679   0.5204003   1.6372986  -0.65794206  0.05121964\n",
      "  -0.37797913 -1.0111783  -0.7128026   0.7007648  -1.1622875 ]]),)\n",
      "        y          = needle.Tensor([[-1.3100054  -1.0678679   0.5204003   1.6372986  -0.65794206  0.05121964\n",
      "  -0.37797913 -1.0111783  -0.7128026   0.7007648  -1.1622875 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.3100054  -1.0678679   0.5204003   1.6372986  -0.65794206  0.05121964\n",
      "  -0.37797913 -1.0111783  -0.7128026   0.7007648  -1.1622875 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384ad790>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.3100054  -1.0678679   0.5204003   1.6372986  -0.65794206  0.05121964\n",
      "  -0.37797913 -1.0111783  -0.7128026   0.7007648  -1.1622875 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.4288017  -0.23263265  0.369505   -0.13545164 -0.29080006 -0.43043798\n",
      "   0.388688    0.30721402 -0.5...814764   0.11623892 -0.6677647  -0.8773303\n",
      "   0.04038146  0.26205662  0.39179692 -0.42184103  0.45302597 -0.942907  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384ad790>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 2.07533389e-01 -1.04236722e-01 -5.32850623e-02  3.44054401e-02\n",
      "  -1.89045906e-01 -1.48772404e-01 -1.5...02  1.22030586e-01 -1.42824680e-01  2.12501049e-01\n",
      "   2.69666791e-01  3.80488634e-02 -1.02554858e-02  6.72077835e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 2.07533389e-01 -1.04236722e-01 -5.32850623e-02  3.44054401e-02\n",
      "  -1.89045906e-01 -1.48772404e-01 -1....2030586e-01 -1.42824680e-01  2.12501049e-01\n",
      "   2.69666791e-01  3.80488634e-02 -1.02554858e-02  6.72077835e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4384ad520>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 2.07533389e-01 -1.04236722e-01 -5.32850623e-02  3.44054401e-02\n",
      "  -1.89045906e-01 -1.48772404e-01 -1....2030586e-01 -1.42824680e-01  2.12501049e-01\n",
      "   2.69666791e-01  3.80488634e-02 -1.02554858e-02  6.72077835e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4384ad520>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4384add00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4384add00>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4384adfa0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4384adfa0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-11-1-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[ 2.533558  ,  0.10284929,  0.56878537,  0.8644734 ,\n",
      "         -2.0929503 , -0.4641377 , -0.75334585, -1.327074...4065331,  0.15319292, -0.9578949 ,\n",
      "          0.6002577 ,  0.39078507, -0.24764307, -0.8352551 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.2032, -0.4688, -0.1473,  0.3353, -0.0217,  0.4002, -0.0897,\n",
      "          -0.5746, -0.3004,  0.1546,  0.3030,..., -0.0554,  0.4433, -0.2220,\n",
      "           0.0989,  0.0620, -0.0359, -0.4052, -0.1328]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 7.5911254e-02, -7.2061486e-04, -1.1176537e+00, -9.0056792e-02,\n",
      "          1.1118522e+00, -1.0198215e+00,  1.4...8e-01, -7.8964317e-01,\n",
      "          2.9087359e-01,  8.3469190e-02, -2.6056619e-02,  1.2960631e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.1311, -0.1997, -0.0426,  0.1945, -0.0108,  0.1967, -0.0663,\n",
      "          -0.2904, -0.1028,  0.0747,  0.1617,..., -0.0306,  0.1904, -0.1036,\n",
      "           0.0415,  0.0305, -0.0218, -0.2015, -0.0560]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb438471190>\n",
      "model_     = LSTM(11, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0044, -0.0237, -0.0540, -0.0199, -0.0047,  0.1093, -0.0301,\n",
      "           0.0080,  0.0820, -0.0043, -0.1078,..., -0.0306,  0.1904, -0.1036,\n",
      "           0.0415,  0.0305, -0.0218, -0.2015, -0.0560]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 2.1865127 ,  0.31337848,  0.38970882,  0.42126322,\n",
      "         -0.64572626,  1.444343  , -0.23101202, -0.534954...   0.31825364,  0.61820734,  1.6225806 , -1.8457873 ,\n",
      "          0.39789352, -1.2334121 ,  1.0284009 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 2.1865127   0.31337848  0.38970882  0.42126322 -0.64572626\n",
      "    1.444343   -0.23101202 -0.5349543   ...102539  -0.09283371  0.31825364\n",
      "    0.61820734  1.6225806  -1.8457873   0.39789352 -1.2334121\n",
      "    1.0284009 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb438471190>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 2.1865127   0.31337848  0.38970882  0.42126322 -0.64572626\n",
      "    1.444343   -0.23101202 -0.5349543   1...2   1.3102539  -0.09283371  0.31825364\n",
      "    0.61820734  1.6225806  -1.8457873   0.39789352 -1.2334121\n",
      "    1.0284009 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb438471190>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 2.1865127   0.31337848  0.38970882  0.42126322 -0.64572626  1.444343\n",
      "  -0.23101202...1142   1.3102539  -0.09283371  0.31825364  0.61820734\n",
      "   1.6225806  -1.8457873   0.39789352 -1.2334121   1.0284009 ]]))\n",
      "        y          = needle.Tensor([[ 2.1865127   0.31337848  0.38970882  0.42126322 -0.64572626  1.444343\n",
      "  -0.23101202 -0.5349543   1.0864869  -0.128156   -0.3916407 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 2.1865127   0.31337848  0.38970882  0.42126322 -0.64572626  1.444343\n",
      "  -0.23101202 -0.5349543   1.0864869  -0.128156   -0.3916407 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb438471eb0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 2.1865127   0.31337848  0.38970882  0.42126322 -0.64572626  1.444343\n",
      "  -0.23101202 -0.5349543   1.0864869  -0.128156   -0.3916407 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.3533082  -1.1511164   0.23694447  0.39813703 -0.3441486   0.2863094\n",
      "   0.11638545 -0.20081519 -0.19...530295  0.4639999   0.77301586  0.19206563\n",
      "   0.6315102   0.6022933   0.1761033   0.66486394  0.57526577 -0.17748705]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb438471eb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 2.02220172e-01 -2.05702335e-01 -3.65487635e-02  9.95733142e-02\n",
      "   1.50623769e-01  2.60574758e-01  5.5...01 -1.33095533e-01 -5.64375371e-02  1.60563201e-01\n",
      "   2.64265418e-01 -2.06908703e-01 -2.07584351e-01 -1.43888235e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 2.02220172e-01 -2.05702335e-01 -3.65487635e-02  9.95733142e-02\n",
      "   1.50623769e-01  2.60574758e-01  5....3095533e-01 -5.64375371e-02  1.60563201e-01\n",
      "   2.64265418e-01 -2.06908703e-01 -2.07584351e-01 -1.43888235e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461f69b50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 2.02220172e-01 -2.05702335e-01 -3.65487635e-02  9.95733142e-02\n",
      "   1.50623769e-01  2.60574758e-01  5....3095533e-01 -5.64375371e-02  1.60563201e-01\n",
      "   2.64265418e-01 -2.06908703e-01 -2.07584351e-01 -1.43888235e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461f69b50>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461f69550>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461f69550>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461f698b0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461f698b0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-11-15-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 0.20669602, -0.32577434, -1.9969774 , -0.252378  ,\n",
      "          1.1532545 , -2.4191146 , -0.7070079 , -0.517884...32147  , -0.9263148 ,  1.9209554 ,\n",
      "          0.17435177, -0.5145817 ,  0.07157169,  2.1755342 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 1.2221e-01, -4.8687e-01,  4.9964e-01, -6.4742e-01,  3.1982e-01,\n",
      "           1.1053e-01, -1.2319e-01,  4.5854...1,  9.6388e-02,  5.2864e-01, -1.5038e-01,  1.6947e-01,\n",
      "          -2.5315e-02, -1.5256e-01]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.90796906,  0.8391592 ,  0.03392147,  1.9355965 ,\n",
      "          0.23676649,  0.08801596,  0.63939905, -1.204805...703263 , -0.17330897,  1.7611836 ,\n",
      "         -0.13088052, -1.2756261 ,  1.9856431 , -0.83453816]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 5.2816e-02, -3.1325e-01,  1.4836e-01, -3.3291e-01,  1.3659e-01,\n",
      "           6.9580e-02, -6.7639e-02,  2.2321...1,  4.1304e-02,  3.0474e-01, -7.5994e-02,  1.0587e-01,\n",
      "          -1.7068e-02, -4.0982e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb450cb0f10>\n",
      "model_     = LSTM(11, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 5.2816e-02, -3.1325e-01,  1.4836e-01, -3.3291e-01,  1.3659e-01,\n",
      "           6.9580e-02, -6.7639e-02,  2.2321...1,  4.1304e-02,  3.0474e-01, -7.5994e-02,  1.0587e-01,\n",
      "          -1.7068e-02, -4.0982e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.80460554, -0.33256394,  2.0072865 ,  1.6343371 ,\n",
      "          0.14786856, -1.7610824 , -0.7669516 ,  0.554694...   1.6703132 ,  0.1820129 , -0.18060026, -0.21798967,\n",
      "          0.09003441,  0.11570954, -0.30494827]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.80460554 -0.33256394  2.0072865   1.6343371   0.14786856\n",
      "   -1.7610824  -0.7669516   0.554694    ...43577    0.55331045  1.6703132\n",
      "    0.1820129  -0.18060026 -0.21798967  0.09003441  0.11570954\n",
      "   -0.30494827]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450cb0f10>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.80460554 -0.33256394  2.0072865   1.6343371   0.14786856\n",
      "   -1.7610824  -0.7669516   0.554694    0...14 -2.143577    0.55331045  1.6703132\n",
      "    0.1820129  -0.18060026 -0.21798967  0.09003441  0.11570954\n",
      "   -0.30494827]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450cb0f10>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.80460554 -0.33256394  2.0072865   1.6343371   0.14786856 -1.7610824\n",
      "  -0.7669516...74514 -2.143577    0.55331045  1.6703132   0.1820129\n",
      "  -0.18060026 -0.21798967  0.09003441  0.11570954 -0.30494827]]),)\n",
      "        y          = needle.Tensor([[-0.80460554 -0.33256394  2.0072865   1.6343371   0.14786856 -1.7610824\n",
      "  -0.7669516   0.554694    0.44...4474514 -2.143577    0.55331045  1.6703132   0.1820129\n",
      "  -0.18060026 -0.21798967  0.09003441  0.11570954 -0.30494827]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.80460554 -0.33256394  2.0072865   1.6343371   0.14786856 -1.7610824\n",
      "  -0.7669516   0.554694    0.4...77    0.55331045  1.6703132   0.1820129\n",
      "  -0.18060026 -0.21798967  0.09003441  0.11570954 -0.30494827]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450cb0820>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.80460554 -0.33256394  2.0072865   1.6343371   0.14786856 -1.7610824\n",
      "  -0.7669516   0.554694    0.44...4474514 -2.143577    0.55331045  1.6703132   0.1820129\n",
      "  -0.18060026 -0.21798967  0.09003441  0.11570954 -0.30494827]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-4.68681306e-01  3.35541159e-01  1.16951287e+00  1.02565372e+00\n",
      "   3.11196953e-01  7.09811211e-01  1.6...01 -3.50835204e-01 -3.60276401e-01  3.94978821e-01\n",
      "   2.08688498e-01  4.30981040e-01  5.36499619e-01 -9.68370914e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450cb0820>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-1.90007865e-01  1.92978978e-01  1.10354245e-01 -5.05564064e-02\n",
      "   8.39103758e-02  7.90340602e-02 -1.0...01 -2.24860013e-01  1.02731168e-01 -1.36081085e-01\n",
      "   1.46322250e-02 -8.65120143e-02  2.60137856e-01 -2.36282840e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-1.90007865e-01  1.92978978e-01  1.10354245e-01 -5.05564064e-02\n",
      "   8.39103758e-02  7.90340602e-02 -1....4860013e-01  1.02731168e-01 -1.36081085e-01\n",
      "   1.46322250e-02 -8.65120143e-02  2.60137856e-01 -2.36282840e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450cb0bb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-1.90007865e-01  1.92978978e-01  1.10354245e-01 -5.05564064e-02\n",
      "   8.39103758e-02  7.90340602e-02 -1....4860013e-01  1.02731168e-01 -1.36081085e-01\n",
      "   1.46322250e-02 -8.65120143e-02  2.60137856e-01 -2.36282840e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450cb0bb0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450cb0c70>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450cb0c70>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb450cb0940>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb450cb0940>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-True-12-11-15-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 2.904661  ,  0.9362906 ,  1.6881523 , -0.3523972 ,\n",
      "          0.14421776, -0.629654  , -0.42021942,  0.058128...167347 ,  1.1149985 ,  1.4269723 ,\n",
      "         -0.8831134 ,  0.0692445 , -0.86987805, -0.58036894]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-2.4007e-01,  2.7047e-01, -7.9047e-02, -1.1675e-01,  1.1696e-01,\n",
      "           1.7563e-01, -2.9907e-01, -6.8482...1, -5.9917e-02, -4.4322e-01,  1.2807e-01,  3.5989e-01,\n",
      "          -2.0927e-01,  4.2216e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-2.76303351e-01,  1.38887480e-01, -6.61411881e-02,\n",
      "         -4.35695350e-01, -1.69074610e-02, -7.69681096e-01..., -4.65466499e-01,  3.72427911e-01,\n",
      "          1.54279117e-02,  1.01268816e+00, -6.39996529e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-1.0099e-01,  1.3041e-01, -4.2036e-02, -5.8579e-02,  3.5542e-02,\n",
      "           6.8501e-02, -1.2506e-01, -3.8722...2, -3.3809e-02, -1.3482e-01,  5.1526e-02,  1.5969e-01,\n",
      "          -1.2734e-01,  1.6464e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb471297a30>\n",
      "model_     = LSTM(11, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0022,  0.0854,  0.1216,  ..., -0.2375, -0.0016, -0.0458],\n",
      "         [ 0.0320,  0.0876, -0.0269,  ..., -0.0...00, -0.0610],\n",
      "         [-0.1395, -0.0411, -0.3168,  ...,  0.1597, -0.1273,  0.0165]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 1.59434170e-01, -4.98135597e-01,  1.03195226e+00, ...,\n",
      "         -1.65842041e-01,  1.03277230e+00, -1.0574585...40166157e-01, -1.29355419e+00, ...,\n",
      "         -4.00988787e-01, -4.72437978e-01, -9.86831486e-01]]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.59434170e-01 -4.98135597e-01  1.03195226e+00 ... -1.65842041e-01\n",
      "    1.03277230e+00 -1.05745852e+...2]\n",
      "  [-9.22170758e-01  2.40166157e-01 -1.29355419e+00 ... -4.00988787e-01\n",
      "   -4.72437978e-01 -9.86831486e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471297a30>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 1.59434170e-01 -4.98135597e-01  1.03195226e+00 ... -1.65842041e-01\n",
      "    1.03277230e+00 -1.05745852e+0...7966e-02]\n",
      "  [-9.22170758e-01  2.40166157e-01 -1.29355419e+00 ... -4.00988787e-01\n",
      "   -4.72437978e-01 -9.86831486e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471297a30>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.15943417 -0.4981356   1.0319523  -1.6447489   0.60087717  0.00816715\n",
      "  -0.904182...16616 -1.2935542   1.464737   -1.1736248   0.72278076\n",
      "   0.5955779  -0.09109665 -0.4009888  -0.47243798 -0.9868315 ]]))\n",
      "        y          = needle.Tensor([[ 0.15943417 -0.4981356   1.0319523  -1.6447489   0.60087717  0.00816715\n",
      "  -0.90418255 -0.90006137 -0.1...2344011   0.53892076  1.2283354   0.25020155 -0.476295\n",
      "   0.6123088   1.2195001   0.257651   -0.30146036  0.43745568]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.15943417 -0.4981356   1.0319523  -1.6447489   0.60087717  0.00816715\n",
      "  -0.90418255 -0.90006137 -0....92076  1.2283354   0.25020155 -0.476295\n",
      "   0.6123088   1.2195001   0.257651   -0.30146036  0.43745568]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4712978b0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.15943417 -0.4981356   1.0319523  -1.6447489   0.60087717  0.00816715\n",
      "  -0.90418255 -0.90006137 -0.1...2344011   0.53892076  1.2283354   0.25020155 -0.476295\n",
      "   0.6123088   1.2195001   0.257651   -0.30146036  0.43745568]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.04624832e-01  1.00389743e+00  2.09297463e-01 -1.12720765e-01\n",
      "   8.77995074e-01  7.39758134e-01  4.2...01 -3.00116569e-01 -4.67131704e-01  2.89990455e-01\n",
      "   3.88467193e-01  6.78991377e-02  2.86051054e-02 -3.54301006e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4712978b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.02362263  0.2816791   0.19127971  0.09732923  0.24499923  0.00204414\n",
      "   0.02261752 -0.2025559   0.0...51546   0.2698378   0.2820894  -0.11165519\n",
      "   0.09255815 -0.03375116 -0.24941114 -0.21966106 -0.15783583  0.01189199]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.02362263  0.2816791   0.19127971  0.09732923  0.24499923  0.00204414\n",
      "   0.02261752 -0.2025559   0.... 0.2698378   0.2820894  -0.11165519\n",
      "   0.09255815 -0.03375116 -0.24941114 -0.21966106 -0.15783583  0.01189199]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4720801c0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.02362263  0.2816791   0.19127971  0.09732923  0.24499923  0.00204414\n",
      "   0.02261752 -0.2025559   0.... 0.2698378   0.2820894  -0.11165519\n",
      "   0.09255815 -0.03375116 -0.24941114 -0.21966106 -0.15783583  0.01189199]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4720801c0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb472080b50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb472080b50>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb472080af0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb472080af0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-True-12-11-15-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 0.25585788,  0.193745  ,  0.5494862 , -0.70038134,\n",
      "         -2.6772115 ,  1.1665173 , -0.09712072,  1.140168...239523 ,  0.9659616 , -0.9278697 ,\n",
      "         -1.5736167 , -1.5203835 ,  1.445837  , -0.23157747]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0192,  0.0372, -0.1229,  0.2371,  0.0076, -0.1267, -0.0236,\n",
      "           0.2972, -0.0783,  0.2137,  0.1338,..., -0.0469,  0.0868,  0.0320,\n",
      "           0.0525, -0.2054, -0.0224,  0.1346, -0.1140]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.34772614, -2.7587214 ,  1.0930494 , -0.5103978 ,\n",
      "          0.42791396,  1.1118017 ,  1.2091832 , -0.694475...831291 ,  1.9629549 ,  1.4768224 ,\n",
      "         -1.0067859 ,  0.18644223,  0.6857878 , -0.76200575]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0087,  0.0149, -0.0661,  0.1480,  0.0045, -0.0550, -0.0159,\n",
      "           0.2007, -0.0457,  0.0821,  0.0665,..., -0.0281,  0.0350,  0.0141,\n",
      "           0.0269, -0.0970, -0.0114,  0.0600, -0.0641]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb480bd3340>\n",
      "model_     = LSTM(11, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0134, -0.0587,  0.1220,  0.0631, -0.0033,  0.0427,  0.0253,\n",
      "           0.0203, -0.0944, -0.0110,  0.0538,..., -0.0281,  0.0350,  0.0141,\n",
      "           0.0269, -0.0970, -0.0114,  0.0600, -0.0641]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 1.45933051e-02, -3.04343611e-01, -9.95537400e-01,\n",
      "          4.75075036e-01, -8.38554442e-01,  8.28876421e-02...        -1.00513351e+00,  9.10439670e-01,  5.21122694e-01,\n",
      "          6.99059308e-01, -9.26087081e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.45933051e-02 -3.04343611e-01 -9.95537400e-01  4.75075036e-01\n",
      "   -8.38554442e-01  8.28876421e-02 -...83465e+00 -4.78908181e-01 -1.00513351e+00  9.10439670e-01\n",
      "    5.21122694e-01  6.99059308e-01 -9.26087081e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480bd3340>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 1.45933051e-02 -3.04343611e-01 -9.95537400e-01  4.75075036e-01\n",
      "   -8.38554442e-01  8.28876421e-02 -5... -1.00983465e+00 -4.78908181e-01 -1.00513351e+00  9.10439670e-01\n",
      "    5.21122694e-01  6.99059308e-01 -9.26087081e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480bd3340>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.45933051e-02 -3.04343611e-01 -9.95537400e-01  4.75075036e-01\n",
      "  -8.38554442e-01  ... -1.00983465e+00 -4.78908181e-01 -1.00513351e+00  9.10439670e-01\n",
      "   5.21122694e-01  6.99059308e-01 -9.26087081e-01]]),)\n",
      "        y          = needle.Tensor([[ 1.45933051e-02 -3.04343611e-01 -9.95537400e-01  4.75075036e-01\n",
      "  -8.38554442e-01  8.28876421e-02 -5.6...\n",
      "  -1.00983465e+00 -4.78908181e-01 -1.00513351e+00  9.10439670e-01\n",
      "   5.21122694e-01  6.99059308e-01 -9.26087081e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.45933051e-02 -3.04343611e-01 -9.95537400e-01  4.75075036e-01\n",
      "  -8.38554442e-01  8.28876421e-02 -5....+00 -4.78908181e-01 -1.00513351e+00  9.10439670e-01\n",
      "   5.21122694e-01  6.99059308e-01 -9.26087081e-01]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480bd3f70>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 1.45933051e-02 -3.04343611e-01 -9.95537400e-01  4.75075036e-01\n",
      "  -8.38554442e-01  8.28876421e-02 -5.6...\n",
      "  -1.00983465e+00 -4.78908181e-01 -1.00513351e+00  9.10439670e-01\n",
      "   5.21122694e-01  6.99059308e-01 -9.26087081e-01]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.75767356e-01  1.75000414e-01 -6.44537330e-01 -5.81787467e-01\n",
      "  -1.34988189e-01  4.35917735e-01 -8.6...01 -2.27153391e-01  2.66064882e-01  6.88821971e-01\n",
      "  -2.35453621e-02 -1.92349106e-01  6.28603220e-01  2.33850211e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480bd3f70>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-8.80967230e-02  2.41420329e-01 -2.79695272e-01 -3.74036133e-02\n",
      "  -1.68272808e-01 -1.66102022e-01  2.2...01 -1.71982363e-01 -2.86762685e-01 -1.10226259e-01\n",
      "  -2.38377407e-01  7.78773427e-02  2.34089553e-01 -1.61257908e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-8.80967230e-02  2.41420329e-01 -2.79695272e-01 -3.74036133e-02\n",
      "  -1.68272808e-01 -1.66102022e-01  2....1982363e-01 -2.86762685e-01 -1.10226259e-01\n",
      "  -2.38377407e-01  7.78773427e-02  2.34089553e-01 -1.61257908e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb430234400>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-8.80967230e-02  2.41420329e-01 -2.79695272e-01 -3.74036133e-02\n",
      "  -1.68272808e-01 -1.66102022e-01  2....1982363e-01 -2.86762685e-01 -1.10226259e-01\n",
      "  -2.38377407e-01  7.78773427e-02  2.34089553e-01 -1.61257908e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb430234400>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb430234610>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb430234610>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4302343a0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4302343a0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-True-12-11-15-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 6.42834783e-01, -2.76293099e-01, -6.87059462e-01,\n",
      "         -3.40153724e-01,  6.43860251e-02, -3.63378376e-01...,  8.57348680e-01, -1.27674258e+00,\n",
      "         -1.65342474e+00, -1.79545569e+00,  5.71224056e-02]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-2.3793e-01, -3.8619e-01, -1.1976e-01,  5.3239e-01, -3.6916e-01,\n",
      "          -6.9442e-01,  2.7998e-01, -1.7649...2, -1.5891e-02, -3.7463e-02,  6.0627e-02,  1.0452e-02,\n",
      "           3.9460e-01, -2.0011e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 1.14389729e+00,  9.67884958e-01, -5.01175940e-01,\n",
      "          7.13569164e-01, -4.52291816e-01, -2.31929469e+00..., -2.89070070e-01, -4.04748976e-01,\n",
      "          2.13941827e-01, -1.24651158e+00, -2.70069242e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-1.1539e-01, -1.8936e-01, -5.8595e-02,  2.3219e-01, -1.9671e-01,\n",
      "          -3.2653e-01,  8.0996e-02, -1.4715...2, -8.8419e-03, -2.1328e-02,  2.8014e-02,  5.0826e-03,\n",
      "           2.0656e-01, -1.1494e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4719b7a00>\n",
      "model_     = LSTM(11, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0175,  0.0402,  0.0816,  ..., -0.0051,  0.1065,  0.0089],\n",
      "         [ 0.0278, -0.0045,  0.0612,  ..., -0.0...99, -0.0155],\n",
      "         [ 0.0229,  0.0468,  0.1208,  ...,  0.0051,  0.2066, -0.0115]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-1.09946907e+00,  2.31474191e-01, -6.54915214e-01, ...,\n",
      "         -1.87046845e-02, -2.08823204e+00,  6.8339604...66062975e-01, -9.47013199e-01, ...,\n",
      "         -2.04718232e-01, -4.07145500e-01,  3.04621696e-01]]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.09946907e+00  2.31474191e-01 -6.54915214e-01 ... -1.87046845e-02\n",
      "   -2.08823204e+00  6.83396041e-...1]\n",
      "  [-6.25332534e-01  7.66062975e-01 -9.47013199e-01 ... -2.04718232e-01\n",
      "   -4.07145500e-01  3.04621696e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4719b7a00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-1.09946907e+00  2.31474191e-01 -6.54915214e-01 ... -1.87046845e-02\n",
      "   -2.08823204e+00  6.83396041e-0...5078e-01]\n",
      "  [-6.25332534e-01  7.66062975e-01 -9.47013199e-01 ... -2.04718232e-01\n",
      "   -4.07145500e-01  3.04621696e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4719b7a00>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.09946907e+00  2.31474191e-01 -6.54915214e-01  3.27154994e-01\n",
      "   1.81018457e-01  ...07e+00\n",
      "  -1.2454954e+00  9.8163754e-01 -3.7311769e-01 -4.6655536e-01\n",
      "  -2.0471823e-01 -4.0714550e-01  3.0462170e-01]]))\n",
      "        y          = needle.Tensor([[-1.09946907e+00  2.31474191e-01 -6.54915214e-01  3.27154994e-01\n",
      "   1.81018457e-01  5.75516336e-02 -8.2...\n",
      "   9.30525959e-01  8.57925892e-01 -1.65828332e-01  5.27915657e-01\n",
      "   1.40784132e+00 -1.17570505e-01  1.44466150e+00]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.09946907e+00  2.31474191e-01 -6.54915214e-01  3.27154994e-01\n",
      "   1.81018457e-01  5.75516336e-02 -8....-01  8.57925892e-01 -1.65828332e-01  5.27915657e-01\n",
      "   1.40784132e+00 -1.17570505e-01  1.44466150e+00]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4719b7940>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.09946907e+00  2.31474191e-01 -6.54915214e-01  3.27154994e-01\n",
      "   1.81018457e-01  5.75516336e-02 -8.2...\n",
      "   9.30525959e-01  8.57925892e-01 -1.65828332e-01  5.27915657e-01\n",
      "   1.40784132e+00 -1.17570505e-01  1.44466150e+00]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.00570213  0.2133906   0.35060143 -0.21650858  0.94498044  0.0580695\n",
      "  -0.8014092  -0.47604725  0.36...90869  -0.5921117   0.23018134  0.17979938\n",
      "   0.01432513 -0.13972038  0.45010135 -0.20526257 -0.5639484   0.63855535]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4719b7940>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 2.67140687e-01 -1.18054196e-01  2.47709513e-01  1.29617363e-01\n",
      "  -1.99818671e-01  1.37197226e-01 -1.4...01  2.00222433e-02  1.22054815e-02  1.81265950e-01\n",
      "   7.53581822e-02  1.51086897e-01  9.47007537e-02 -2.29570016e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 2.67140687e-01 -1.18054196e-01  2.47709513e-01  1.29617363e-01\n",
      "  -1.99818671e-01  1.37197226e-01 -1....0222433e-02  1.22054815e-02  1.81265950e-01\n",
      "   7.53581822e-02  1.51086897e-01  9.47007537e-02 -2.29570016e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461fa6580>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 2.67140687e-01 -1.18054196e-01  2.47709513e-01  1.29617363e-01\n",
      "  -1.99818671e-01  1.37197226e-01 -1....0222433e-02  1.22054815e-02  1.81265950e-01\n",
      "   7.53581822e-02  1.51086897e-01  9.47007537e-02 -2.29570016e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461fa6580>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461fa6940>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461fa6940>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461fa6eb0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461fa6eb0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-False-1-1-1-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[0.87735057]]], dtype=float32)\n",
      "c_         = tensor([[[0.1696]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.25448614]]], dtype=float32)\n",
      "h_         = tensor([[[0.0799]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb462025f70>\n",
      "model_     = LSTM(1, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[0.0799]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[0.5885363]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[0.5885363]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb462025f70>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[0.5885363]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb462025f70>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.5885363]]),)\n",
      "        y          = needle.Tensor([[0.5885363]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.5885363]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462025eb0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[0.5885363]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.15447854 -0.4970858   0.326092   -0.09748649]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462025eb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.11845672 -0.7561109  -0.08533072  0.53995776]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.11845672 -0.7561109  -0.08533072  0.53995776]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb462025730>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.11845672 -0.7561109  -0.08533072  0.53995776]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb462025730>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb462025e80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb462025e80>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb462025070>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb462025070>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-1-1-1-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[0.78429383]]], dtype=float32)\n",
      "c_         = tensor([[[0.2625]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[1.0529175]]], dtype=float32)\n",
      "h_         = tensor([[[0.1952]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb43837af10>\n",
      "model_     = LSTM(1, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.1247]],\n",
      "\n",
      "        [[-0.1378]],\n",
      "\n",
      "        [[-0.0567]],\n",
      "\n",
      "        [[-0.0058]],\n",
      "\n",
      "        [[-0.0772]],\n",
      "\n",
      "        ...7]],\n",
      "\n",
      "        [[ 0.0760]],\n",
      "\n",
      "        [[ 0.1348]],\n",
      "\n",
      "        [[ 0.1820]],\n",
      "\n",
      "        [[ 0.1952]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-1.1724881 ]],\n",
      "\n",
      "       [[ 0.01352832]],\n",
      "\n",
      "       [[ 0.18830675]],\n",
      "\n",
      "       [[ 0.15579529]],\n",
      "\n",
      "       [[-0.436952...]],\n",
      "\n",
      "       [[ 0.8613759 ]],\n",
      "\n",
      "       [[ 0.59847647]],\n",
      "\n",
      "       [[ 1.771166  ]],\n",
      "\n",
      "       [[ 1.3778267 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.1724881 ]]\n",
      "\n",
      " [[ 0.01352832]]\n",
      "\n",
      " [[ 0.18830675]]\n",
      "\n",
      " [[ 0.15579529]]\n",
      "\n",
      " [[-0.4369523 ]]\n",
      "\n",
      " [[-0.561345 ...]]\n",
      "\n",
      " [[ 0.22132297]]\n",
      "\n",
      " [[-0.00954335]]\n",
      "\n",
      " [[ 0.8613759 ]]\n",
      "\n",
      " [[ 0.59847647]]\n",
      "\n",
      " [[ 1.771166  ]]\n",
      "\n",
      " [[ 1.3778267 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb43837af10>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-1.1724881 ]]\n",
      "\n",
      " [[ 0.01352832]]\n",
      "\n",
      " [[ 0.18830675]]\n",
      "\n",
      " [[ 0.15579529]]\n",
      "\n",
      " [[-0.4369523 ]]\n",
      "\n",
      " [[-0.561345  ...454041 ]]\n",
      "\n",
      " [[ 0.22132297]]\n",
      "\n",
      " [[-0.00954335]]\n",
      "\n",
      " [[ 0.8613759 ]]\n",
      "\n",
      " [[ 0.59847647]]\n",
      "\n",
      " [[ 1.771166  ]]\n",
      "\n",
      " [[ 1.3778267 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb43837af10>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.1724881]]), needle.Tensor([[0.01352832]]), needle.Tensor([[0.18830675]]), needle...needle.Tensor([[0.8613759]]), needle.Tensor([[0.59847647]]), needle.Tensor([[1.771166]]), needle.Tensor([[1.3778267]]))\n",
      "        y          = needle.Tensor([[-1.1724881]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.1724881]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb43837aaf0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.1724881]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.8152624   1.0724775  -0.8777784  -0.96952564]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb43837aaf0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.3672018  -0.43102467  0.61012626  0.09425664]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.3672018  -0.43102467  0.61012626  0.09425664]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4811dda30>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.3672018  -0.43102467  0.61012626  0.09425664]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4811dda30>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4811dd7f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4811dd7f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4811dd370>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4811dd370>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________ test_lstm[cpu-False-False-1-1-1-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[0.8953948]],\n",
      "\n",
      "       [[1.066281 ]]], dtype=float32)\n",
      "c_         = tensor([[[0.1278]],\n",
      "\n",
      "        [[0.0110]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.21909134]],\n",
      "\n",
      "       [[-0.67220604]]], dtype=float32)\n",
      "h_         = tensor([[[0.0579]],\n",
      "\n",
      "        [[0.0055]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb450aeeee0>\n",
      "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[0.0055]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[0.59658897]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[0.59658897]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450aeeee0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[0.59658897]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450aeeee0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.59658897]]),)\n",
      "        y          = needle.Tensor([[0.59658897]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.59658897]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450aeedf0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[0.59658897]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.46982777  0.50364256  0.3452859  -0.17940223]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450aeedf0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.1163156   0.19697702  0.1271553  -0.17761171]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.1163156   0.19697702  0.1271553  -0.17761171]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480da0e20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.1163156   0.19697702  0.1271553  -0.17761171]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480da0e20>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480da0b50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480da0b50>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480da0a60>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480da0a60>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-1-1-2-13] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-1.0071748]],\n",
      "\n",
      "       [[-1.347147 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.2198]],\n",
      "\n",
      "        [[ 0.0160]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[0.6690134]],\n",
      "\n",
      "       [[0.9640846]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0840]],\n",
      "\n",
      "        [[ 0.0080]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4384af9d0>\n",
      "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0079]],\n",
      "\n",
      "        [[-0.0287]],\n",
      "\n",
      "        [[-0.0388]],\n",
      "\n",
      "        [[-0.0588]],\n",
      "\n",
      "        [[-0.0313]],\n",
      "\n",
      "        ...0]],\n",
      "\n",
      "        [[-0.0068]],\n",
      "\n",
      "        [[-0.0113]],\n",
      "\n",
      "        [[-0.0063]],\n",
      "\n",
      "        [[ 0.0080]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.3169543 ]],\n",
      "\n",
      "       [[-0.9931002 ]],\n",
      "\n",
      "       [[-0.7559459 ]],\n",
      "\n",
      "       [[-2.5979588 ]],\n",
      "\n",
      "       [[ 0.283399...]],\n",
      "\n",
      "       [[-1.4380089 ]],\n",
      "\n",
      "       [[-0.14117736]],\n",
      "\n",
      "       [[ 0.07462013]],\n",
      "\n",
      "       [[ 0.6048838 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.3169543 ]]\n",
      "\n",
      " [[-0.9931002 ]]\n",
      "\n",
      " [[-0.7559459 ]]\n",
      "\n",
      " [[-2.5979588 ]]\n",
      "\n",
      " [[ 0.28339928]]\n",
      "\n",
      " [[ 0.9299822...]]\n",
      "\n",
      " [[ 0.3623904 ]]\n",
      "\n",
      " [[ 0.9419312 ]]\n",
      "\n",
      " [[-1.4380089 ]]\n",
      "\n",
      " [[-0.14117736]]\n",
      "\n",
      " [[ 0.07462013]]\n",
      "\n",
      " [[ 0.6048838 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4384af9d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.3169543 ]]\n",
      "\n",
      " [[-0.9931002 ]]\n",
      "\n",
      " [[-0.7559459 ]]\n",
      "\n",
      " [[-2.5979588 ]]\n",
      "\n",
      " [[ 0.28339928]]\n",
      "\n",
      " [[ 0.92998224...2434516]]\n",
      "\n",
      " [[ 0.3623904 ]]\n",
      "\n",
      " [[ 0.9419312 ]]\n",
      "\n",
      " [[-1.4380089 ]]\n",
      "\n",
      " [[-0.14117736]]\n",
      "\n",
      " [[ 0.07462013]]\n",
      "\n",
      " [[ 0.6048838 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4384af9d0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.3169543]]), needle.Tensor([[-0.9931002]]), needle.Tensor([[-0.7559459]]), needle...le.Tensor([[-1.4380089]]), needle.Tensor([[-0.14117736]]), needle.Tensor([[0.07462013]]), needle.Tensor([[0.6048838]]))\n",
      "        y          = needle.Tensor([[-0.3169543]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.3169543]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384af5e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.3169543]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.06491425 -0.2455659   0.23575132  0.23896052]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384af5e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.29515076  0.73938525 -0.69928634  0.59865415]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.29515076  0.73938525 -0.69928634  0.59865415]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450d927c0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.29515076  0.73938525 -0.69928634  0.59865415]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450d927c0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450d92070>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450d92070>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb450d92e20>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb450d92e20>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-1-15-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-0.7800061 ],\n",
      "        [-1.3960326 ],\n",
      "        [-0.43641806],\n",
      "        [ 1.0622516 ],\n",
      "        [ 0.65320224],\n",
      "   ...588093  ],\n",
      "        [ 0.96277994],\n",
      "        [-1.6911156 ],\n",
      "        [ 2.3773904 ],\n",
      "        [-0.76612926]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0036],\n",
      "         [-0.0043],\n",
      "         [ 0.0116],\n",
      "         [ 0.0037],\n",
      "         [ 0.0060],\n",
      "         [ 0.0001]... [-0.0012],\n",
      "         [ 0.0129],\n",
      "         [-0.0139],\n",
      "         [ 0.0219],\n",
      "         [-0.0115]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-1.5160147 ],\n",
      "        [-0.400086  ],\n",
      "        [ 0.59929895],\n",
      "        [ 0.06262992],\n",
      "        [ 1.7144219 ],\n",
      "   ...02394632],\n",
      "        [-0.06301381],\n",
      "        [-0.11187159],\n",
      "        [ 2.2219465 ],\n",
      "        [ 0.3256772 ]]], dtype=float32)\n",
      "h_         = tensor([[[-1.8064e-03],\n",
      "         [-2.1889e-03],\n",
      "         [ 5.5983e-03],\n",
      "         [ 1.8448e-03],\n",
      "         [ 2.9657e-03]...     [ 6.1998e-03],\n",
      "         [-7.2363e-03],\n",
      "         [ 1.0160e-02],\n",
      "         [-5.9467e-03]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb458a591c0>\n",
      "model_     = LSTM(1, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-1.8064e-03],\n",
      "         [-2.1889e-03],\n",
      "         [ 5.5983e-03],\n",
      "         [ 1.8448e-03],\n",
      "         [ 2.9657e-03]...     [ 6.1998e-03],\n",
      "         [-7.2363e-03],\n",
      "         [ 1.0160e-02],\n",
      "         [-5.9467e-03]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.18365292],\n",
      "        [ 0.2217292 ],\n",
      "        [-0.6155775 ],\n",
      "        [-0.19454806],\n",
      "        [-0.3165295 ],\n",
      "   ...06008944],\n",
      "        [-0.6866215 ],\n",
      "        [ 0.7007647 ],\n",
      "        [-1.1840016 ],\n",
      "        [ 0.58225113]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.18365292]\n",
      "  [ 0.2217292 ]\n",
      "  [-0.6155775 ]\n",
      "  [-0.19454806]\n",
      "  [-0.3165295 ]\n",
      "  [-0.00652345]\n",
      "  [ 0.0...[ 1.7167046 ]\n",
      "  [ 1.0775405 ]\n",
      "  [ 0.06008944]\n",
      "  [-0.6866215 ]\n",
      "  [ 0.7007647 ]\n",
      "  [-1.1840016 ]\n",
      "  [ 0.58225113]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458a591c0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.18365292]\n",
      "  [ 0.2217292 ]\n",
      "  [-0.6155775 ]\n",
      "  [-0.19454806]\n",
      "  [-0.3165295 ]\n",
      "  [-0.00652345]\n",
      "  [ 0.01...4  ]\n",
      "  [ 1.7167046 ]\n",
      "  [ 1.0775405 ]\n",
      "  [ 0.06008944]\n",
      "  [-0.6866215 ]\n",
      "  [ 0.7007647 ]\n",
      "  [-1.1840016 ]\n",
      "  [ 0.58225113]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458a591c0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.18365292]\n",
      " [ 0.2217292 ]\n",
      " [-0.6155775 ]\n",
      " [-0.19454806]\n",
      " [-0.3165295 ]\n",
      " [-0.00652....549334  ]\n",
      " [ 1.7167046 ]\n",
      " [ 1.0775405 ]\n",
      " [ 0.06008944]\n",
      " [-0.6866215 ]\n",
      " [ 0.7007647 ]\n",
      " [-1.1840016 ]\n",
      " [ 0.58225113]]),)\n",
      "        y          = needle.Tensor([[ 0.18365292]\n",
      " [ 0.2217292 ]\n",
      " [-0.6155775 ]\n",
      " [-0.19454806]\n",
      " [-0.3165295 ]\n",
      " [-0.00652345]\n",
      " [ 0.01575042]\n",
      " [ 1.549334  ]\n",
      " [ 1.7167046 ]\n",
      " [ 1.0775405 ]\n",
      " [ 0.06008944]\n",
      " [-0.6866215 ]\n",
      " [ 0.7007647 ]\n",
      " [-1.1840016 ]\n",
      " [ 0.58225113]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.18365292]\n",
      " [ 0.2217292 ]\n",
      " [-0.6155775 ]\n",
      " [-0.19454806]\n",
      " [-0.3165295 ]\n",
      " [-0.00652345]\n",
      " [ 0.01575042... 1.7167046 ]\n",
      " [ 1.0775405 ]\n",
      " [ 0.06008944]\n",
      " [-0.6866215 ]\n",
      " [ 0.7007647 ]\n",
      " [-1.1840016 ]\n",
      " [ 0.58225113]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458a59400>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.18365292]\n",
      " [ 0.2217292 ]\n",
      " [-0.6155775 ]\n",
      " [-0.19454806]\n",
      " [-0.3165295 ]\n",
      " [-0.00652345]\n",
      " [ 0.01575042]\n",
      " [ 1.549334  ]\n",
      " [ 1.7167046 ]\n",
      " [ 1.0775405 ]\n",
      " [ 0.06008944]\n",
      " [-0.6866215 ]\n",
      " [ 0.7007647 ]\n",
      " [-1.1840016 ]\n",
      " [ 0.58225113]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.3796484e-02 -1.8227127e-01 -7.0991553e-03  2.1748552e-02]\n",
      " [ 1.6656874e-02 -2.2006109e-01 -8.571004...5270e-02  1.1750941e+00  4.5767915e-02 -1.4021187e-01]\n",
      " [ 4.3740217e-02 -5.7787073e-01 -2.2507081e-02  6.8951361e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458a59400>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.43688822  0.06368971  0.5792446   0.97931635]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.43688822  0.06368971  0.5792446   0.97931635]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb458a597f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.43688822  0.06368971  0.5792446   0.97931635]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb458a597f0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458a59d90>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458a59d90>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb458a597c0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb458a597c0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-1-15-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-0.43715093],\n",
      "        [-0.5639763 ],\n",
      "        [-0.75772804],\n",
      "        [-0.5333163 ],\n",
      "        [-1.1256431 ],\n",
      "   ...8060735 ],\n",
      "        [-1.7129481 ],\n",
      "        [ 0.14013578],\n",
      "        [-1.0808418 ],\n",
      "        [-0.87564415]]], dtype=float32)\n",
      "c_         = tensor([[[-0.3061],\n",
      "         [-0.4887],\n",
      "         [-0.3625],\n",
      "         [ 0.0587],\n",
      "         [ 0.4360],\n",
      "         [ 0.2716]... [-0.0563],\n",
      "         [-0.1106],\n",
      "         [-0.0117],\n",
      "         [-0.1173],\n",
      "         [ 0.1388]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.17665814],\n",
      "        [ 0.20219804],\n",
      "        [ 0.18772513],\n",
      "        [ 1.7783873 ],\n",
      "        [-1.8474923 ],\n",
      "   ...16674505],\n",
      "        [-0.78559613],\n",
      "        [ 1.1358993 ],\n",
      "        [ 0.6421513 ],\n",
      "        [-1.1655086 ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.1104],\n",
      "         [-0.1449],\n",
      "         [-0.1201],\n",
      "         [ 0.0363],\n",
      "         [ 0.2964],\n",
      "         [ 0.1513]... [-0.0314],\n",
      "         [-0.0486],\n",
      "         [-0.0068],\n",
      "         [-0.0488],\n",
      "         [ 0.0970]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb480ec8a30>\n",
      "model_     = LSTM(1, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 6.9423e-02],\n",
      "         [-7.6314e-02],\n",
      "         [-1.0141e-01],\n",
      "         [-8.0160e-02],\n",
      "         [ 1.3999e-01]...     [-4.8564e-02],\n",
      "         [-6.7932e-03],\n",
      "         [-4.8847e-02],\n",
      "         [ 9.6975e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.27827108],\n",
      "        [-0.42537045],\n",
      "        [-0.70994014],\n",
      "        [-2.0091424 ],\n",
      "        [ 0.5460731 ],\n",
      "   ...45524794],\n",
      "        [-0.45611447],\n",
      "        [ 0.6213265 ],\n",
      "        [-0.86317396],\n",
      "        [ 1.4970853 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.27827108]\n",
      "  [-0.42537045]\n",
      "  [-0.70994014]\n",
      "  [-2.0091424 ]\n",
      "  [ 0.5460731 ]\n",
      "  [ 0.5937275 ]\n",
      "  [ 0.4...[-0.77399224]\n",
      "  [ 0.8514263 ]\n",
      "  [ 0.45524794]\n",
      "  [-0.45611447]\n",
      "  [ 0.6213265 ]\n",
      "  [-0.86317396]\n",
      "  [ 1.4970853 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480ec8a30>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.27827108]\n",
      "  [-0.42537045]\n",
      "  [-0.70994014]\n",
      "  [-2.0091424 ]\n",
      "  [ 0.5460731 ]\n",
      "  [ 0.5937275 ]\n",
      "  [ 0.41...127]\n",
      "  [-0.77399224]\n",
      "  [ 0.8514263 ]\n",
      "  [ 0.45524794]\n",
      "  [-0.45611447]\n",
      "  [ 0.6213265 ]\n",
      "  [-0.86317396]\n",
      "  [ 1.4970853 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480ec8a30>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.27827108]\n",
      " [-0.42537045]\n",
      " [-0.70994014]\n",
      " [-2.0091424 ]\n",
      " [ 0.5460731 ]\n",
      " [ 0.59372...0.58494127]\n",
      " [-0.77399224]\n",
      " [ 0.8514263 ]\n",
      " [ 0.45524794]\n",
      " [-0.45611447]\n",
      " [ 0.6213265 ]\n",
      " [-0.86317396]\n",
      " [ 1.4970853 ]]))\n",
      "        y          = needle.Tensor([[ 0.27827108]\n",
      " [-0.42537045]\n",
      " [-0.70994014]\n",
      " [-2.0091424 ]\n",
      " [ 0.5460731 ]\n",
      " [ 0.5937275 ]\n",
      " [ 0.41967902]\n",
      " [ 0.3884385 ]\n",
      " [-0.3543275 ]\n",
      " [ 0.2971522 ]\n",
      " [ 1.5950971 ]\n",
      " [-1.2258148 ]\n",
      " [ 3.1168053 ]\n",
      " [ 2.0070856 ]\n",
      " [-0.2820085 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.27827108]\n",
      " [-0.42537045]\n",
      " [-0.70994014]\n",
      " [-2.0091424 ]\n",
      " [ 0.5460731 ]\n",
      " [ 0.5937275 ]\n",
      " [ 0.41967902...-0.3543275 ]\n",
      " [ 0.2971522 ]\n",
      " [ 1.5950971 ]\n",
      " [-1.2258148 ]\n",
      " [ 3.1168053 ]\n",
      " [ 2.0070856 ]\n",
      " [-0.2820085 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480ec8ac0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.27827108]\n",
      " [-0.42537045]\n",
      " [-0.70994014]\n",
      " [-2.0091424 ]\n",
      " [ 0.5460731 ]\n",
      " [ 0.5937275 ]\n",
      " [ 0.41967902]\n",
      " [ 0.3884385 ]\n",
      " [-0.3543275 ]\n",
      " [ 0.2971522 ]\n",
      " [ 1.5950971 ]\n",
      " [-1.2258148 ]\n",
      " [ 3.1168053 ]\n",
      " [ 2.0070856 ]\n",
      " [-0.2820085 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.05519336  0.20154153  0.25527412  0.17534737]\n",
      " [-0.08436962 -0.30808023 -0.39021686 -0.26803932]\n",
      " [...3   1.9639971 ]\n",
      " [ 0.39809313  1.4536585   1.8412154   1.2647278 ]\n",
      " [-0.05593466 -0.20424841 -0.25870267 -0.17770243]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480ec8ac0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.8141986  -0.7629794   0.46326184  0.5467292 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.8141986  -0.7629794   0.46326184  0.5467292 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461750cd0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.8141986  -0.7629794   0.46326184  0.5467292 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461750cd0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461750700>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461750700>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461750d30>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461750d30>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-1-15-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-0.9939409 ],\n",
      "        [ 0.7639601 ],\n",
      "        [-0.72583646],\n",
      "        [-0.77635527],\n",
      "        [ 0.14003502],\n",
      "   ...1153951 ],\n",
      "        [ 0.46215242],\n",
      "        [-1.0180676 ],\n",
      "        [-0.8696058 ],\n",
      "        [-0.8524559 ]]], dtype=float32)\n",
      "c_         = tensor([[[-2.3019e-02],\n",
      "         [ 4.2084e-02],\n",
      "         [-2.9501e-02],\n",
      "         [ 2.8084e-02],\n",
      "         [-1.6332e-02]...     [-9.3633e-05],\n",
      "         [ 3.5432e-05],\n",
      "         [-7.3383e-05],\n",
      "         [-2.8856e-05]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.57775086],\n",
      "        [-1.2822715 ],\n",
      "        [-0.11908696],\n",
      "        [ 0.15925029],\n",
      "        [-0.48548135],\n",
      "   ...38270712],\n",
      "        [-0.7088219 ],\n",
      "        [ 0.45369017],\n",
      "        [-2.779438  ],\n",
      "        [-0.8936102 ]]], dtype=float32)\n",
      "h_         = tensor([[[-1.2125e-02],\n",
      "         [ 1.9700e-02],\n",
      "         [-1.5877e-02],\n",
      "         [ 1.3411e-02],\n",
      "         [-8.4513e-03]...     [-4.6861e-05],\n",
      "         [ 1.7709e-05],\n",
      "         [-3.6719e-05],\n",
      "         [-1.4432e-05]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb430238fa0>\n",
      "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-2.5738e-05],\n",
      "         [ 4.1204e-05],\n",
      "         [-3.3763e-05],\n",
      "         [ 2.8134e-05],\n",
      "         [-1.7910e-05]...     [-4.6861e-05],\n",
      "         [ 1.7709e-05],\n",
      "         [-3.6719e-05],\n",
      "         [-1.4432e-05]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.8082686 ],\n",
      "        [-0.95397496],\n",
      "        [ 1.1576107 ],\n",
      "        [-0.67319876],\n",
      "        [ 0.52746737],\n",
      "   ...44688612],\n",
      "        [ 2.1740184 ],\n",
      "        [-0.43760732],\n",
      "        [ 1.3126229 ],\n",
      "        [ 0.41492158]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.8082686 ]\n",
      "  [-0.95397496]\n",
      "  [ 1.1576107 ]\n",
      "  [-0.67319876]\n",
      "  [ 0.52746737]\n",
      "  [-0.10705979]\n",
      "  [ 1.1...[-0.0540273 ]\n",
      "  [ 0.75595045]\n",
      "  [-0.44688612]\n",
      "  [ 2.1740184 ]\n",
      "  [-0.43760732]\n",
      "  [ 1.3126229 ]\n",
      "  [ 0.41492158]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb430238fa0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.8082686 ]\n",
      "  [-0.95397496]\n",
      "  [ 1.1576107 ]\n",
      "  [-0.67319876]\n",
      "  [ 0.52746737]\n",
      "  [-0.10705979]\n",
      "  [ 1.15...52 ]\n",
      "  [-0.0540273 ]\n",
      "  [ 0.75595045]\n",
      "  [-0.44688612]\n",
      "  [ 2.1740184 ]\n",
      "  [-0.43760732]\n",
      "  [ 1.3126229 ]\n",
      "  [ 0.41492158]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb430238fa0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.8082686 ]\n",
      " [-0.95397496]\n",
      " [ 1.1576107 ]\n",
      " [-0.67319876]\n",
      " [ 0.52746737]\n",
      " [-0.10705....1175352 ]\n",
      " [-0.0540273 ]\n",
      " [ 0.75595045]\n",
      " [-0.44688612]\n",
      " [ 2.1740184 ]\n",
      " [-0.43760732]\n",
      " [ 1.3126229 ]\n",
      " [ 0.41492158]]),)\n",
      "        y          = needle.Tensor([[ 0.8082686 ]\n",
      " [-0.95397496]\n",
      " [ 1.1576107 ]\n",
      " [-0.67319876]\n",
      " [ 0.52746737]\n",
      " [-0.10705979]\n",
      " [ 1.1579454 ]\n",
      " [ 1.1175352 ]\n",
      " [-0.0540273 ]\n",
      " [ 0.75595045]\n",
      " [-0.44688612]\n",
      " [ 2.1740184 ]\n",
      " [-0.43760732]\n",
      " [ 1.3126229 ]\n",
      " [ 0.41492158]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.8082686 ]\n",
      " [-0.95397496]\n",
      " [ 1.1576107 ]\n",
      " [-0.67319876]\n",
      " [ 0.52746737]\n",
      " [-0.10705979]\n",
      " [ 1.1579454 ...-0.0540273 ]\n",
      " [ 0.75595045]\n",
      " [-0.44688612]\n",
      " [ 2.1740184 ]\n",
      " [-0.43760732]\n",
      " [ 1.3126229 ]\n",
      " [ 0.41492158]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4302384f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.8082686 ]\n",
      " [-0.95397496]\n",
      " [ 1.1576107 ]\n",
      " [-0.67319876]\n",
      " [ 0.52746737]\n",
      " [-0.10705979]\n",
      " [ 1.1579454 ]\n",
      " [ 1.1175352 ]\n",
      " [-0.0540273 ]\n",
      " [ 0.75595045]\n",
      " [-0.44688612]\n",
      " [ 2.1740184 ]\n",
      " [-0.43760732]\n",
      " [ 1.3126229 ]\n",
      " [ 0.41492158]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.40922773 -0.56357676 -0.05774289  0.10731088]\n",
      " [ 0.4829991   0.6651726   0.06815218 -0.12665579]\n",
      " [...76 -0.05809953]\n",
      " [-0.66458315 -0.91524494 -0.09377407  0.17427218]\n",
      " [-0.21007548 -0.28930995 -0.02964209  0.05508763]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4302384f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.0105803   0.78887796  0.71647537 -0.01172304]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.0105803   0.78887796  0.71647537 -0.01172304]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4588e0070>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.0105803   0.78887796  0.71647537 -0.01172304]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4588e0070>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4588e03a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4588e03a0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4588e0430>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4588e0430>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-1-15-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-0.3020587 ],\n",
      "        [-1.9187952 ],\n",
      "        [ 1.419051  ],\n",
      "        [ 0.2411215 ],\n",
      "        [ 0.02656752],\n",
      "   ...21189843],\n",
      "        [ 0.31007147],\n",
      "        [-2.0224981 ],\n",
      "        [-0.8510119 ],\n",
      "        [ 0.3966078 ]]], dtype=float32)\n",
      "c_         = tensor([[[ 2.4680e-01],\n",
      "         [-3.7366e-02],\n",
      "         [-4.5507e-02],\n",
      "         [-2.3584e-02],\n",
      "         [ 2.9583e-01]...     [-2.3331e-03],\n",
      "         [ 9.7021e-02],\n",
      "         [-3.0557e-02],\n",
      "         [ 9.2260e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.4048787 ],\n",
      "        [-0.7317495 ],\n",
      "        [ 0.33840644],\n",
      "        [ 1.2651623 ],\n",
      "        [-1.9106292 ],\n",
      "   ...79710734],\n",
      "        [ 0.61093163],\n",
      "        [-0.8700817 ],\n",
      "        [-0.9749998 ],\n",
      "        [-0.84286267]]], dtype=float32)\n",
      "h_         = tensor([[[ 1.6801e-01],\n",
      "         [-1.4783e-02],\n",
      "         [-2.5041e-02],\n",
      "         [-1.0482e-02],\n",
      "         [ 2.2341e-01]...     [-1.1693e-03],\n",
      "         [ 4.5740e-02],\n",
      "         [-1.5549e-02],\n",
      "         [ 4.3500e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4384afbb0>\n",
      "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 5.5022e-03],\n",
      "         [-7.1083e-03],\n",
      "         [-7.1697e-03],\n",
      "         [ 1.7177e-02],\n",
      "         [ 5.6577e-02]...     [-1.1693e-03],\n",
      "         [ 4.5740e-02],\n",
      "         [-1.5549e-02],\n",
      "         [ 4.3500e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.27810633],\n",
      "        [-1.3409295 ],\n",
      "        [-1.3094507 ],\n",
      "        [ 0.702908  ],\n",
      "        [ 1.754042  ],\n",
      "   ...21039478],\n",
      "        [-0.3190387 ],\n",
      "        [ 0.6253763 ],\n",
      "        [-0.6294947 ],\n",
      "        [ 1.2769275 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.27810633]\n",
      "  [-1.3409295 ]\n",
      "  [-1.3094507 ]\n",
      "  [ 0.702908  ]\n",
      "  [ 1.754042  ]\n",
      "  [ 1.3642248 ]\n",
      "  [-0.9...[ 0.22571923]\n",
      "  [-0.23935306]\n",
      "  [-0.21039478]\n",
      "  [-0.3190387 ]\n",
      "  [ 0.6253763 ]\n",
      "  [-0.6294947 ]\n",
      "  [ 1.2769275 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4384afbb0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.27810633]\n",
      "  [-1.3409295 ]\n",
      "  [-1.3094507 ]\n",
      "  [ 0.702908  ]\n",
      "  [ 1.754042  ]\n",
      "  [ 1.3642248 ]\n",
      "  [-0.98...974]\n",
      "  [ 0.22571923]\n",
      "  [-0.23935306]\n",
      "  [-0.21039478]\n",
      "  [-0.3190387 ]\n",
      "  [ 0.6253763 ]\n",
      "  [-0.6294947 ]\n",
      "  [ 1.2769275 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4384afbb0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.27810633]\n",
      " [-1.3409295 ]\n",
      " [-1.3094507 ]\n",
      " [ 0.702908  ]\n",
      " [ 1.754042  ]\n",
      " [ 1.36422...0.56050974]\n",
      " [ 0.22571923]\n",
      " [-0.23935306]\n",
      " [-0.21039478]\n",
      " [-0.3190387 ]\n",
      " [ 0.6253763 ]\n",
      " [-0.6294947 ]\n",
      " [ 1.2769275 ]]))\n",
      "        y          = needle.Tensor([[ 0.27810633]\n",
      " [-1.3409295 ]\n",
      " [-1.3094507 ]\n",
      " [ 0.702908  ]\n",
      " [ 1.754042  ]\n",
      " [ 1.3642248 ]\n",
      " [-0.9816454 ]\n",
      " [ 0.7985976 ]\n",
      " [-0.8673713 ]\n",
      " [ 0.6049315 ]\n",
      " [-1.5445876 ]\n",
      " [-0.799828  ]\n",
      " [-0.5656663 ]\n",
      " [-0.36536974]\n",
      " [ 0.4733997 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.27810633]\n",
      " [-1.3409295 ]\n",
      " [-1.3094507 ]\n",
      " [ 0.702908  ]\n",
      " [ 1.754042  ]\n",
      " [ 1.3642248 ]\n",
      " [-0.9816454 ...-0.8673713 ]\n",
      " [ 0.6049315 ]\n",
      " [-1.5445876 ]\n",
      " [-0.799828  ]\n",
      " [-0.5656663 ]\n",
      " [-0.36536974]\n",
      " [ 0.4733997 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384af580>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.27810633]\n",
      " [-1.3409295 ]\n",
      " [-1.3094507 ]\n",
      " [ 0.702908  ]\n",
      " [ 1.754042  ]\n",
      " [ 1.3642248 ]\n",
      " [-0.9816454 ]\n",
      " [ 0.7985976 ]\n",
      " [-0.8673713 ]\n",
      " [ 0.6049315 ]\n",
      " [-1.5445876 ]\n",
      " [-0.799828  ]\n",
      " [-0.5656663 ]\n",
      " [-0.36536974]\n",
      " [ 0.4733997 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.11676128 -0.10318963  0.08918785  0.24516648]\n",
      " [-0.56298125  0.49754357 -0.430032   -1.1821053 ]\n",
      " [...47 -0.49866688]\n",
      " [-0.1533983   0.13556817 -0.11717296 -0.3220941 ]\n",
      " [ 0.19875404 -0.17565203  0.15181784  0.41732866]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384af580>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.62759733 -0.63612115 -0.06133997 -0.17299473]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.62759733 -0.63612115 -0.06133997 -0.17299473]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb43837a070>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.62759733 -0.63612115 -0.06133997 -0.17299473]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb43837a070>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb43837a700>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb43837a700>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb43837a100>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb43837a100>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-11-1-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[0.78140765]]], dtype=float32)\n",
      "c_         = tensor([[[-0.5146]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[1.0626471]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0004]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb480edb5e0>\n",
      "model_     = LSTM(11, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0004]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 1.1796734 , -1.3845654 ,  2.8112826 ,  0.94563293,\n",
      "          1.290244  ,  0.042611  ,  1.1683052 , -1.042513  ,\n",
      "          0.4778518 ,  2.1560316 ,  1.3670132 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.1796734  -1.3845654   2.8112826   0.94563293  1.290244\n",
      "    0.042611    1.1683052  -1.042513    0.4778518   2.1560316\n",
      "    1.3670132 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480edb5e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 1.1796734  -1.3845654   2.8112826   0.94563293  1.290244\n",
      "    0.042611    1.1683052  -1.042513    0.4778518   2.1560316\n",
      "    1.3670132 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480edb5e0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.1796734  -1.3845654   2.8112826   0.94563293  1.290244    0.042611\n",
      "   1.1683052  -1.042513    0.4778518   2.1560316   1.3670132 ]]),)\n",
      "        y          = needle.Tensor([[ 1.1796734  -1.3845654   2.8112826   0.94563293  1.290244    0.042611\n",
      "   1.1683052  -1.042513    0.4778518   2.1560316   1.3670132 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.1796734  -1.3845654   2.8112826   0.94563293  1.290244    0.042611\n",
      "   1.1683052  -1.042513    0.4778518   2.1560316   1.3670132 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480edbac0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 1.1796734  -1.3845654   2.8112826   0.94563293  1.290244    0.042611\n",
      "   1.1683052  -1.042513    0.4778518   2.1560316   1.3670132 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.5936087  2.7196426 -1.0955007 -6.988879 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480edbac0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.7801826  -0.6060264   0.08735359 -0.732962  ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.7801826  -0.6060264   0.08735359 -0.732962  ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480edbc10>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.7801826  -0.6060264   0.08735359 -0.732962  ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480edbc10>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480edb820>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480edb820>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480edbd60>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480edbd60>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-11-1-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[0.14197323]]], dtype=float32)\n",
      "c_         = tensor([[[0.1236]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[0.71585655]]], dtype=float32)\n",
      "h_         = tensor([[[0.1053]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4620dcf70>\n",
      "model_     = LSTM(11, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.0343]],\n",
      "\n",
      "        [[-0.0047]],\n",
      "\n",
      "        [[ 0.0389]],\n",
      "\n",
      "        [[-0.4447]],\n",
      "\n",
      "        [[-0.0303]],\n",
      "\n",
      "        ...7]],\n",
      "\n",
      "        [[ 0.0845]],\n",
      "\n",
      "        [[ 0.2653]],\n",
      "\n",
      "        [[ 0.3686]],\n",
      "\n",
      "        [[ 0.1053]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-1.257092  , -0.5400522 , -0.7652985 ,  0.6754767 ,\n",
      "          1.4390429 ,  0.4799358 , -0.8697776 , -1.547324...  -0.6337659 , -2.1177778 ,  0.54508066, -0.08789999,\n",
      "          1.1577396 , -1.1644639 ,  0.05167471]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.257092   -0.5400522  -0.7652985   0.6754767   1.4390429\n",
      "    0.4799358  -0.8697776  -1.5473249   0...5464296  -1.1426481  -0.6337659\n",
      "   -2.1177778   0.54508066 -0.08789999  1.1577396  -1.1644639\n",
      "    0.05167471]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4620dcf70>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-1.257092   -0.5400522  -0.7652985   0.6754767   1.4390429\n",
      "    0.4799358  -0.8697776  -1.5473249   0....84  -0.5464296  -1.1426481  -0.6337659\n",
      "   -2.1177778   0.54508066 -0.08789999  1.1577396  -1.1644639\n",
      "    0.05167471]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4620dcf70>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.257092   -0.5400522  -0.7652985   0.6754767   1.4390429   0.4799358\n",
      "  -0.8697776...83584  -0.5464296  -1.1426481  -0.6337659  -2.1177778\n",
      "   0.54508066 -0.08789999  1.1577396  -1.1644639   0.05167471]]))\n",
      "        y          = needle.Tensor([[-1.257092   -0.5400522  -0.7652985   0.6754767   1.4390429   0.4799358\n",
      "  -0.8697776  -1.5473249   0.6114917   0.40263772 -1.4924687 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.257092   -0.5400522  -0.7652985   0.6754767   1.4390429   0.4799358\n",
      "  -0.8697776  -1.5473249   0.6114917   0.40263772 -1.4924687 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4620dc250>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.257092   -0.5400522  -0.7652985   0.6754767   1.4390429   0.4799358\n",
      "  -0.8697776  -1.5473249   0.6114917   0.40263772 -1.4924687 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 2.5098925   0.41643935  0.7523989  -2.669471  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4620dc250>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.5503931   0.20719862  0.06644392  0.70623565]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.5503931   0.20719862  0.06644392  0.70623565]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4711f5640>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.5503931   0.20719862  0.06644392  0.70623565]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4711f5640>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4711f5c70>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4711f5c70>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4711f5e80>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4711f5e80>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-11-1-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[1.6477507 ]],\n",
      "\n",
      "       [[0.13908067]]], dtype=float32)\n",
      "c_         = tensor([[[0.4141]],\n",
      "\n",
      "        [[0.1159]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.14652188]],\n",
      "\n",
      "       [[-0.23365341]]], dtype=float32)\n",
      "h_         = tensor([[[0.3156]],\n",
      "\n",
      "        [[0.0646]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb471419e50>\n",
      "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[0.0646]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 1.67131   ,  0.88600165, -0.23592325, -0.9940943 ,\n",
      "         -0.0860274 ,  0.5676539 ,  0.02161075, -0.56960905,\n",
      "          0.16193748, -0.31033814, -0.1810146 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.67131     0.88600165 -0.23592325 -0.9940943  -0.0860274\n",
      "    0.5676539   0.02161075 -0.56960905  0.16193748 -0.31033814\n",
      "   -0.1810146 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471419e50>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 1.67131     0.88600165 -0.23592325 -0.9940943  -0.0860274\n",
      "    0.5676539   0.02161075 -0.56960905  0.16193748 -0.31033814\n",
      "   -0.1810146 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471419e50>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.67131     0.88600165 -0.23592325 -0.9940943  -0.0860274   0.5676539\n",
      "   0.02161075 -0.56960905  0.16193748 -0.31033814 -0.1810146 ]]),)\n",
      "        y          = needle.Tensor([[ 1.67131     0.88600165 -0.23592325 -0.9940943  -0.0860274   0.5676539\n",
      "   0.02161075 -0.56960905  0.16193748 -0.31033814 -0.1810146 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.67131     0.88600165 -0.23592325 -0.9940943  -0.0860274   0.5676539\n",
      "   0.02161075 -0.56960905  0.16193748 -0.31033814 -0.1810146 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471419280>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 1.67131     0.88600165 -0.23592325 -0.9940943  -0.0860274   0.5676539\n",
      "   0.02161075 -0.56960905  0.16193748 -0.31033814 -0.1810146 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.85028344 -1.5741712   0.6793511   1.4194329 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471419280>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.5406264 -0.8841423 -0.6095344  0.8416991]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.5406264 -0.8841423 -0.6095344  0.8416991]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471d3eb80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.5406264 -0.8841423 -0.6095344  0.8416991]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471d3eb80>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d3e0a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d3e0a0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471d3e8b0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471d3e8b0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-11-1-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.16845313]],\n",
      "\n",
      "       [[-1.1666656 ]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.5247]],\n",
      "\n",
      "        [[-0.0380]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[0.3557396]],\n",
      "\n",
      "       [[1.6395677]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.3940]],\n",
      "\n",
      "        [[-0.0201]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb430100490>\n",
      "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0030]],\n",
      "\n",
      "        [[-0.0175]],\n",
      "\n",
      "        [[-0.0315]],\n",
      "\n",
      "        [[-0.0201]],\n",
      "\n",
      "        [[-0.0104]],\n",
      "\n",
      "        ...6]],\n",
      "\n",
      "        [[-0.0032]],\n",
      "\n",
      "        [[-0.0012]],\n",
      "\n",
      "        [[-0.0006]],\n",
      "\n",
      "        [[-0.0201]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-4.3380037e-01,  3.2010770e-01, -9.3616998e-01, -1.0373474e+00,\n",
      "          1.7333466e-01, -5.1248491e-01, -3.5...9964437e-01, -1.3081743e-01, -1.1927228e+00,\n",
      "         -7.9030657e-01,  1.1266755e+00,  1.6115208e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-4.3380037e-01  3.2010770e-01 -9.3616998e-01 -1.0373474e+00\n",
      "    1.7333466e-01 -5.1248491e-01 -3.5483...  7.7552027e-01  4.9964437e-01 -1.3081743e-01 -1.1927228e+00\n",
      "   -7.9030657e-01  1.1266755e+00  1.6115208e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb430100490>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-4.3380037e-01  3.2010770e-01 -9.3616998e-01 -1.0373474e+00\n",
      "    1.7333466e-01 -5.1248491e-01 -3.54835...e-01\n",
      "    7.7552027e-01  4.9964437e-01 -1.3081743e-01 -1.1927228e+00\n",
      "   -7.9030657e-01  1.1266755e+00  1.6115208e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb430100490>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.43380037  0.3201077  -0.93617    -1.0373474   0.17333466 -0.5124849\n",
      "  -0.0035483...7837  -0.38380995  0.926971    0.77552027  0.49964437\n",
      "  -0.13081743 -1.1927228  -0.79030657  1.1266755   0.16115208]]))\n",
      "        y          = needle.Tensor([[-0.43380037  0.3201077  -0.93617    -1.0373474   0.17333466 -0.5124849\n",
      "  -0.00354836 -1.2688174   2.3146708  -1.6811674   0.19832945]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.43380037  0.3201077  -0.93617    -1.0373474   0.17333466 -0.5124849\n",
      "  -0.00354836 -1.2688174   2.3146708  -1.6811674   0.19832945]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4301009d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.43380037  0.3201077  -0.93617    -1.0373474   0.17333466 -0.5124849\n",
      "  -0.00354836 -1.2688174   2.3146708  -1.6811674   0.19832945]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.3977085 -3.268621  -5.014926  -0.9340975]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4301009d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.1087662  -0.6818222  -0.35741103 -0.12275398]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.1087662  -0.6818222  -0.35741103 -0.12275398]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461dbe9d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.1087662  -0.6818222  -0.35741103 -0.12275398]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461dbe9d0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461dbe220>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461dbe220>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461dbe610>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461dbe610>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-11-15-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 2.0019038 ],\n",
      "        [-0.6004084 ],\n",
      "        [-1.5488232 ],\n",
      "        [-0.9123605 ],\n",
      "        [ 0.63412416],\n",
      "   ...69738835],\n",
      "        [ 0.5921813 ],\n",
      "        [ 0.94663626],\n",
      "        [-1.1595942 ],\n",
      "        [-1.4685066 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.4598],\n",
      "         [-0.5071],\n",
      "         [-0.0138],\n",
      "         [ 0.7695],\n",
      "         [-0.1439],\n",
      "         [ 0.0654]... [ 0.7622],\n",
      "         [-0.2324],\n",
      "         [-0.0079],\n",
      "         [ 0.2158],\n",
      "         [-0.1207]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.14387871],\n",
      "        [-1.5149163 ],\n",
      "        [ 0.09101181],\n",
      "        [-0.51445794],\n",
      "        [-0.8115123 ],\n",
      "   ...9956011 ],\n",
      "        [-0.20332697],\n",
      "        [ 0.59240615],\n",
      "        [-0.29930747],\n",
      "        [-0.68386483]]], dtype=float32)\n",
      "h_         = tensor([[[-0.2733],\n",
      "         [-0.0613],\n",
      "         [-0.0100],\n",
      "         [ 0.0289],\n",
      "         [-0.1425],\n",
      "         [ 0.0137]... [ 0.3327],\n",
      "         [-0.0828],\n",
      "         [-0.0054],\n",
      "         [ 0.1482],\n",
      "         [-0.1199]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb46253adc0>\n",
      "model_     = LSTM(11, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.2733],\n",
      "         [-0.0613],\n",
      "         [-0.0100],\n",
      "         [ 0.0289],\n",
      "         [-0.1425],\n",
      "         [ 0.0137]... [ 0.3327],\n",
      "         [-0.0828],\n",
      "         [-0.0054],\n",
      "         [ 0.1482],\n",
      "         [-0.1199]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 3.3646441e-01, -2.3355751e-01, -1.1674813e+00, -7.9063892e-01,\n",
      "          2.3999177e-01, -2.8222715e-02,  2.0...3951303e-01,  1.2703003e+00, -8.3377826e-01,\n",
      "         -1.3123662e+00, -3.0480666e+00,  3.5337266e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 3.3646441e-01 -2.3355751e-01 -1.1674813e+00 -7.9063892e-01\n",
      "    2.3999177e-01 -2.8222715e-02  2.0186...  5.3961629e-01 -9.3951303e-01  1.2703003e+00 -8.3377826e-01\n",
      "   -1.3123662e+00 -3.0480666e+00  3.5337266e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46253adc0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 3.3646441e-01 -2.3355751e-01 -1.1674813e+00 -7.9063892e-01\n",
      "    2.3999177e-01 -2.8222715e-02  2.01867...e-02\n",
      "    5.3961629e-01 -9.3951303e-01  1.2703003e+00 -8.3377826e-01\n",
      "   -1.3123662e+00 -3.0480666e+00  3.5337266e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46253adc0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 3.3646441e-01 -2.3355751e-01 -1.1674813e+00 -7.9063892e-01\n",
      "   2.3999177e-01 -2.822...2e-02\n",
      "   5.3961629e-01 -9.3951303e-01  1.2703003e+00 -8.3377826e-01\n",
      "  -1.3123662e+00 -3.0480666e+00  3.5337266e-01]]),)\n",
      "        y          = needle.Tensor([[ 3.3646441e-01 -2.3355751e-01 -1.1674813e+00 -7.9063892e-01\n",
      "   2.3999177e-01 -2.8222715e-02  2.0186782...562e-02\n",
      "   5.3961629e-01 -9.3951303e-01  1.2703003e+00 -8.3377826e-01\n",
      "  -1.3123662e+00 -3.0480666e+00  3.5337266e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 3.3646441e-01 -2.3355751e-01 -1.1674813e+00 -7.9063892e-01\n",
      "   2.3999177e-01 -2.8222715e-02  2.018678...61629e-01 -9.3951303e-01  1.2703003e+00 -8.3377826e-01\n",
      "  -1.3123662e+00 -3.0480666e+00  3.5337266e-01]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46253aac0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 3.3646441e-01 -2.3355751e-01 -1.1674813e+00 -7.9063892e-01\n",
      "   2.3999177e-01 -2.8222715e-02  2.0186782...562e-02\n",
      "   5.3961629e-01 -9.3951303e-01  1.2703003e+00 -8.3377826e-01\n",
      "  -1.3123662e+00 -3.0480666e+00  3.5337266e-01]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 2.610462   -0.25178808 -0.5408119   0.55628395]\n",
      " [ 2.5043588  -3.2374418  -0.61622906 -1.8906416 ]\n",
      " [...2   0.7952416 ]\n",
      " [ 3.6630764  -2.4805837   0.22505993  0.835688  ]\n",
      " [-1.9766546  -0.5072905  -2.7338214   6.3108635 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46253aac0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.9563887   0.22434759 -0.80024517  0.07350242]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.9563887   0.22434759 -0.80024517  0.07350242]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46253acd0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.9563887   0.22434759 -0.80024517  0.07350242]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46253acd0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46253a2b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46253a2b0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46253abb0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46253abb0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-1-11-15-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 0.3896753 ],\n",
      "        [-0.23039156],\n",
      "        [ 0.30270875],\n",
      "        [-0.6664236 ],\n",
      "        [-0.4039066 ],\n",
      "   ...8466557 ],\n",
      "        [ 1.5481627 ],\n",
      "        [ 0.9970718 ],\n",
      "        [ 0.14640577],\n",
      "        [-0.24906495]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.0894],\n",
      "         [-0.4247],\n",
      "         [ 0.2739],\n",
      "         [-0.0155],\n",
      "         [ 0.7655],\n",
      "         [-0.6121]... [-0.2820],\n",
      "         [ 0.1385],\n",
      "         [ 0.0487],\n",
      "         [-0.5279],\n",
      "         [ 0.6265]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.08359555],\n",
      "        [-1.0876588 ],\n",
      "        [-0.86066425],\n",
      "        [ 0.3028589 ],\n",
      "        [ 0.25521305],\n",
      "   ...17710409],\n",
      "        [ 0.55817807],\n",
      "        [ 1.238315  ],\n",
      "        [-0.20083244],\n",
      "        [-1.625544  ]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.0503],\n",
      "         [-0.1426],\n",
      "         [ 0.1161],\n",
      "         [-0.0015],\n",
      "         [ 0.3840],\n",
      "         [-0.0776]... [-0.0513],\n",
      "         [ 0.0314],\n",
      "         [ 0.0391],\n",
      "         [-0.4784],\n",
      "         [ 0.5212]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4382e2160>\n",
      "model_     = LSTM(11, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-3.7649e-03],\n",
      "         [-1.2930e-01],\n",
      "         [ 2.9066e-01],\n",
      "         [ 2.9970e-02],\n",
      "         [ 2.2193e-02]...     [ 3.1374e-02],\n",
      "         [ 3.9074e-02],\n",
      "         [-4.7836e-01],\n",
      "         [ 5.2121e-01]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.11751936, -1.3980204 , -1.2094588 , ..., -0.33397424,\n",
      "         -0.53938323, -0.07360082],\n",
      "        [-0.1158...\n",
      "        [-0.05661142,  0.12646686,  0.30132508, ...,  0.78059095,\n",
      "          0.634377  , -0.59370023]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.11751936 -1.3980204  -1.2094588  ... -0.33397424 -0.53938323\n",
      "   -0.07360082]\n",
      "  [-0.11584961  0.64...  0.24971469\n",
      "    0.5671819 ]\n",
      "  [-0.05661142  0.12646686  0.30132508 ...  0.78059095  0.634377\n",
      "   -0.59370023]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4382e2160>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.11751936 -1.3980204  -1.2094588  ... -0.33397424 -0.53938323\n",
      "   -0.07360082]\n",
      "  [-0.11584961  0.640...9405754  0.24971469\n",
      "    0.5671819 ]\n",
      "  [-0.05661142  0.12646686  0.30132508 ...  0.78059095  0.634377\n",
      "   -0.59370023]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4382e2160>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.11751936 -1.3980204  -1.2094588  -0.48293307  0.41084263 -0.9019499\n",
      "   0.7685391...  -6.12590909e-01 -1.25244570e+00 -2.03094795e-01 -1.52145720e+00\n",
      "   7.80590951e-01  6.34377003e-01 -5.93700230e-01]]))\n",
      "        y          = needle.Tensor([[ 0.11751936 -1.3980204  -1.2094588  -0.48293307  0.41084263 -0.9019499\n",
      "   0.76853913  1.6785979  -0.33...8895774 -0.41246602 -0.9418225   1.0013496  -0.3070162\n",
      "   0.5266715   2.0062628  -0.88163185  0.74418026 -0.30866838]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.11751936 -1.3980204  -1.2094588  -0.48293307  0.41084263 -0.9019499\n",
      "   0.76853913  1.6785979  -0.3...6602 -0.9418225   1.0013496  -0.3070162\n",
      "   0.5266715   2.0062628  -0.88163185  0.74418026 -0.30866838]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4382e20d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.11751936 -1.3980204  -1.2094588  -0.48293307  0.41084263 -0.9019499\n",
      "   0.76853913  1.6785979  -0.33...8895774 -0.41246602 -0.9418225   1.0013496  -0.3070162\n",
      "   0.5266715   2.0062628  -0.88163185  0.74418026 -0.30866838]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.36949295 -1.8385324  -0.16238701 -3.1866724 ]\n",
      " [ 0.7082509  -0.6324262  -0.96359944 -0.9448604 ]\n",
      " [...1   4.274808  ]\n",
      " [ 0.42143077 -1.0061531  -2.1814537  -0.07025877]\n",
      " [-0.9919499   1.7401369  -0.85007614 -0.30437142]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4382e20d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.4427086   0.13398385 -0.86229455 -0.6289228 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.4427086   0.13398385 -0.86229455 -0.6289228 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4620dceb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.4427086   0.13398385 -0.86229455 -0.6289228 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4620dceb0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4620dc190>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4620dc190>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4620dca90>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4620dca90>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-1-11-15-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 0.3696613 ],\n",
      "        [ 0.7099069 ],\n",
      "        [ 2.582784  ],\n",
      "        [ 1.5073627 ],\n",
      "        [ 0.83332   ],\n",
      "   ...12241504],\n",
      "        [ 1.342411  ],\n",
      "        [-0.34492105],\n",
      "        [ 1.3817558 ],\n",
      "        [-1.6060711 ]]], dtype=float32)\n",
      "c_         = tensor([[[-1.9777e-01],\n",
      "         [ 2.7466e-01],\n",
      "         [-9.4378e-01],\n",
      "         [ 2.0972e-01],\n",
      "         [-3.9907e-01]...     [ 1.8098e-01],\n",
      "         [-5.7007e-03],\n",
      "         [-4.9843e-03],\n",
      "         [ 1.4201e-01]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.79397213],\n",
      "        [ 0.76568556],\n",
      "        [-0.23552614],\n",
      "        [ 0.17593637],\n",
      "        [-0.21691681],\n",
      "   ...27671427],\n",
      "        [ 0.66435224],\n",
      "        [ 0.2895916 ],\n",
      "        [-0.85294896],\n",
      "        [ 0.8574336 ]]], dtype=float32)\n",
      "h_         = tensor([[[-9.2120e-02],\n",
      "         [ 1.7513e-01],\n",
      "         [-3.1595e-01],\n",
      "         [ 2.4056e-02],\n",
      "         [-2.8222e-01]...     [ 7.6163e-02],\n",
      "         [-2.8637e-03],\n",
      "         [-2.5023e-03],\n",
      "         [ 6.2327e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb461261b80>\n",
      "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0195],\n",
      "         [-0.0396],\n",
      "         [ 0.0608],\n",
      "         [-0.0053],\n",
      "         [ 0.0552],\n",
      "         [-0.0054]... [ 0.1010],\n",
      "         [ 0.0762],\n",
      "         [-0.0029],\n",
      "         [-0.0025],\n",
      "         [ 0.0623]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.1697128 , -0.7582708 , -0.78327465,  0.04505941,\n",
      "          0.45522958, -2.072818  , -0.47433215,  0.563957...  -0.4375278 ,  0.3239667 , -0.80268115,  0.81263626,\n",
      "          1.4487723 , -0.9439537 , -0.34131265]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.1697128  -0.7582708  -0.78327465  0.04505941  0.45522958\n",
      "   -2.072818   -0.47433215  0.563957    ...16806029 -1.4887179  -0.4375278\n",
      "    0.3239667  -0.80268115  0.81263626  1.4487723  -0.9439537\n",
      "   -0.34131265]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461261b80>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.1697128  -0.7582708  -0.78327465  0.04505941  0.45522958\n",
      "   -2.072818   -0.47433215  0.563957    0...203  0.16806029 -1.4887179  -0.4375278\n",
      "    0.3239667  -0.80268115  0.81263626  1.4487723  -0.9439537\n",
      "   -0.34131265]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461261b80>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.1697128  -0.7582708  -0.78327465  0.04505941  0.45522958 -2.072818\n",
      "  -0.47433215...13203  0.16806029 -1.4887179  -0.4375278   0.3239667\n",
      "  -0.80268115  0.81263626  1.4487723  -0.9439537  -0.34131265]]),)\n",
      "        y          = needle.Tensor([[-1.1697128  -0.7582708  -0.78327465  0.04505941  0.45522958 -2.072818\n",
      "  -0.47433215  0.563957    0.130...4013203  0.16806029 -1.4887179  -0.4375278   0.3239667\n",
      "  -0.80268115  0.81263626  1.4487723  -0.9439537  -0.34131265]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.1697128  -0.7582708  -0.78327465  0.04505941  0.45522958 -2.072818\n",
      "  -0.47433215  0.563957    0.13...6029 -1.4887179  -0.4375278   0.3239667\n",
      "  -0.80268115  0.81263626  1.4487723  -0.9439537  -0.34131265]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461261ac0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.1697128  -0.7582708  -0.78327465  0.04505941  0.45522958 -2.072818\n",
      "  -0.47433215  0.563957    0.130...4013203  0.16806029 -1.4887179  -0.4375278   0.3239667\n",
      "  -0.80268115  0.81263626  1.4487723  -0.9439537  -0.34131265]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.45212296 -1.5725408  -0.3356655  -0.11269037]\n",
      " [-0.07729065  0.36075628  0.6495777   0.63490885]\n",
      " [...    0.3188336 ]\n",
      " [-3.2851787   0.3903536   0.56743526  0.47803134]\n",
      " [ 1.1516794  -0.4019653  -1.0596985   0.44183755]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461261ac0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.8467525  -0.83914113 -0.7896476   0.20799625]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.8467525  -0.83914113 -0.7896476   0.20799625]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46122d130>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.8467525  -0.83914113 -0.7896476   0.20799625]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46122d130>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46122d430>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46122d430>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46122dd30>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46122dd30>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-1-11-15-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-1.9427075e+00],\n",
      "        [ 7.3198199e-02],\n",
      "        [ 6.1275619e-01],\n",
      "        [-9.5188998e-02],\n",
      "        [-5.70...       [ 1.1040963e+00],\n",
      "        [-1.0809815e+00],\n",
      "        [ 1.8234234e+00],\n",
      "        [ 1.3341159e+00]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.4719],\n",
      "         [ 0.4194],\n",
      "         [-0.0774],\n",
      "         [ 0.6547],\n",
      "         [-0.7078],\n",
      "         [-0.3264]... [-0.0521],\n",
      "         [-0.1382],\n",
      "         [-0.0380],\n",
      "         [ 0.2499],\n",
      "         [-0.0927]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-1.784149  ],\n",
      "        [ 0.20297818],\n",
      "        [ 0.10714506],\n",
      "        [-1.4887964 ],\n",
      "        [ 0.9197915 ],\n",
      "   ...20234424],\n",
      "        [-0.21284413],\n",
      "        [ 0.4586849 ],\n",
      "        [-0.96157694],\n",
      "        [ 0.6513675 ]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.2765],\n",
      "         [ 0.3359],\n",
      "         [-0.0385],\n",
      "         [ 0.5493],\n",
      "         [-0.3248],\n",
      "         [-0.1979]... [-0.0285],\n",
      "         [-0.0675],\n",
      "         [-0.0193],\n",
      "         [ 0.1121],\n",
      "         [-0.0470]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb458b48df0>\n",
      "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0082],\n",
      "         [ 0.0138],\n",
      "         [-0.0274],\n",
      "         [-0.0252],\n",
      "         [ 0.0102],\n",
      "         [-0.0327]... [-0.0285],\n",
      "         [-0.0675],\n",
      "         [-0.0193],\n",
      "         [ 0.1121],\n",
      "         [-0.0470]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 1.44231284e+00, -1.25958657e+00,  9.95256230e-02, ...,\n",
      "          4.30061996e-01,  7.66000748e-01,  9.7685843...12242401e+00,  6.47633374e-01, ...,\n",
      "         -3.87312144e-01,  1.33269274e+00, -5.30204654e-01]]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.44231284e+00 -1.25958657e+00  9.95256230e-02 ...  4.30061996e-01\n",
      "    7.66000748e-01  9.76858437e-...1]\n",
      "  [ 3.35456371e-01 -1.12242401e+00  6.47633374e-01 ... -3.87312144e-01\n",
      "    1.33269274e+00 -5.30204654e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458b48df0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 1.44231284e+00 -1.25958657e+00  9.95256230e-02 ...  4.30061996e-01\n",
      "    7.66000748e-01  9.76858437e-0...1014e-01]\n",
      "  [ 3.35456371e-01 -1.12242401e+00  6.47633374e-01 ... -3.87312144e-01\n",
      "    1.33269274e+00 -5.30204654e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458b48df0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.4423128  -1.2595866   0.09952562 -0.47924688 -0.42185912 -0.14920604\n",
      "   0.174872...10e+00\n",
      "   8.6138105e-01  3.6613028e-02  6.6961658e-01  6.2561226e-01\n",
      "  -3.8731214e-01  1.3326927e+00 -5.3020465e-01]]))\n",
      "        y          = needle.Tensor([[ 1.4423128  -1.2595866   0.09952562 -0.47924688 -0.42185912 -0.14920604\n",
      "   0.17487223 -0.19233751  0.4...284754 -0.7722451   1.083839    0.38150474  0.34400302\n",
      "   1.1907915   0.7193189   0.5540556  -0.81300974  1.2179375 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.4423128  -1.2595866   0.09952562 -0.47924688 -0.42185912 -0.14920604\n",
      "   0.17487223 -0.19233751  0....51   1.083839    0.38150474  0.34400302\n",
      "   1.1907915   0.7193189   0.5540556  -0.81300974  1.2179375 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458b48160>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 1.4423128  -1.2595866   0.09952562 -0.47924688 -0.42185912 -0.14920604\n",
      "   0.17487223 -0.19233751  0.4...284754 -0.7722451   1.083839    0.38150474  0.34400302\n",
      "   1.1907915   0.7193189   0.5540556  -0.81300974  1.2179375 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.9264774   2.6514025   0.7528512  -0.4897176 ]\n",
      " [-0.20488977 -0.26364836  0.6590209  -0.16539836]\n",
      " [...7   2.2420073 ]\n",
      " [-0.598957    1.9201807  -1.080464    1.0819296 ]\n",
      " [-1.9788326   2.0727181  -2.555915    0.18483578]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458b48160>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.17939198 -0.98864496  0.76321125  0.23331594]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.17939198 -0.98864496  0.76321125  0.23331594]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461d80310>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.17939198 -0.98864496  0.76321125  0.23331594]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461d80310>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461d80ca0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461d80ca0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461d80c10>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461d80c10>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-12-1-1-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 12\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.89628947, -2.2454302 , -1.4239084 ,  0.24361522,\n",
      "          1.2964362 ,  0.03779044,  0.34096268, -0.27361822,\n",
      "          0.39872548, -1.0846885 , -2.006816  , -0.3834687 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0147, -0.0156, -0.0042,  0.0087, -0.0241, -0.0142, -0.0180,\n",
      "           0.0080, -0.0131,  0.0122,  0.0031,  0.0027]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.11790587,  1.141563  , -0.64927727, -1.0076436 ,\n",
      "          1.2589017 , -1.0063709 , -0.48930165, -1.4056019 ,\n",
      "         -0.17372899, -0.00790384, -1.1857917 ,  0.38993827]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0076, -0.0078, -0.0021,  0.0043, -0.0121, -0.0072, -0.0089,\n",
      "           0.0039, -0.0065,  0.0060,  0.0016,  0.0014]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb461568340>\n",
      "model_     = LSTM(1, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0076, -0.0078, -0.0021,  0.0043, -0.0121, -0.0072, -0.0089,\n",
      "           0.0039, -0.0065,  0.0060,  0.0016,  0.0014]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.20064083]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.20064083]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461568340>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.20064083]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461568340>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.20064083]]),)\n",
      "        y          = needle.Tensor([[-0.20064083]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.20064083]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461568a00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.20064083]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.00647438 -0.02900465 -0.04602227  0.0133345  -0.00114201 -0.01917469\n",
      "  -0.01381698  0.04157847 -0.0...835354 -0.03004696  0.01110236  0.03647235\n",
      "  -0.03289708 -0.0359126  -0.03376237 -0.02940324 -0.00527493  0.0242088 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461568a00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.22881858 -0.22476798  0.07845265  0.22973949 -0.24672884 -0.20747231\n",
      "  -0.14067253 -0.16007008  0.0...097859  0.00953761  0.28091532 -0.21264371\n",
      "  -0.02963099 -0.00672105 -0.07492916 -0.14102925 -0.23807596  0.13858876]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.22881858 -0.22476798  0.07845265  0.22973949 -0.24672884 -0.20747231\n",
      "  -0.14067253 -0.16007008  0.... 0.00953761  0.28091532 -0.21264371\n",
      "  -0.02963099 -0.00672105 -0.07492916 -0.14102925 -0.23807596  0.13858876]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4615680d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.22881858 -0.22476798  0.07845265  0.22973949 -0.24672884 -0.20747231\n",
      "  -0.14067253 -0.16007008  0.... 0.00953761  0.28091532 -0.21264371\n",
      "  -0.02963099 -0.00672105 -0.07492916 -0.14102925 -0.23807596  0.13858876]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4615680d0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461568640>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461568640>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461568070>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461568070>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-12-1-1-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[ 0.28367853,  2.321083  ,  1.3870316 , -0.57353437,\n",
      "          0.49419272,  0.8148981 ,  0.18796147,  0.20045094,\n",
      "         -1.5112557 ,  1.2259802 ,  2.4026983 , -0.79547423]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0597, -0.1698,  0.0292, -0.0664, -0.0966,  0.1652,  0.1326,\n",
      "           0.0280,  0.0069, -0.0508,  0.0627, -0.1381]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.8497245 ,  2.7978582 , -1.6019642 ,  1.5726179 ,\n",
      "          0.7330602 ,  0.48282188,  0.18894072, -0.87941915,\n",
      "         -1.8894515 ,  0.7181074 , -0.47008255,  0.533133  ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0290, -0.0833,  0.0137, -0.0333, -0.0489,  0.0863,  0.0691,\n",
      "           0.0145,  0.0034, -0.0263,  0.0296, -0.0692]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4720804f0>\n",
      "model_     = LSTM(1, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-8.3355e-02, -7.0338e-02, -1.3340e-03, -4.0063e-02, -7.8394e-02,\n",
      "           7.2345e-02,  6.7431e-02,  2.4515...2,  6.9115e-02,  1.4453e-02,  3.4271e-03, -2.6271e-02,\n",
      "           2.9594e-02, -6.9231e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-1.1846323 ]],\n",
      "\n",
      "       [[ 0.8902226 ]],\n",
      "\n",
      "       [[ 0.5894598 ]],\n",
      "\n",
      "       [[-0.03376669]],\n",
      "\n",
      "       [[ 0.675641...]],\n",
      "\n",
      "       [[ 0.7075576 ]],\n",
      "\n",
      "       [[-0.30678335]],\n",
      "\n",
      "       [[-2.5265744 ]],\n",
      "\n",
      "       [[ 0.19760029]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.1846323 ]]\n",
      "\n",
      " [[ 0.8902226 ]]\n",
      "\n",
      " [[ 0.5894598 ]]\n",
      "\n",
      " [[-0.03376669]]\n",
      "\n",
      " [[ 0.6756418 ]]\n",
      "\n",
      " [[-1.2712289...]]\n",
      "\n",
      " [[-0.95155585]]\n",
      "\n",
      " [[-0.11545087]]\n",
      "\n",
      " [[ 0.7075576 ]]\n",
      "\n",
      " [[-0.30678335]]\n",
      "\n",
      " [[-2.5265744 ]]\n",
      "\n",
      " [[ 0.19760029]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4720804f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-1.1846323 ]]\n",
      "\n",
      " [[ 0.8902226 ]]\n",
      "\n",
      " [[ 0.5894598 ]]\n",
      "\n",
      " [[-0.03376669]]\n",
      "\n",
      " [[ 0.6756418 ]]\n",
      "\n",
      " [[-1.2712289 ...48107  ]]\n",
      "\n",
      " [[-0.95155585]]\n",
      "\n",
      " [[-0.11545087]]\n",
      "\n",
      " [[ 0.7075576 ]]\n",
      "\n",
      " [[-0.30678335]]\n",
      "\n",
      " [[-2.5265744 ]]\n",
      "\n",
      " [[ 0.19760029]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4720804f0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.1846323]]), needle.Tensor([[0.8902226]]), needle.Tensor([[0.5894598]]), needle.T...le.Tensor([[0.7075576]]), needle.Tensor([[-0.30678335]]), needle.Tensor([[-2.5265744]]), needle.Tensor([[0.19760029]]))\n",
      "        y          = needle.Tensor([[-1.1846323]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.1846323]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb472080f70>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.1846323]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.17364414  0.27028218 -0.05857157 -0.10166188 -0.16431175  0.11605506\n",
      "   0.27504057  0.14438042 -0.3...755445  0.1894239   0.33993062 -0.17869426\n",
      "   0.00177248 -0.17951132 -0.09153326  0.0206473  -0.01083056 -0.31635723]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb472080f70>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.25053936e-01 -7.52443522e-02  6.88272715e-02 -1.69737577e-01\n",
      "   4.45905924e-02 -1.20932102e-01 -9.8...02  2.38425016e-01 -2.24158540e-01  9.21925604e-02\n",
      "  -1.59754857e-01  9.76767242e-02  2.57207453e-01  2.80837893e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.25053936e-01 -7.52443522e-02  6.88272715e-02 -1.69737577e-01\n",
      "   4.45905924e-02 -1.20932102e-01 -9....8425016e-01 -2.24158540e-01  9.21925604e-02\n",
      "  -1.59754857e-01  9.76767242e-02  2.57207453e-01  2.80837893e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461fa6df0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.25053936e-01 -7.52443522e-02  6.88272715e-02 -1.69737577e-01\n",
      "   4.45905924e-02 -1.20932102e-01 -9....8425016e-01 -2.24158540e-01  9.21925604e-02\n",
      "  -1.59754857e-01  9.76767242e-02  2.57207453e-01  2.80837893e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461fa6df0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461fa6160>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461fa6160>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461fa64f0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461fa64f0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-12-1-1-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 12\n",
      "bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-9.6917027e-01,  9.4877785e-01,  1.9128729e+00, -1.8836228e+00,\n",
      "          1.9836116e-01,  5.1495850e-01, -8.8...7e-01,  4.1786534e-01,\n",
      "          5.7222956e-01,  7.8458828e-01,  4.4641724e-01,  5.1988696e-04]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0400, -0.0885,  0.0054,  0.1455, -0.0424, -0.0703, -0.0598,\n",
      "           0.1575, -0.0206,  0.1309,  0.2045,...,  0.0269,  0.0045,  0.0077,\n",
      "          -0.0346, -0.0017,  0.0103,  0.0151, -0.0203]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.5062227 ,  0.8751839 ,  0.8961401 ,  0.9343124 ,\n",
      "         -0.4213268 ,  1.1000414 ,  0.12966307,  0.307497...7668245,  0.16767585,  1.2076229 ,\n",
      "         -0.9536691 , -0.69086367, -0.14416078,  0.9944607 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0218, -0.0457,  0.0029,  0.0842, -0.0176, -0.0412, -0.0329,\n",
      "           0.0642, -0.0101,  0.0676,  0.1213,...,  0.0137,  0.0022,  0.0038,\n",
      "          -0.0173, -0.0008,  0.0051,  0.0076, -0.0100]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4620259a0>\n",
      "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0140,  0.0018, -0.0036,  0.0018,  0.0137,  0.0022,  0.0038,\n",
      "          -0.0173, -0.0008,  0.0051,  0.0076, -0.0100]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.535423]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.535423]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4620259a0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.535423]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4620259a0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.535423]]),)\n",
      "        y          = needle.Tensor([[-1.535423]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.535423]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462025880>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.535423]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.2026036  -0.42734107  0.22701897  0.1385032  -0.26444405 -0.17669469\n",
      "  -0.41132334  0.33150128 -0.3...664073  0.3344379  -0.3407776   0.35240266\n",
      "   0.20485848 -0.36064762 -0.04672776  0.078384    0.41163442  0.42257032]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462025880>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.03513923  0.19325992 -0.2104089  -0.04090713  0.08187103  0.01992023\n",
      "  -0.12831202 -0.09844206  0.0...348704 -0.27363327 -0.02326685 -0.15071294\n",
      "  -0.20111355 -0.06736748  0.02596697 -0.03530079 -0.00380415  0.04570895]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.03513923  0.19325992 -0.2104089  -0.04090713  0.08187103  0.01992023\n",
      "  -0.12831202 -0.09844206  0....-0.27363327 -0.02326685 -0.15071294\n",
      "  -0.20111355 -0.06736748  0.02596697 -0.03530079 -0.00380415  0.04570895]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb462025070>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.03513923  0.19325992 -0.2104089  -0.04090713  0.08187103  0.01992023\n",
      "  -0.12831202 -0.09844206  0....-0.27363327 -0.02326685 -0.15071294\n",
      "  -0.20111355 -0.06736748  0.02596697 -0.03530079 -0.00380415  0.04570895]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb462025070>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4620250d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4620250d0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb462025e20>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb462025e20>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-12-1-1-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.55335546,  0.00693383, -0.3495859 ,  1.2668492 ,\n",
      "         -1.5442036 ,  1.1089072 ,  0.9296658 , -2.822873...5518566,  0.00691587,  0.52141595,\n",
      "         -1.3531798 ,  0.688023  ,  0.26312047, -1.0623835 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.3676, -0.2432, -0.3124, -0.2621,  0.1170, -0.0344,  0.1701,\n",
      "           0.1133,  0.1003,  0.0956,  0.0387,..., -0.0090, -0.0121, -0.0208,\n",
      "           0.0256, -0.0220,  0.0185,  0.0781, -0.0275]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 1.8393918e+00,  1.0034838e+00,  7.8163326e-01,  3.5151872e-01,\n",
      "          1.7336563e+00, -2.2941834e-01, -6.1...2e-01, -7.1872741e-01,\n",
      "         -3.7854198e-01, -1.0349815e+00, -4.1989345e-02,  1.9168417e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.1726, -0.1002, -0.1562, -0.1587,  0.0461, -0.0149,  0.0790,\n",
      "           0.0684,  0.0519,  0.0561,  0.0215,..., -0.0044, -0.0059, -0.0109,\n",
      "           0.0125, -0.0111,  0.0092,  0.0400, -0.0135]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb481270a00>\n",
      "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 2.8014e-03,  1.4480e-03,  2.0725e-03, -4.2680e-03,  5.2216e-04,\n",
      "          -8.6138e-05,  1.6437e-03, -4.2584...3, -1.0889e-02,  1.2546e-02, -1.1145e-02,  9.1851e-03,\n",
      "           4.0010e-02, -1.3514e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.6469127 ]],\n",
      "\n",
      "       [[-0.9375559 ]],\n",
      "\n",
      "       [[-0.5945766 ]],\n",
      "\n",
      "       [[-0.971705  ]],\n",
      "\n",
      "       [[-0.515316...]],\n",
      "\n",
      "       [[ 0.6632351 ]],\n",
      "\n",
      "       [[-0.5864089 ]],\n",
      "\n",
      "       [[-1.5009425 ]],\n",
      "\n",
      "       [[-1.6710118 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.6469127 ]]\n",
      "\n",
      " [[-0.9375559 ]]\n",
      "\n",
      " [[-0.5945766 ]]\n",
      "\n",
      " [[-0.971705  ]]\n",
      "\n",
      " [[-0.5153162 ]]\n",
      "\n",
      " [[ 0.2081555...]]\n",
      "\n",
      " [[-0.5338069 ]]\n",
      "\n",
      " [[ 0.7750282 ]]\n",
      "\n",
      " [[ 0.6632351 ]]\n",
      "\n",
      " [[-0.5864089 ]]\n",
      "\n",
      " [[-1.5009425 ]]\n",
      "\n",
      " [[-1.6710118 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb481270a00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.6469127 ]]\n",
      "\n",
      " [[-0.9375559 ]]\n",
      "\n",
      " [[-0.5945766 ]]\n",
      "\n",
      " [[-0.971705  ]]\n",
      "\n",
      " [[-0.5153162 ]]\n",
      "\n",
      " [[ 0.20815551...990468 ]]\n",
      "\n",
      " [[-0.5338069 ]]\n",
      "\n",
      " [[ 0.7750282 ]]\n",
      "\n",
      " [[ 0.6632351 ]]\n",
      "\n",
      " [[-0.5864089 ]]\n",
      "\n",
      " [[-1.5009425 ]]\n",
      "\n",
      " [[-1.6710118 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb481270a00>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.6469127]]), needle.Tensor([[-0.9375559]]), needle.Tensor([[-0.5945766]]), needle....dle.Tensor([[0.6632351]]), needle.Tensor([[-0.5864089]]), needle.Tensor([[-1.5009425]]), needle.Tensor([[-1.6710118]]))\n",
      "        y          = needle.Tensor([[0.6469127]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.6469127]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb481270b20>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[0.6469127]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.16328464  0.06168193 -0.05856084 -0.18051651 -0.0338329  -0.00609681\n",
      "  -0.0272215  -0.0466522  -0.1...826495 -0.18330497  0.13293247  0.10704432\n",
      "   0.08675297 -0.17761296 -0.03201851 -0.1346988  -0.06829632  0.10271713]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb481270b20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 2.74171472e-01  2.30560064e-01  2.20023692e-01 -1.24905467e-01\n",
      "  -2.26897866e-01  2.11251318e-01 -1.5...02  4.70900536e-03 -9.52272862e-02  2.05523103e-01\n",
      "  -1.17153764e-01  1.14635527e-01 -2.20549911e-01  3.75138521e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 2.74171472e-01  2.30560064e-01  2.20023692e-01 -1.24905467e-01\n",
      "  -2.26897866e-01  2.11251318e-01 -1....0900536e-03 -9.52272862e-02  2.05523103e-01\n",
      "  -1.17153764e-01  1.14635527e-01 -2.20549911e-01  3.75138521e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb438385c10>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 2.74171472e-01  2.30560064e-01  2.20023692e-01 -1.24905467e-01\n",
      "  -2.26897866e-01  2.11251318e-01 -1....0900536e-03 -9.52272862e-02  2.05523103e-01\n",
      "  -1.17153764e-01  1.14635527e-01 -2.20549911e-01  3.75138521e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb438385c10>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb438385790>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb438385790>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb438385d60>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb438385d60>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-12-1-15-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-6.78234518e-01,  4.24830496e-01,  1.93261504e-01,\n",
      "          7.28701174e-01,  6.28236115e-01, -1.09848809e+00..., -6.96133435e-01,  2.52699077e-01,\n",
      "          1.76232532e-01, -1.18547904e+00,  6.08487725e-01]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.2032, -0.1276, -0.1051, -0.1342, -0.1486, -0.1930,  0.0261,\n",
      "           0.0543,  0.0060, -0.0949, -0.1691,..., -0.0572, -0.0668,  0.0085,\n",
      "           0.0225,  0.0025, -0.0375, -0.0674,  0.0369]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.30793515,  0.514462  ,  0.63631976, -0.1310335 ,\n",
      "         -0.60273993, -0.8895813 , -0.50528365, -1.485392...1774837, -0.9616598 , -0.17507787,\n",
      "         -0.13458718,  0.48981163,  0.9542626 ,  1.2296003 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0972, -0.0626, -0.0525, -0.0723, -0.0801, -0.1116,  0.0106,\n",
      "           0.0221,  0.0028, -0.0407, -0.0964,..., -0.0294, -0.0354,  0.0039,\n",
      "           0.0105,  0.0012, -0.0178, -0.0355,  0.0177]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb471419700>\n",
      "model_     = LSTM(1, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0972, -0.0626, -0.0525, -0.0723, -0.0801, -0.1116,  0.0106,\n",
      "           0.0221,  0.0028, -0.0407, -0.0964,..., -0.0294, -0.0354,  0.0039,\n",
      "           0.0105,  0.0012, -0.0178, -0.0355,  0.0177]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 1.468794  ],\n",
      "        [-0.14385957],\n",
      "        [ 1.329416  ],\n",
      "        [-0.9421609 ],\n",
      "        [ 0.7536689 ],\n",
      "   ...6160078 ],\n",
      "        [ 0.7552876 ],\n",
      "        [-0.2558958 ],\n",
      "        [ 1.7315716 ],\n",
      "        [ 0.53033733]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.468794  ]\n",
      "  [-0.14385957]\n",
      "  [ 1.329416  ]\n",
      "  [-0.9421609 ]\n",
      "  [ 0.7536689 ]\n",
      "  [ 0.28652036]\n",
      "  [-0.5...[-0.51330173]\n",
      "  [ 0.36456951]\n",
      "  [-0.6160078 ]\n",
      "  [ 0.7552876 ]\n",
      "  [-0.2558958 ]\n",
      "  [ 1.7315716 ]\n",
      "  [ 0.53033733]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471419700>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 1.468794  ]\n",
      "  [-0.14385957]\n",
      "  [ 1.329416  ]\n",
      "  [-0.9421609 ]\n",
      "  [ 0.7536689 ]\n",
      "  [ 0.28652036]\n",
      "  [-0.51...411]\n",
      "  [-0.51330173]\n",
      "  [ 0.36456951]\n",
      "  [-0.6160078 ]\n",
      "  [ 0.7552876 ]\n",
      "  [-0.2558958 ]\n",
      "  [ 1.7315716 ]\n",
      "  [ 0.53033733]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471419700>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.468794  ]\n",
      " [-0.14385957]\n",
      " [ 1.329416  ]\n",
      " [-0.9421609 ]\n",
      " [ 0.7536689 ]\n",
      " [ 0.28652....09775411]\n",
      " [-0.51330173]\n",
      " [ 0.36456951]\n",
      " [-0.6160078 ]\n",
      " [ 0.7552876 ]\n",
      " [-0.2558958 ]\n",
      " [ 1.7315716 ]\n",
      " [ 0.53033733]]),)\n",
      "        y          = needle.Tensor([[ 1.468794  ]\n",
      " [-0.14385957]\n",
      " [ 1.329416  ]\n",
      " [-0.9421609 ]\n",
      " [ 0.7536689 ]\n",
      " [ 0.28652036]\n",
      " [-0.5131005 ]\n",
      " [-0.09775411]\n",
      " [-0.51330173]\n",
      " [ 0.36456951]\n",
      " [-0.6160078 ]\n",
      " [ 0.7552876 ]\n",
      " [-0.2558958 ]\n",
      " [ 1.7315716 ]\n",
      " [ 0.53033733]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.468794  ]\n",
      " [-0.14385957]\n",
      " [ 1.329416  ]\n",
      " [-0.9421609 ]\n",
      " [ 0.7536689 ]\n",
      " [ 0.28652036]\n",
      " [-0.5131005 ...-0.51330173]\n",
      " [ 0.36456951]\n",
      " [-0.6160078 ]\n",
      " [ 0.7552876 ]\n",
      " [-0.2558958 ]\n",
      " [ 1.7315716 ]\n",
      " [ 0.53033733]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471419ac0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 1.468794  ]\n",
      " [-0.14385957]\n",
      " [ 1.329416  ]\n",
      " [-0.9421609 ]\n",
      " [ 0.7536689 ]\n",
      " [ 0.28652036]\n",
      " [-0.5131005 ]\n",
      " [-0.09775411]\n",
      " [-0.51330173]\n",
      " [ 0.36456951]\n",
      " [-0.6160078 ]\n",
      " [ 0.7552876 ]\n",
      " [-0.2558958 ]\n",
      " [ 1.7315716 ]\n",
      " [ 0.53033733]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.58359066e-01  8.11029226e-02 -2.91727722e-01  7.95341209e-02\n",
      "  -1.02423579e-01  2.67222643e-01  3.8...02  1.24747597e-01 -1.38086975e-01 -1.33587763e-01\n",
      "  -4.88088578e-02 -1.01891547e-01  1.09517850e-01 -7.61517510e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471419ac0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.31003404e-01  2.20564485e-01 -2.53948390e-01  2.35860467e-01\n",
      "   1.69727802e-02 -1.38876438e-02 -7.2...01 -1.65026248e-01 -1.04779899e-02  8.65814686e-02\n",
      "   2.87872851e-01 -7.49245286e-02 -1.72731400e-01  1.78774893e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.31003404e-01  2.20564485e-01 -2.53948390e-01  2.35860467e-01\n",
      "   1.69727802e-02 -1.38876438e-02 -7....5026248e-01 -1.04779899e-02  8.65814686e-02\n",
      "   2.87872851e-01 -7.49245286e-02 -1.72731400e-01  1.78774893e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471297910>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.31003404e-01  2.20564485e-01 -2.53948390e-01  2.35860467e-01\n",
      "   1.69727802e-02 -1.38876438e-02 -7....5026248e-01 -1.04779899e-02  8.65814686e-02\n",
      "   2.87872851e-01 -7.49245286e-02 -1.72731400e-01  1.78774893e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471297910>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471297df0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471297df0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471297f10>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471297f10>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-12-1-15-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 0.45282915,  0.9015596 ,  0.10038413,  1.5855013 ,\n",
      "          0.8618043 ,  0.29652393, -0.97716147,  0.897868...796201 , -1.677018  , -0.90897506,\n",
      "          0.00913527,  2.2623196 , -0.0795772 ,  0.6443242 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 1.0048e-02, -2.7640e-02,  1.0278e-02, -2.1637e-04, -2.8525e-02,\n",
      "          -5.1725e-03, -2.2050e-03,  2.7850...1, -3.9016e-02, -2.5733e-01,  8.2694e-02, -3.4867e-01,\n",
      "          -1.3133e-01, -1.4408e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.37687927, -0.09941279,  0.34990618, -1.0207031 ,\n",
      "         -1.6570303 ,  0.24696712, -0.47540152,  1.790961...1383354,  0.79501987, -0.36855558,\n",
      "          0.5416738 , -0.17114279, -0.8866561 , -0.0909861 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 5.1754e-03, -1.3655e-02,  5.1256e-03, -1.0402e-04, -1.4687e-02,\n",
      "          -2.6388e-03, -1.0776e-03,  1.3829...2, -2.1491e-02, -1.3042e-01,  5.4436e-02, -2.0547e-01,\n",
      "          -5.8993e-02, -7.5276e-03]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb461c25100>\n",
      "model_     = LSTM(1, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-8.1448e-03,  4.6258e-02, -1.1886e-02,  ...,  3.7492e-02,\n",
      "           1.1990e-02,  1.9585e-04],\n",
      "         [ 3....7467e-02, -2.6675e-01,  8.0455e-02,  ..., -2.0547e-01,\n",
      "          -5.8993e-02, -7.5276e-03]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 7.7131087e-01],\n",
      "        [-4.2340526e-01],\n",
      "        [-1.8748260e+00],\n",
      "        [ 9.1066353e-02],\n",
      "        [-4.22...       [ 7.1050262e-01],\n",
      "        [-8.8861436e-01],\n",
      "        [ 2.0888166e+00],\n",
      "        [-2.4411685e+00]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 7.7131087e-01]\n",
      "  [-4.2340526e-01]\n",
      "  [-1.8748260e+00]\n",
      "  [ 9.1066353e-02]\n",
      "  [-4.2292774e-02]\n",
      "  [-2.76...7.5167185e-01]\n",
      "  [-1.0891949e+00]\n",
      "  [ 7.1050262e-01]\n",
      "  [-8.8861436e-01]\n",
      "  [ 2.0888166e+00]\n",
      "  [-2.4411685e+00]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461c25100>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 7.7131087e-01]\n",
      "  [-4.2340526e-01]\n",
      "  [-1.8748260e+00]\n",
      "  [ 9.1066353e-02]\n",
      "  [-4.2292774e-02]\n",
      "  [-2.767...0]\n",
      "  [-7.5167185e-01]\n",
      "  [-1.0891949e+00]\n",
      "  [ 7.1050262e-01]\n",
      "  [-8.8861436e-01]\n",
      "  [ 2.0888166e+00]\n",
      "  [-2.4411685e+00]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461c25100>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.77131087]\n",
      " [-0.42340526]\n",
      " [-1.874826  ]\n",
      " [ 0.09106635]\n",
      " [-0.04229277]\n",
      " [-0.27676...0.5354259 ]\n",
      " [ 1.4071375 ]\n",
      " [-0.75167185]\n",
      " [-1.0891949 ]\n",
      " [ 0.7105026 ]\n",
      " [-0.88861436]\n",
      " [ 2.0888166 ]\n",
      " [-2.4411685 ]]))\n",
      "        y          = needle.Tensor([[ 0.77131087]\n",
      " [-0.42340526]\n",
      " [-1.874826  ]\n",
      " [ 0.09106635]\n",
      " [-0.04229277]\n",
      " [-0.27676088]\n",
      " [ 0.30323133]\n",
      " [ 1.2190561 ]\n",
      " [ 0.8327363 ]\n",
      " [ 0.5133242 ]\n",
      " [ 0.09737691]\n",
      " [-1.6149931 ]\n",
      " [-0.986784  ]\n",
      " [ 1.7016771 ]\n",
      " [ 0.78079814]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.77131087]\n",
      " [-0.42340526]\n",
      " [-1.874826  ]\n",
      " [ 0.09106635]\n",
      " [-0.04229277]\n",
      " [-0.27676088]\n",
      " [ 0.30323133... 0.8327363 ]\n",
      " [ 0.5133242 ]\n",
      " [ 0.09737691]\n",
      " [-1.6149931 ]\n",
      " [-0.986784  ]\n",
      " [ 1.7016771 ]\n",
      " [ 0.78079814]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461c25160>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.77131087]\n",
      " [-0.42340526]\n",
      " [-1.874826  ]\n",
      " [ 0.09106635]\n",
      " [-0.04229277]\n",
      " [-0.27676088]\n",
      " [ 0.30323133]\n",
      " [ 1.2190561 ]\n",
      " [ 0.8327363 ]\n",
      " [ 0.5133242 ]\n",
      " [ 0.09737691]\n",
      " [-1.6149931 ]\n",
      " [-0.986784  ]\n",
      " [ 1.7016771 ]\n",
      " [ 0.78079814]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 7.65049458e-02 -1.53445706e-01 -1.40212193e-01 -7.78407082e-02\n",
      "   1.71457395e-01 -4.78017293e-02  1.1...01  1.89246982e-01 -7.98579231e-02 -2.71352828e-02\n",
      "  -2.18761325e-01 -1.54168978e-01  4.96031977e-02 -2.78575718e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461c25160>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.08697915e-02  2.68686414e-02 -1.63932353e-01  1.73233360e-01\n",
      "   2.70910382e-01 -5.64156920e-02 -2.3...01 -5.64384758e-02 -1.17289096e-01 -1.84745714e-01\n",
      "  -1.32906064e-01  1.60432160e-01  2.65095234e-02 -1.52216017e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.08697915e-02  2.68686414e-02 -1.63932353e-01  1.73233360e-01\n",
      "   2.70910382e-01 -5.64156920e-02 -2....4384758e-02 -1.17289096e-01 -1.84745714e-01\n",
      "  -1.32906064e-01  1.60432160e-01  2.65095234e-02 -1.52216017e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46125c8b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.08697915e-02  2.68686414e-02 -1.63932353e-01  1.73233360e-01\n",
      "   2.70910382e-01 -5.64156920e-02 -2....4384758e-02 -1.17289096e-01 -1.84745714e-01\n",
      "  -1.32906064e-01  1.60432160e-01  2.65095234e-02 -1.52216017e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46125c8b0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46125cdc0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46125cdc0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46125c700>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46125c700>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-12-1-15-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 0.09194332,  0.67454326, -0.2794028 , -0.81592363,\n",
      "          0.25751394, -1.6297458 ,  2.7651446 ,  1.036277...654516 , -0.17529264, -0.09414487,\n",
      "          0.2474196 , -0.39436114,  2.475916  ,  1.9121435 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0374,  0.0258, -0.0177, -0.0209,  0.0206, -0.0272, -0.0088,\n",
      "          -0.0363,  0.0364, -0.0314,  0.0049,..., -0.0054, -0.0006,  0.0022,\n",
      "          -0.0009,  0.0035, -0.0014,  0.0041,  0.0015]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-5.85706592e-01, -8.99863616e-02,  4.82275158e-01,\n",
      "         -1.02107495e-01,  3.26082170e-01,  4.79854614e-01..., -2.17061251e-01,  4.23861444e-01,\n",
      "          1.81670213e+00, -1.69149593e-01, -2.73169100e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0193,  0.0124, -0.0087, -0.0107,  0.0107, -0.0139, -0.0042,\n",
      "          -0.0179,  0.0179, -0.0151,  0.0024,..., -0.0027, -0.0003,  0.0011,\n",
      "          -0.0005,  0.0018, -0.0007,  0.0020,  0.0008]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4588e0b20>\n",
      "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0008,  0.0012, -0.0021,  0.0008, -0.0030, -0.0003,  0.0013,\n",
      "          -0.0005,  0.0020, -0.0008,  0.0023,..., -0.0027, -0.0003,  0.0011,\n",
      "          -0.0005,  0.0018, -0.0007,  0.0020,  0.0008]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.2649078 ],\n",
      "        [ 0.38041687],\n",
      "        [ 0.18224764],\n",
      "        [-0.19101733],\n",
      "        [ 0.6202012 ],\n",
      "   ...5806304 ],\n",
      "        [ 0.38209945],\n",
      "        [ 0.19115539],\n",
      "        [ 0.41624004],\n",
      "        [-0.23737672]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.2649078 ]\n",
      "  [ 0.38041687]\n",
      "  [ 0.18224764]\n",
      "  [-0.19101733]\n",
      "  [ 0.6202012 ]\n",
      "  [-1.3365037 ]\n",
      "  [-1.7...[-0.37504998]\n",
      "  [-0.7660486 ]\n",
      "  [ 1.5806304 ]\n",
      "  [ 0.38209945]\n",
      "  [ 0.19115539]\n",
      "  [ 0.41624004]\n",
      "  [-0.23737672]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4588e0b20>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.2649078 ]\n",
      "  [ 0.38041687]\n",
      "  [ 0.18224764]\n",
      "  [-0.19101733]\n",
      "  [ 0.6202012 ]\n",
      "  [-1.3365037 ]\n",
      "  [-1.71...68 ]\n",
      "  [-0.37504998]\n",
      "  [-0.7660486 ]\n",
      "  [ 1.5806304 ]\n",
      "  [ 0.38209945]\n",
      "  [ 0.19115539]\n",
      "  [ 0.41624004]\n",
      "  [-0.23737672]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4588e0b20>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.2649078 ]\n",
      " [ 0.38041687]\n",
      " [ 0.18224764]\n",
      " [-0.19101733]\n",
      " [ 0.6202012 ]\n",
      " [-1.33650....1958468 ]\n",
      " [-0.37504998]\n",
      " [-0.7660486 ]\n",
      " [ 1.5806304 ]\n",
      " [ 0.38209945]\n",
      " [ 0.19115539]\n",
      " [ 0.41624004]\n",
      " [-0.23737672]]),)\n",
      "        y          = needle.Tensor([[-0.2649078 ]\n",
      " [ 0.38041687]\n",
      " [ 0.18224764]\n",
      " [-0.19101733]\n",
      " [ 0.6202012 ]\n",
      " [-1.3365037 ]\n",
      " [-1.7192203 ]\n",
      " [-1.1958468 ]\n",
      " [-0.37504998]\n",
      " [-0.7660486 ]\n",
      " [ 1.5806304 ]\n",
      " [ 0.38209945]\n",
      " [ 0.19115539]\n",
      " [ 0.41624004]\n",
      " [-0.23737672]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.2649078 ]\n",
      " [ 0.38041687]\n",
      " [ 0.18224764]\n",
      " [-0.19101733]\n",
      " [ 0.6202012 ]\n",
      " [-1.3365037 ]\n",
      " [-1.7192203 ...-0.37504998]\n",
      " [-0.7660486 ]\n",
      " [ 1.5806304 ]\n",
      " [ 0.38209945]\n",
      " [ 0.19115539]\n",
      " [ 0.41624004]\n",
      " [-0.23737672]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4588e0e50>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.2649078 ]\n",
      " [ 0.38041687]\n",
      " [ 0.18224764]\n",
      " [-0.19101733]\n",
      " [ 0.6202012 ]\n",
      " [-1.3365037 ]\n",
      " [-1.7192203 ]\n",
      " [-1.1958468 ]\n",
      " [-0.37504998]\n",
      " [-0.7660486 ]\n",
      " [ 1.5806304 ]\n",
      " [ 0.38209945]\n",
      " [ 0.19115539]\n",
      " [ 0.41624004]\n",
      " [-0.23737672]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.01760967 -0.03009092 -0.01303719  0.01465621 -0.00827416  0.03317605\n",
      "   0.01752174  0.00715984  0.0...3194591  0.0456912   0.06495306  0.0459392\n",
      "  -0.06242326 -0.02005878 -0.02608861 -0.06480163 -0.05882204  0.05583213]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4588e0e50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.07912797 -0.06025271 -0.15886243 -0.11690207 -0.27783686  0.24283999\n",
      "  -0.24801907 -0.24860416 -0.0...561681 -0.2544924   0.2343092   0.21511382\n",
      "  -0.21473068  0.16614908  0.00335452 -0.12103765  0.13621894 -0.16583467]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.07912797 -0.06025271 -0.15886243 -0.11690207 -0.27783686  0.24283999\n",
      "  -0.24801907 -0.24860416 -0....-0.2544924   0.2343092   0.21511382\n",
      "  -0.21473068  0.16614908  0.00335452 -0.12103765  0.13621894 -0.16583467]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450ac8fa0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.07912797 -0.06025271 -0.15886243 -0.11690207 -0.27783686  0.24283999\n",
      "  -0.24801907 -0.24860416 -0....-0.2544924   0.2343092   0.21511382\n",
      "  -0.21473068  0.16614908  0.00335452 -0.12103765  0.13621894 -0.16583467]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450ac8fa0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ac86a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ac86a0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb450ac8370>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb450ac8370>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-12-1-15-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-1.0451431 , -0.9673827 ,  1.3201984 , -0.1597305 ,\n",
      "         -0.25892246,  1.766111  ,  0.17227851, -0.381342...448858 , -1.4239867 , -0.1707107 ,\n",
      "          0.65019923, -0.7598031 ,  0.05099341,  0.13650362]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 6.8364e-02, -2.8343e-02,  9.2209e-03, -6.9917e-03,  1.8323e-02,\n",
      "           3.0659e-02,  4.8572e-02, -2.1545...2,  7.8510e-03, -2.5664e-02, -7.0089e-03, -1.4515e-02,\n",
      "          -1.1360e-02,  1.0142e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.4850497 ,  0.720321  , -0.30951032,  0.8562879 ,\n",
      "         -0.8194197 , -2.1432064 , -0.5221574 , -0.145365...4566897,  0.6506889 ,  1.0883588 ,\n",
      "         -1.7427149 , -1.523383  ,  0.35233003, -0.24169205]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 3.6770e-02, -1.2128e-02,  4.4124e-03, -2.9179e-03,  9.2670e-03,\n",
      "           1.7300e-02,  2.5774e-02, -1.0658...2,  3.8980e-03, -1.2694e-02, -3.4703e-03, -7.3836e-03,\n",
      "          -5.7099e-03,  5.0381e-03]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb48118fc40>\n",
      "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-3.8163e-05,  1.2990e-03,  6.8024e-04,  ...,  6.9825e-04,\n",
      "           3.8342e-04,  1.0239e-04],\n",
      "         [-1....2728e-03, -8.6535e-03, -7.0555e-03,  ..., -7.3836e-03,\n",
      "          -5.7099e-03,  5.0381e-03]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.240705  ],\n",
      "        [-1.5881625 ],\n",
      "        [-0.81470174],\n",
      "        [ 0.42884126],\n",
      "        [ 1.0285126 ],\n",
      "   ...08978764],\n",
      "        [-0.31282035],\n",
      "        [-0.7980162 ],\n",
      "        [-0.20247626],\n",
      "        [-1.2963574 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.240705  ]\n",
      "  [-1.5881625 ]\n",
      "  [-0.81470174]\n",
      "  [ 0.42884126]\n",
      "  [ 1.0285126 ]\n",
      "  [ 0.22329456]\n",
      "  [ 0.2...[ 1.8394631 ]\n",
      "  [-1.296714  ]\n",
      "  [ 0.08978764]\n",
      "  [-0.31282035]\n",
      "  [-0.7980162 ]\n",
      "  [-0.20247626]\n",
      "  [-1.2963574 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48118fc40>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.240705  ]\n",
      "  [-1.5881625 ]\n",
      "  [-0.81470174]\n",
      "  [ 0.42884126]\n",
      "  [ 1.0285126 ]\n",
      "  [ 0.22329456]\n",
      "  [ 0.29...581]\n",
      "  [ 1.8394631 ]\n",
      "  [-1.296714  ]\n",
      "  [ 0.08978764]\n",
      "  [-0.31282035]\n",
      "  [-0.7980162 ]\n",
      "  [-0.20247626]\n",
      "  [-1.2963574 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48118fc40>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.240705  ]\n",
      " [-1.5881625 ]\n",
      " [-0.81470174]\n",
      " [ 0.42884126]\n",
      " [ 1.0285126 ]\n",
      " [ 0.22329...0.01139581]\n",
      " [ 1.8394631 ]\n",
      " [-1.296714  ]\n",
      " [ 0.08978764]\n",
      " [-0.31282035]\n",
      " [-0.7980162 ]\n",
      " [-0.20247626]\n",
      " [-1.2963574 ]]))\n",
      "        y          = needle.Tensor([[ 0.240705  ]\n",
      " [-1.5881625 ]\n",
      " [-0.81470174]\n",
      " [ 0.42884126]\n",
      " [ 1.0285126 ]\n",
      " [ 0.22329456]\n",
      " [ 0.29090548]\n",
      " [ 0.98979795]\n",
      " [ 0.19335912]\n",
      " [-0.37128216]\n",
      " [-0.57003593]\n",
      " [ 1.4065989 ]\n",
      " [ 0.46309286]\n",
      " [ 0.10249928]\n",
      " [ 1.3362489 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.240705  ]\n",
      " [-1.5881625 ]\n",
      " [-0.81470174]\n",
      " [ 0.42884126]\n",
      " [ 1.0285126 ]\n",
      " [ 0.22329456]\n",
      " [ 0.29090548... 0.19335912]\n",
      " [-0.37128216]\n",
      " [-0.57003593]\n",
      " [ 1.4065989 ]\n",
      " [ 0.46309286]\n",
      " [ 0.10249928]\n",
      " [ 1.3362489 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb48118f970>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.240705  ]\n",
      " [-1.5881625 ]\n",
      " [-0.81470174]\n",
      " [ 0.42884126]\n",
      " [ 1.0285126 ]\n",
      " [ 0.22329456]\n",
      " [ 0.29090548]\n",
      " [ 0.98979795]\n",
      " [ 0.19335912]\n",
      " [-0.37128216]\n",
      " [-0.57003593]\n",
      " [ 1.4065989 ]\n",
      " [ 0.46309286]\n",
      " [ 0.10249928]\n",
      " [ 1.3362489 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.34213769e-02  2.09405627e-02  1.17277289e-02 -4.73208912e-02\n",
      "   6.62394390e-02 -3.81862521e-02  1.8...02  3.56254548e-01  2.49161243e-01 -1.97149720e-02\n",
      "   2.06948698e-01  3.71505946e-01 -3.61880362e-01 -8.65984559e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb48118f970>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.24737275  0.11219877  0.11509478 -0.05556425  0.01721364  0.05788323\n",
      "  -0.19017512  0.10225692  0.2...208311  -0.05529083 -0.1091273   0.0167937\n",
      "   0.2794932   0.2646724  -0.20824206  0.00881064  0.1190742  -0.19815835]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.24737275  0.11219877  0.11509478 -0.05556425  0.01721364  0.05788323\n",
      "  -0.19017512  0.10225692  0.... -0.05529083 -0.1091273   0.0167937\n",
      "   0.2794932   0.2646724  -0.20824206  0.00881064  0.1190742  -0.19815835]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471cfb1f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.24737275  0.11219877  0.11509478 -0.05556425  0.01721364  0.05788323\n",
      "  -0.19017512  0.10225692  0.... -0.05529083 -0.1091273   0.0167937\n",
      "   0.2794932   0.2646724  -0.20824206  0.00881064  0.1190742  -0.19815835]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471cfb1f0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471cfb1c0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471cfb1c0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471cfb670>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471cfb670>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-12-11-1-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.9579853 ,  1.3722068 , -0.65173703, -2.123213  ,\n",
      "         -0.45189887,  1.6884196 , -0.1513394 , -0.912039  ,\n",
      "         -0.52724123, -0.73637164, -0.03609249, -0.40242755]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.1835,  0.3269, -0.0838,  0.1336,  0.2860, -0.2511,  0.1097,\n",
      "          -0.1832, -0.0836,  0.1341,  0.2626,  0.3085]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.7308976 , -1.2732593 , -0.4230726 , -0.52694476,\n",
      "         -0.12128946, -0.8997628 ,  0.09961547, -0.4844507 ,\n",
      "         -0.44016248, -1.2429923 ,  2.1393847 , -1.6208814 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0505,  0.1097, -0.0557,  0.0582,  0.2015, -0.0909,  0.0736,\n",
      "          -0.0710, -0.0372,  0.0579,  0.0938,  0.1810]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb471d4ad00>\n",
      "model_     = LSTM(11, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0505,  0.1097, -0.0557,  0.0582,  0.2015, -0.0909,  0.0736,\n",
      "          -0.0710, -0.0372,  0.0579,  0.0938,  0.1810]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.8635484 , -0.44236147,  0.3438219 , -0.8671674 ,\n",
      "         -0.05338816,  0.2666709 ,  1.6839864 ,  2.1441927 ,\n",
      "         -0.6960457 ,  0.5749641 ,  0.423703  ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.8635484  -0.44236147  0.3438219  -0.8671674  -0.05338816\n",
      "    0.2666709   1.6839864   2.1441927  -0.6960457   0.5749641\n",
      "    0.423703  ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d4ad00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.8635484  -0.44236147  0.3438219  -0.8671674  -0.05338816\n",
      "    0.2666709   1.6839864   2.1441927  -0.6960457   0.5749641\n",
      "    0.423703  ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471d4ad00>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.8635484  -0.44236147  0.3438219  -0.8671674  -0.05338816  0.2666709\n",
      "   1.6839864   2.1441927  -0.6960457   0.5749641   0.423703  ]]),)\n",
      "        y          = needle.Tensor([[-0.8635484  -0.44236147  0.3438219  -0.8671674  -0.05338816  0.2666709\n",
      "   1.6839864   2.1441927  -0.6960457   0.5749641   0.423703  ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.8635484  -0.44236147  0.3438219  -0.8671674  -0.05338816  0.2666709\n",
      "   1.6839864   2.1441927  -0.6960457   0.5749641   0.423703  ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d4a2e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.8635484  -0.44236147  0.3438219  -0.8671674  -0.05338816  0.2666709\n",
      "   1.6839864   2.1441927  -0.6960457   0.5749641   0.423703  ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.87536895  0.10370645 -0.00549095 -0.23457637  0.07516018 -0.49495277\n",
      "  -0.05963506 -0.311283   -0.0...90869   -0.24872975  0.9627705  -0.5345653\n",
      "   0.7237845  -0.43928486 -0.21487147 -0.2620934  -0.55119854  0.427673  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471d4a2e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-1.78077370e-01 -1.15066767e-04 -2.66721994e-01 -8.25158656e-02\n",
      "   1.23143137e-01  2.79914439e-01 -2.6...02  1.01327032e-01 -4.55138236e-02 -1.67669237e-01\n",
      "   2.07456529e-01  2.61085093e-01  1.86830878e-01 -6.85417801e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-1.78077370e-01 -1.15066767e-04 -2.66721994e-01 -8.25158656e-02\n",
      "   1.23143137e-01  2.79914439e-01 -2....1327032e-01 -4.55138236e-02 -1.67669237e-01\n",
      "   2.07456529e-01  2.61085093e-01  1.86830878e-01 -6.85417801e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471d4aa90>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-1.78077370e-01 -1.15066767e-04 -2.66721994e-01 -8.25158656e-02\n",
      "   1.23143137e-01  2.79914439e-01 -2....1327032e-01 -4.55138236e-02 -1.67669237e-01\n",
      "   2.07456529e-01  2.61085093e-01  1.86830878e-01 -6.85417801e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471d4aa90>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d4a220>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471d4a220>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471d4aa00>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471d4aa00>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-12-11-1-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[ 0.51412416,  1.358628  ,  0.04625287, -1.1077951 ,\n",
      "         -0.7678557 , -0.14947829, -0.05249583, -0.4437394 ,\n",
      "         -0.36395887,  1.0989543 ,  0.8917971 ,  0.2778143 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.1389,  0.1644, -0.0740,  0.0164, -0.2272,  0.0630,  0.0617,\n",
      "           0.0147, -0.2129, -0.4009,  0.1557,  0.2287]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.04897539,  0.91982794,  1.0085872 ,  0.8139971 ,\n",
      "          1.5464685 ,  1.0603906 , -1.147442  , -0.27602753,\n",
      "         -0.05117771,  0.0370606 , -0.2723881 , -0.51781017]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0825,  0.0853, -0.0492,  0.0063, -0.0722,  0.0377,  0.0385,\n",
      "           0.0064, -0.0792, -0.1036,  0.0923,  0.0540]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4612619a0>\n",
      "model_     = LSTM(11, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 7.8619e-02, -1.6763e-01, -1.6441e-01,  5.9298e-02,  5.9886e-02,\n",
      "          -2.4971e-01,  7.6538e-02, -2.4837...2,  3.8536e-02,  6.4357e-03, -7.9164e-02, -1.0363e-01,\n",
      "           9.2286e-02,  5.3978e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-8.93812239e-01, -1.48939133e+00,  4.11999449e-02,\n",
      "         -3.10271335e+00,  4.72809255e-01,  7.63187110e-02...         2.33509675e-01,  1.05147315e-02, -3.83515120e-01,\n",
      "          2.95908660e-01, -2.89348327e-02]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-8.93812239e-01 -1.48939133e+00  4.11999449e-02 -3.10271335e+00\n",
      "    4.72809255e-01  7.63187110e-02 -...90474e-01 -1.81608033e+00  2.33509675e-01  1.05147315e-02\n",
      "   -3.83515120e-01  2.95908660e-01 -2.89348327e-02]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4612619a0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-8.93812239e-01 -1.48939133e+00  4.11999449e-02 -3.10271335e+00\n",
      "    4.72809255e-01  7.63187110e-02 -3...  2.30390474e-01 -1.81608033e+00  2.33509675e-01  1.05147315e-02\n",
      "   -3.83515120e-01  2.95908660e-01 -2.89348327e-02]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4612619a0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.89381224 -1.4893913   0.04119994 -3.1027133   0.47280926  0.07631871\n",
      "  -0.395167...13684  -1.3590237  -0.24266136  0.23039047 -1.8160803\n",
      "   0.23350967  0.01051473 -0.38351512  0.29590866 -0.02893483]]))\n",
      "        y          = needle.Tensor([[-0.89381224 -1.4893913   0.04119994 -3.1027133   0.47280926  0.07631871\n",
      "  -0.39516768 -0.40661854 -1.1170716  -0.97448784 -0.70301205]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.89381224 -1.4893913   0.04119994 -3.1027133   0.47280926  0.07631871\n",
      "  -0.39516768 -0.40661854 -1.1170716  -0.97448784 -0.70301205]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461261760>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.89381224 -1.4893913   0.04119994 -3.1027133   0.47280926  0.07631871\n",
      "  -0.39516768 -0.40661854 -1.1170716  -0.97448784 -0.70301205]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.0298774  -0.2635563  -0.12632118  0.3988347  -0.1739919   0.23570085\n",
      "   0.9450624  -0.31616265 -0.1...0046147  0.18510988 -0.8814319   0.8216079\n",
      "  -0.49961674 -0.65308523 -1.0364165   0.22764903  0.7617669  -0.3593524 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461261760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 2.31895149e-02  2.46350229e-01  2.42677987e-01  1.94761515e-01\n",
      "   1.49549574e-01 -8.08522254e-02  4.3...01  1.90854996e-01 -9.12299752e-03 -1.59723997e-01\n",
      "  -2.31761381e-01  2.20820904e-01 -2.23137200e-01 -9.00779366e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 2.31895149e-02  2.46350229e-01  2.42677987e-01  1.94761515e-01\n",
      "   1.49549574e-01 -8.08522254e-02  4....0854996e-01 -9.12299752e-03 -1.59723997e-01\n",
      "  -2.31761381e-01  2.20820904e-01 -2.23137200e-01 -9.00779366e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4719d50d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 2.31895149e-02  2.46350229e-01  2.42677987e-01  1.94761515e-01\n",
      "   1.49549574e-01 -8.08522254e-02  4....0854996e-01 -9.12299752e-03 -1.59723997e-01\n",
      "  -2.31761381e-01  2.20820904e-01 -2.23137200e-01 -9.00779366e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4719d50d0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4719d52b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4719d52b0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4719d5d90>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4719d5d90>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[cpu-False-False-12-11-1-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.35333818, -0.48773447,  1.2448149 , -0.28019956,\n",
      "         -0.14012082,  0.00564459, -0.75151616, -2.665968...6088827, -0.06868552,  0.02125139,\n",
      "          0.0970984 , -1.1753157 ,  0.72976243,  1.0915302 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0304, -0.0032, -0.2800, -0.0748, -0.3863,  0.0341, -0.0176,\n",
      "          -0.1473, -0.0539,  0.0674, -0.0210,..., -0.0083,  0.0491,  0.0327,\n",
      "           0.0429,  0.0139,  0.0073, -0.0077, -0.0169]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-1.1658106 ,  1.5344943 ,  0.60819244,  1.0407126 ,\n",
      "         -1.7942989 ,  0.5513623 , -0.6247852 ,  1.994535...5220708,  2.31873   ,  0.10348514,\n",
      "          0.19585498,  1.255467  , -0.8828525 , -0.4609998 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0164, -0.0022, -0.0974, -0.0339, -0.2202,  0.0218, -0.0066,\n",
      "          -0.0526, -0.0339,  0.0350, -0.0100,..., -0.0039,  0.0250,  0.0160,\n",
      "           0.0214,  0.0071,  0.0035, -0.0037, -0.0085]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4302380d0>\n",
      "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0108,  0.0102, -0.0047,  0.0302, -0.0039,  0.0250,  0.0160,\n",
      "           0.0214,  0.0071,  0.0035, -0.0037, -0.0085]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.31792963,  1.0350059 , -0.5097138 ,  1.1185412 ,\n",
      "         -1.6398972 , -0.08557685, -0.27211785,  0.28264257,\n",
      "          1.4530636 , -0.32694873,  0.29049158]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.31792963  1.0350059  -0.5097138   1.1185412  -1.6398972\n",
      "   -0.08557685 -0.27211785  0.28264257  1.4530636  -0.32694873\n",
      "    0.29049158]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4302380d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.31792963  1.0350059  -0.5097138   1.1185412  -1.6398972\n",
      "   -0.08557685 -0.27211785  0.28264257  1.4530636  -0.32694873\n",
      "    0.29049158]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4302380d0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.31792963  1.0350059  -0.5097138   1.1185412  -1.6398972  -0.08557685\n",
      "  -0.27211785  0.28264257  1.4530636  -0.32694873  0.29049158]]),)\n",
      "        y          = needle.Tensor([[-0.31792963  1.0350059  -0.5097138   1.1185412  -1.6398972  -0.08557685\n",
      "  -0.27211785  0.28264257  1.4530636  -0.32694873  0.29049158]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.31792963  1.0350059  -0.5097138   1.1185412  -1.6398972  -0.08557685\n",
      "  -0.27211785  0.28264257  1.4530636  -0.32694873  0.29049158]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb430238640>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.31792963  1.0350059  -0.5097138   1.1185412  -1.6398972  -0.08557685\n",
      "  -0.27211785  0.28264257  1.4530636  -0.32694873  0.29049158]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 9.5984757e-02 -4.1706783e-01 -2.2260596e-01 -1.4688665e-03\n",
      "   1.5052688e-01 -3.7441742e-01 -3.4260422...96370e-01  5.7441866e-01 -5.0187594e-01 -5.7590348e-01\n",
      "   5.2790028e-01  8.0512412e-02 -9.8219052e-02 -1.2793223e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb430238640>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.39145085e-01  2.38083839e-01  1.97155982e-01  1.25218183e-01\n",
      "   1.87084079e-03 -1.40496030e-01  6.8...02 -6.75336868e-02  2.12855160e-01  2.80030370e-01\n",
      "  -6.58062100e-02  2.31278181e-01  2.86398530e-02 -2.43110329e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.39145085e-01  2.38083839e-01  1.97155982e-01  1.25218183e-01\n",
      "   1.87084079e-03 -1.40496030e-01  6....5336868e-02  2.12855160e-01  2.80030370e-01\n",
      "  -6.58062100e-02  2.31278181e-01  2.86398530e-02 -2.43110329e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4382fceb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.39145085e-01  2.38083839e-01  1.97155982e-01  1.25218183e-01\n",
      "   1.87084079e-03 -1.40496030e-01  6....5336868e-02  2.12855160e-01  2.80030370e-01\n",
      "  -6.58062100e-02  2.31278181e-01  2.86398530e-02 -2.43110329e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4382fceb0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4382fce50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4382fce50>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4382fcc40>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4382fcc40>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-12-11-1-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.87854266, -2.1004653 , -1.1996763 , -0.42917317,\n",
      "          0.8911072 , -0.5267291 , -0.68665   ,  0.539965...940079 ,  1.4088441 , -0.22980535,\n",
      "          0.60570633,  0.098719  , -0.6979875 , -0.10004253]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.1487, -0.4887, -0.0719, -0.0329,  0.0840, -0.0048, -0.3890,\n",
      "          -0.0647, -0.2564, -0.0211,  0.1375,...,  0.0043,  0.0153, -0.0225,\n",
      "          -0.0116,  0.0362, -0.0394,  0.0626, -0.0426]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 0.10272103, -1.4510498 , -3.1976852 , -0.87114996,\n",
      "          0.19069098,  0.5308425 , -0.613112  , -1.022891...1993482, -2.183336  , -0.05261718,\n",
      "          1.396179  ,  0.03784915,  0.31346035,  0.8364799 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0809, -0.2383, -0.0341, -0.0198,  0.0522, -0.0029, -0.1701,\n",
      "          -0.0376, -0.1366, -0.0061,  0.0809,...,  0.0022,  0.0079, -0.0110,\n",
      "          -0.0057,  0.0184, -0.0202,  0.0320, -0.0218]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb46239daf0>\n",
      "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0018,  0.0036,  0.0061, -0.0077,  0.0214,  0.0120,  0.0047,\n",
      "          -0.0220,  0.0098, -0.0002,  0.0208,...,  0.0022,  0.0079, -0.0110,\n",
      "          -0.0057,  0.0184, -0.0202,  0.0320, -0.0218]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.04417643,  0.725918  ,  1.2099941 , -1.485649  ,\n",
      "         -0.52249306, -0.15034331,  0.7326631 , -1.583252...  -1.1023436 , -0.07814832,  0.6648317 , -1.0232564 ,\n",
      "         -1.0149423 , -0.40516183, -0.44243234]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.04417643  0.725918    1.2099941  -1.485649   -0.52249306\n",
      "   -0.15034331  0.7326631  -1.5832521   ...3000335 -1.2526375  -1.1023436\n",
      "   -0.07814832  0.6648317  -1.0232564  -1.0149423  -0.40516183\n",
      "   -0.44243234]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46239daf0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.04417643  0.725918    1.2099941  -1.485649   -0.52249306\n",
      "   -0.15034331  0.7326631  -1.5832521   0...34  0.43000335 -1.2526375  -1.1023436\n",
      "   -0.07814832  0.6648317  -1.0232564  -1.0149423  -0.40516183\n",
      "   -0.44243234]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46239daf0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.04417643  0.725918    1.2099941  -1.485649   -0.52249306 -0.15034331\n",
      "   0.732663...43034  0.43000335 -1.2526375  -1.1023436  -0.07814832\n",
      "   0.6648317  -1.0232564  -1.0149423  -0.40516183 -0.44243234]]))\n",
      "        y          = needle.Tensor([[-0.04417643  0.725918    1.2099941  -1.485649   -0.52249306 -0.15034331\n",
      "   0.7326631  -1.5832521   0.13853317 -0.8014133   0.74622184]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.04417643  0.725918    1.2099941  -1.485649   -0.52249306 -0.15034331\n",
      "   0.7326631  -1.5832521   0.13853317 -0.8014133   0.74622184]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46239d910>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.04417643  0.725918    1.2099941  -1.485649   -0.52249306 -0.15034331\n",
      "   0.7326631  -1.5832521   0.13853317 -0.8014133   0.74622184]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.33704367  0.16709502 -0.63136435  0.07006033  0.02478801  0.36294824\n",
      "  -0.5563178   0.07334504 -0.5...788124  0.70834225  0.57186544  0.04836009\n",
      "  -0.7185553  -0.0885424   0.03857501 -0.7212252   0.4476609   0.73426944]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46239d910>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.24710852 -0.08641487 -0.1642165  -0.00430629  0.23918831  0.17100209\n",
      "  -0.25382224  0.2424314  -0.0...572921 -0.14614582  0.22283131  0.26142228\n",
      "   0.2872545  -0.19963032  0.00648364  0.06201082  0.04670751  0.17644274]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.24710852 -0.08641487 -0.1642165  -0.00430629  0.23918831  0.17100209\n",
      "  -0.25382224  0.2424314  -0....-0.14614582  0.22283131  0.26142228\n",
      "   0.2872545  -0.19963032  0.00648364  0.06201082  0.04670751  0.17644274]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450ad1c40>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.24710852 -0.08641487 -0.1642165  -0.00430629  0.23918831  0.17100209\n",
      "  -0.25382224  0.2424314  -0....-0.14614582  0.22283131  0.26142228\n",
      "   0.2872545  -0.19963032  0.00648364  0.06201082  0.04670751  0.17644274]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450ad1c40>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ad1910>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ad1910>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb450ad1070>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb450ad1070>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-12-11-15-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 2.76533270e+00, -1.39643872e+00, -5.19397594e-02,\n",
      "         -3.87277037e-01, -1.53615609e-01,  1.34555018e+00...,  1.49091089e+00,  1.23400740e-01,\n",
      "          6.79029524e-01, -4.31764960e-01, -9.24204826e-01]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-6.4873e-02,  2.0167e-01,  2.3137e-02,  1.0113e-01,  3.7713e-01,\n",
      "           2.2404e-01, -1.2718e-01, -6.3815...1, -2.2186e-01, -4.4879e-02,  4.3595e-02, -2.7634e-02,\n",
      "          -1.4400e-02, -3.1608e-01]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-0.43475536,  1.4306375 , -0.77177745, -0.47005236,\n",
      "          1.2018882 , -0.18883455,  0.70282483,  0.791798...457649 , -1.3687376 ,  0.65939486,\n",
      "         -1.5004095 , -1.0354568 , -0.6034306 ,  0.46532288]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-3.4585e-02,  1.0756e-01,  1.4582e-02,  5.1783e-02,  1.8946e-01,\n",
      "           1.6025e-01, -6.2254e-02, -2.2758...1, -1.0531e-01, -2.0938e-02,  2.1678e-02, -1.2586e-02,\n",
      "          -7.7240e-03, -1.5570e-01]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4588e01c0>\n",
      "model_     = LSTM(11, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-3.4585e-02,  1.0756e-01,  1.4582e-02,  5.1783e-02,  1.8946e-01,\n",
      "           1.6025e-01, -6.2254e-02, -2.2758...1, -1.0531e-01, -2.0938e-02,  2.1678e-02, -1.2586e-02,\n",
      "          -7.7240e-03, -1.5570e-01]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.5799586 ,  0.96216285, -0.22222534, -0.541669  ,\n",
      "         -0.8017363 ,  0.02659033, -1.0089527 , -1.901146...   0.7352097 , -0.7285355 ,  0.76123595,  0.2468652 ,\n",
      "          0.14811581, -0.60484505,  1.4021839 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.5799586   0.96216285 -0.22222534 -0.541669   -0.8017363\n",
      "    0.02659033 -1.0089527  -1.9011465   0...0969167 -0.7951935   0.7352097\n",
      "   -0.7285355   0.76123595  0.2468652   0.14811581 -0.60484505\n",
      "    1.4021839 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4588e01c0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.5799586   0.96216285 -0.22222534 -0.541669   -0.8017363\n",
      "    0.02659033 -1.0089527  -1.9011465   0....5   0.30969167 -0.7951935   0.7352097\n",
      "   -0.7285355   0.76123595  0.2468652   0.14811581 -0.60484505\n",
      "    1.4021839 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4588e01c0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.5799586   0.96216285 -0.22222534 -0.541669   -0.8017363   0.02659033\n",
      "  -1.008952...8655   0.30969167 -0.7951935   0.7352097  -0.7285355\n",
      "   0.76123595  0.2468652   0.14811581 -0.60484505  1.4021839 ]]),)\n",
      "        y          = needle.Tensor([[-0.5799586   0.96216285 -0.22222534 -0.541669   -0.8017363   0.02659033\n",
      "  -1.0089527  -1.9011465   0.7...158655   0.30969167 -0.7951935   0.7352097  -0.7285355\n",
      "   0.76123595  0.2468652   0.14811581 -0.60484505  1.4021839 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.5799586   0.96216285 -0.22222534 -0.541669   -0.8017363   0.02659033\n",
      "  -1.0089527  -1.9011465   0....9167 -0.7951935   0.7352097  -0.7285355\n",
      "   0.76123595  0.2468652   0.14811581 -0.60484505  1.4021839 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4588e0340>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.5799586   0.96216285 -0.22222534 -0.541669   -0.8017363   0.02659033\n",
      "  -1.0089527  -1.9011465   0.7...158655   0.30969167 -0.7951935   0.7352097  -0.7285355\n",
      "   0.76123595  0.2468652   0.14811581 -0.60484505  1.4021839 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.06676316e+00 -5.54771423e-01  4.08466995e-01 -2.17778400e-01\n",
      "   1.29538238e-01 -5.58540344e-01  9.1...01 -2.16650218e-01 -7.04005510e-02 -1.32767767e-01\n",
      "  -9.68356431e-03 -1.78184479e-01  1.45963937e-01  3.55727077e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4588e0340>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.02300242  0.08493027  0.03842381  0.16656384  0.11755285 -0.07489668\n",
      "  -0.28387713 -0.20646289  0.1...478869 -0.24162662 -0.1141659   0.19921601\n",
      "  -0.24137989  0.11104631 -0.04241297 -0.15725584  0.25093395 -0.06573181]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.02300242  0.08493027  0.03842381  0.16656384  0.11755285 -0.07489668\n",
      "  -0.28387713 -0.20646289  0....-0.24162662 -0.1141659   0.19921601\n",
      "  -0.24137989  0.11104631 -0.04241297 -0.15725584  0.25093395 -0.06573181]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4588e09a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.02300242  0.08493027  0.03842381  0.16656384  0.11755285 -0.07489668\n",
      "  -0.28387713 -0.20646289  0....-0.24162662 -0.1141659   0.19921601\n",
      "  -0.24137989  0.11104631 -0.04241297 -0.15725584  0.25093395 -0.06573181]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4588e09a0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4588e0a90>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4588e0a90>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4588e0160>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4588e0160>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-12-11-15-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 0.18710439,  0.8995231 ,  0.55874294, -1.0887271 ,\n",
      "          0.6293252 ,  0.9476218 , -0.6144782 ,  1.640552...631275 , -0.39103103,  1.1367195 ,\n",
      "          0.3503302 , -0.7880253 , -0.98944175, -0.33511573]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.4061,  0.0786,  0.0307,  0.0307,  0.2815, -0.1719,  0.3058,\n",
      "          -0.2535, -0.3214,  0.1414, -0.5300,...,  0.0343, -0.3608,  0.0666,\n",
      "           0.1004, -0.3222, -0.0057,  0.0476,  0.1088]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-2.3899088 ,  0.22186461,  1.2513125 ,  0.45388266,\n",
      "          1.401744  ,  0.66184187,  0.3239751 ,  0.688693...3915409, -2.0953727 ,  0.7275757 ,\n",
      "          2.5953474 ,  1.0659763 , -0.43060622, -1.6876087 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.1545,  0.0361,  0.0130,  0.0121,  0.1063, -0.0963,  0.1423,\n",
      "          -0.1486, -0.0402,  0.0698, -0.3178,...,  0.0114, -0.2472,  0.0364,\n",
      "           0.0642, -0.1271, -0.0025,  0.0291,  0.0720]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4712b4940>\n",
      "model_     = LSTM(11, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.0507, -0.0590,  0.1326,  ...,  0.0363,  0.0193, -0.0951],\n",
      "         [ 0.0460,  0.1795,  0.0873,  ...,  0.0...58,  0.0052],\n",
      "         [ 0.1625, -0.1370, -0.1526,  ..., -0.0025,  0.0291,  0.0720]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.7349359 ,  0.0625132 ,  0.45431235, ..., -0.75304437,\n",
      "          1.1322172 ,  0.81422925],\n",
      "        [ 0.4216...\n",
      "        [-1.4147427 ,  1.6004219 , -0.10690917, ...,  2.139371  ,\n",
      "          2.2524574 , -0.03174698]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.7349359   0.0625132   0.45431235 ... -0.75304437  1.1322172\n",
      "    0.81422925]\n",
      "  [ 0.42166656 -0.386...64  1.23789\n",
      "   -0.29532853]\n",
      "  [-1.4147427   1.6004219  -0.10690917 ...  2.139371    2.2524574\n",
      "   -0.03174698]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4712b4940>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.7349359   0.0625132   0.45431235 ... -0.75304437  1.1322172\n",
      "    0.81422925]\n",
      "  [ 0.42166656 -0.3861....04638164  1.23789\n",
      "   -0.29532853]\n",
      "  [-1.4147427   1.6004219  -0.10690917 ...  2.139371    2.2524574\n",
      "   -0.03174698]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4712b4940>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.7349359   0.0625132   0.45431235 -0.8471803   0.08599271  0.38823012\n",
      "   0.036385...53e-01\n",
      "  -8.7878382e-01 -3.3942204e-02 -2.2206695e+00  6.0787040e-01\n",
      "   2.1393709e+00  2.2524574e+00 -3.1746976e-02]]))\n",
      "        y          = needle.Tensor([[ 0.7349359   0.0625132   0.45431235 -0.8471803   0.08599271  0.38823012\n",
      "   0.03638576 -0.5506308  -0.7...876024   1.1243199  -0.31708905 -0.01230725  0.2902499\n",
      "   0.28070578  1.5734735   0.7760858   0.5489578  -0.19489379]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.7349359   0.0625132   0.45431235 -0.8471803   0.08599271  0.38823012\n",
      "   0.03638576 -0.5506308  -0....199  -0.31708905 -0.01230725  0.2902499\n",
      "   0.28070578  1.5734735   0.7760858   0.5489578  -0.19489379]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4712b45e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.7349359   0.0625132   0.45431235 -0.8471803   0.08599271  0.38823012\n",
      "   0.03638576 -0.5506308  -0.7...876024   1.1243199  -0.31708905 -0.01230725  0.2902499\n",
      "   0.28070578  1.5734735   0.7760858   0.5489578  -0.19489379]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.5470865   0.02751603  0.37837964 -0.50718105 -0.5705333   0.9239657\n",
      "  -0.6825831  -0.2458694  -0.40...832379 -0.18359046  0.24478143  0.22484796\n",
      "  -0.05387639 -0.10290496  0.10688058 -0.30718198 -0.20742682  0.18709145]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4712b45e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-8.35635662e-02  2.38197207e-01 -2.72818863e-01  2.52559245e-01\n",
      "   2.75435388e-01 -2.16848254e-02  1.4...01  1.61693543e-01 -4.05215770e-02 -1.77407533e-01\n",
      "   1.79994106e-01 -7.20490962e-02  2.17929482e-03 -2.25683123e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-8.35635662e-02  2.38197207e-01 -2.72818863e-01  2.52559245e-01\n",
      "   2.75435388e-01 -2.16848254e-02  1....1693543e-01 -4.05215770e-02 -1.77407533e-01\n",
      "   1.79994106e-01 -7.20490962e-02  2.17929482e-03 -2.25683123e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4382fad30>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-8.35635662e-02  2.38197207e-01 -2.72818863e-01  2.52559245e-01\n",
      "   2.75435388e-01 -2.16848254e-02  1....1693543e-01 -4.05215770e-02 -1.77407533e-01\n",
      "   1.79994106e-01 -7.20490962e-02  2.17929482e-03 -2.25683123e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4382fad30>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4382fa370>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4382fa370>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4382fa7f0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4382fa7f0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-12-11-15-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 1.28637612e+00,  4.78290170e-01,  5.00621438e-01,\n",
      "          3.76679391e-01, -6.35641813e-01, -1.61230493e+00..., -3.67167220e-02,  7.42809534e-01,\n",
      "         -5.31697333e-01, -1.06745052e+00,  2.41630888e+00]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 2.4379e-02,  1.2703e-02,  3.3083e-02, -2.5414e-01, -1.5302e-01,\n",
      "          -3.8210e-01, -2.3579e-01, -1.0245...2, -4.0250e-03, -1.1642e-03, -3.3682e-02,  1.3260e-02,\n",
      "          -3.5421e-03, -1.8127e-03]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[ 1.20522249e+00, -6.76377118e-01,  1.24514794e+00,\n",
      "         -2.74134725e-01, -1.06265175e+00, -1.39960325e+00..., -1.51760781e+00,  4.83074158e-01,\n",
      "         -8.27225447e-01,  1.39145172e+00, -1.43367136e+00]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 1.7176e-02,  6.7550e-03,  1.8591e-02, -1.0012e-01, -6.6691e-02,\n",
      "          -1.8840e-01, -9.6745e-02, -4.3891...3, -1.9889e-03, -6.1194e-04, -1.5990e-02,  6.6267e-03,\n",
      "          -1.7619e-03, -8.6428e-04]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb46123c7f0>\n",
      "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 1.4617e-03,  2.0400e-02,  7.0494e-03, -1.0416e-02,  3.2305e-03,\n",
      "          -1.2944e-02,  9.4835e-03, -1.0715...3, -1.9889e-03, -6.1194e-04, -1.5990e-02,  6.6267e-03,\n",
      "          -1.7619e-03, -8.6428e-04]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.19325411, -0.75316006, -1.5399835 , -0.47861782,\n",
      "         -0.01812887,  0.34374523,  0.0718303 ,  1.181486...   1.3444077 , -1.3607318 ,  0.9617779 , -0.20570089,\n",
      "         -0.48816216, -0.5236783 , -1.1685917 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.19325411 -0.75316006 -1.5399835  -0.47861782 -0.01812887\n",
      "    0.34374523  0.0718303   1.1814865   ...9198115  -1.0884352   1.3444077\n",
      "   -1.3607318   0.9617779  -0.20570089 -0.48816216 -0.5236783\n",
      "   -1.1685917 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46123c7f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.19325411 -0.75316006 -1.5399835  -0.47861782 -0.01812887\n",
      "    0.34374523  0.0718303   1.1814865   0...36  -0.9198115  -1.0884352   1.3444077\n",
      "   -1.3607318   0.9617779  -0.20570089 -0.48816216 -0.5236783\n",
      "   -1.1685917 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46123c7f0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.19325411 -0.75316006 -1.5399835  -0.47861782 -0.01812887  0.34374523\n",
      "   0.071830...7836  -0.9198115  -1.0884352   1.3444077  -1.3607318\n",
      "   0.9617779  -0.20570089 -0.48816216 -0.5236783  -1.1685917 ]]),)\n",
      "        y          = needle.Tensor([[ 0.19325411 -0.75316006 -1.5399835  -0.47861782 -0.01812887  0.34374523\n",
      "   0.0718303   1.1814865   0.7...927836  -0.9198115  -1.0884352   1.3444077  -1.3607318\n",
      "   0.9617779  -0.20570089 -0.48816216 -0.5236783  -1.1685917 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.19325411 -0.75316006 -1.5399835  -0.47861782 -0.01812887  0.34374523\n",
      "   0.0718303   1.1814865   0....115  -1.0884352   1.3444077  -1.3607318\n",
      "   0.9617779  -0.20570089 -0.48816216 -0.5236783  -1.1685917 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461075040>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.19325411 -0.75316006 -1.5399835  -0.47861782 -0.01812887  0.34374523\n",
      "   0.0718303   1.1814865   0.7...927836  -0.9198115  -1.0884352   1.3444077  -1.3607318\n",
      "   0.9617779  -0.20570089 -0.48816216 -0.5236783  -1.1685917 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.18539789e-01  6.95738256e-01  5.38309515e-02 -4.62092131e-01\n",
      "  -6.90165520e-01  5.70168436e-01  2.3...01  4.24912214e-01  8.20479929e-01  2.10070759e-01\n",
      "  -2.95499235e-01  8.34038854e-02  4.51763600e-01  4.85882044e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461075040>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.54103869e-01 -1.06979012e-02 -1.95107013e-01 -1.80913329e-01\n",
      "  -7.92322457e-02 -1.93392336e-01 -2.7...01  6.97416067e-02 -2.37358168e-01  2.21907914e-01\n",
      "   9.75001156e-02  1.41508222e-01  2.70954013e-01  2.08682626e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.54103869e-01 -1.06979012e-02 -1.95107013e-01 -1.80913329e-01\n",
      "  -7.92322457e-02 -1.93392336e-01 -2....7416067e-02 -2.37358168e-01  2.21907914e-01\n",
      "   9.75001156e-02  1.41508222e-01  2.70954013e-01  2.08682626e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4811dd160>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.54103869e-01 -1.06979012e-02 -1.95107013e-01 -1.80913329e-01\n",
      "  -7.92322457e-02 -1.93392336e-01 -2....7416067e-02 -2.37358168e-01  2.21907914e-01\n",
      "   9.75001156e-02  1.41508222e-01  2.70954013e-01  2.08682626e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4811dd160>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4811dd2b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4811dd2b0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4811ddac0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4811ddac0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[cpu-False-False-12-11-15-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = cpu()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 0.1663477 ,  1.3922178 , -1.1809074 ,  0.9013854 ,\n",
      "          0.42484492,  0.769129  , -1.0443716 ,  1.212430...946888 ,  0.72746825,  0.52418405,\n",
      "         -0.30105516,  0.9795667 , -0.6206588 ,  0.65475714]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-8.9891e-03,  5.6754e-02,  2.3097e-02, -6.9695e-01, -1.4806e-02,\n",
      "          -3.0235e-01,  1.0576e-01,  5.6141...1,  1.7962e-02,  7.4945e-02,  3.7903e-03, -5.0773e-03,\n",
      "          -3.5007e-02,  2.7251e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = cpu()\n",
      "h0         = array([[[-4.10642207e-01, -1.56832919e-01, -1.13064051e+00,\n",
      "          1.79075134e+00,  2.40597397e-01,  1.40907753e+00...,  5.26578307e-01, -5.28460622e-01,\n",
      "          3.94555330e-01, -6.64723158e-01, -9.07799542e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-6.5714e-03,  3.6737e-02,  1.3502e-02, -3.4551e-01, -9.7836e-03,\n",
      "          -1.2949e-01,  5.6673e-02,  2.0799...2,  8.5122e-03,  3.7330e-02,  1.8164e-03, -2.6768e-03,\n",
      "          -1.6921e-02,  1.3474e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb48128f6d0>\n",
      "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0053, -0.0053,  0.0185,  ..., -0.0134,  0.0034, -0.0096],\n",
      "         [-0.0144,  0.0175, -0.0214,  ...,  0.0...94, -0.0103],\n",
      "         [ 0.0012, -0.0157,  0.0277,  ..., -0.0027, -0.0169,  0.0135]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-1.5571866e+00,  1.5350361e+00,  7.0298729e-03, ...,\n",
      "         -8.9973456e-01,  6.1617750e-01,  1.6725804e+00]...53e+00, -9.2403144e-01, -1.1026605e+00, ...,\n",
      "         -4.8790646e-01, -8.2720101e-01,  2.5741493e-03]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.5571866e+00  1.5350361e+00  7.0298729e-03 ... -8.9973456e-01\n",
      "    6.1617750e-01  1.6725804e+00]\n",
      "  ...413e+00]\n",
      "  [-1.0511553e+00 -9.2403144e-01 -1.1026605e+00 ... -4.8790646e-01\n",
      "   -8.2720101e-01  2.5741493e-03]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48128f6d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-1.5571866e+00  1.5350361e+00  7.0298729e-03 ... -8.9973456e-01\n",
      "    6.1617750e-01  1.6725804e+00]\n",
      "  [... 1.2785413e+00]\n",
      "  [-1.0511553e+00 -9.2403144e-01 -1.1026605e+00 ... -4.8790646e-01\n",
      "   -8.2720101e-01  2.5741493e-03]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48128f6d0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.5571866   1.5350361   0.00702987 -0.20391001 -0.1802818  -0.11622138\n",
      "  -0.940694...26e+00\n",
      "  -5.1907831e-01 -2.4361722e-01  2.8899750e-01 -6.5634018e-01\n",
      "  -4.8790646e-01 -8.2720101e-01  2.5741493e-03]]))\n",
      "        y          = needle.Tensor([[-1.5571866   1.5350361   0.00702987 -0.20391001 -0.1802818  -0.11622138\n",
      "  -0.94069463  0.44577494 -0.8...6621812  1.2865726   0.8058173   0.9710276  -1.2884797\n",
      "   0.19342956 -0.49291646  0.7054896  -1.2387905  -1.5030191 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.5571866   1.5350361   0.00702987 -0.20391001 -0.1802818  -0.11622138\n",
      "  -0.94069463  0.44577494 -0....726   0.8058173   0.9710276  -1.2884797\n",
      "   0.19342956 -0.49291646  0.7054896  -1.2387905  -1.5030191 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450aee340>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.5571866   1.5350361   0.00702987 -0.20391001 -0.1802818  -0.11622138\n",
      "  -0.94069463  0.44577494 -0.8...6621812  1.2865726   0.8058173   0.9710276  -1.2884797\n",
      "   0.19342956 -0.49291646  0.7054896  -1.2387905  -1.5030191 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-8.90114129e-01  3.46537292e-01 -5.61180353e-01  1.01633430e-01\n",
      "   2.66492367e-03 -7.60985762e-02  6.9...01 -6.81628704e-01 -4.56521988e-01 -2.11699486e-01\n",
      "   9.19741333e-01 -7.62184262e-02  1.77095756e-01 -3.56241465e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450aee340>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.14457542e-01  6.45884871e-03  1.15639120e-01  2.29073048e-01\n",
      "  -1.24222100e-01  4.53420281e-02 -1.7...01  1.28374070e-01  1.95936859e-01 -1.31339103e-01\n",
      "  -2.63100535e-01 -2.38938928e-01  2.74165630e-01 -2.40280434e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.14457542e-01  6.45884871e-03  1.15639120e-01  2.29073048e-01\n",
      "  -1.24222100e-01  4.53420281e-02 -1....8374070e-01  1.95936859e-01 -1.31339103e-01\n",
      "  -2.63100535e-01 -2.38938928e-01  2.74165630e-01 -2.40280434e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb458a7fa30>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.14457542e-01  6.45884871e-03  1.15639120e-01  2.29073048e-01\n",
      "  -1.24222100e-01  4.53420281e-02 -1....8374070e-01  1.95936859e-01 -1.31339103e-01\n",
      "  -2.63100535e-01 -2.38938928e-01  2.74165630e-01 -2.40280434e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb458a7fa30>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458a7f820>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458a7f820>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb458a7f5e0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb458a7f5e0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-1-1-1-1-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.13579562]]], dtype=float32)\n",
      "c_         = tensor([[[-0.6591]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[0.681175]]], dtype=float32)\n",
      "h_         = tensor([[[-0.2493]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb461731d00>\n",
      "model_     = LSTM(1, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.2493]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.0495611]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.0495611]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461731d00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.0495611]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461731d00>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.0495611]]),)\n",
      "        y          = needle.Tensor([[-0.0495611]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.0495611]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461731760>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.0495611]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.03964338 -0.00618727  0.03931895  0.00427783]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461731760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.5898479   0.7170421  -0.29349518 -0.10194588]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.5898479   0.7170421  -0.29349518 -0.10194588]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4617319a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.5898479   0.7170421  -0.29349518 -0.10194588]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4617319a0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461731400>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461731400>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461731580>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461731580>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-1-1-1-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[0.87251]]], dtype=float32)\n",
      "c_         = tensor([[[-0.2098]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[0.10507933]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0856]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4617b0970>\n",
      "model_     = LSTM(1, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.2378]],\n",
      "\n",
      "        [[-0.2736]],\n",
      "\n",
      "        [[-0.1744]],\n",
      "\n",
      "        [[-0.1869]],\n",
      "\n",
      "        [[-0.3371]],\n",
      "\n",
      "        ...4]],\n",
      "\n",
      "        [[-0.1406]],\n",
      "\n",
      "        [[-0.1305]],\n",
      "\n",
      "        [[-0.2278]],\n",
      "\n",
      "        [[-0.0856]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.88598603]],\n",
      "\n",
      "       [[ 0.6558498 ]],\n",
      "\n",
      "       [[-0.44255903]],\n",
      "\n",
      "       [[-0.06635788]],\n",
      "\n",
      "       [[ 1.372558...]],\n",
      "\n",
      "       [[-0.57488596]],\n",
      "\n",
      "       [[-0.5384121 ]],\n",
      "\n",
      "       [[ 0.4372473 ]],\n",
      "\n",
      "       [[-1.5056164 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.88598603]]\n",
      "\n",
      " [[ 0.6558498 ]]\n",
      "\n",
      " [[-0.44255903]]\n",
      "\n",
      " [[-0.06635788]]\n",
      "\n",
      " [[ 1.3725588 ]]\n",
      "\n",
      " [[ 1.0033802...]]\n",
      "\n",
      " [[ 0.709138  ]]\n",
      "\n",
      " [[-0.32979366]]\n",
      "\n",
      " [[-0.57488596]]\n",
      "\n",
      " [[-0.5384121 ]]\n",
      "\n",
      " [[ 0.4372473 ]]\n",
      "\n",
      " [[-1.5056164 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617b0970>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.88598603]]\n",
      "\n",
      " [[ 0.6558498 ]]\n",
      "\n",
      " [[-0.44255903]]\n",
      "\n",
      " [[-0.06635788]]\n",
      "\n",
      " [[ 1.3725588 ]]\n",
      "\n",
      " [[ 1.0033802 ...3966844]]\n",
      "\n",
      " [[ 0.709138  ]]\n",
      "\n",
      " [[-0.32979366]]\n",
      "\n",
      " [[-0.57488596]]\n",
      "\n",
      " [[-0.5384121 ]]\n",
      "\n",
      " [[ 0.4372473 ]]\n",
      "\n",
      " [[-1.5056164 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617b0970>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.88598603]]), needle.Tensor([[0.6558498]]), needle.Tensor([[-0.44255903]]), needle...le.Tensor([[-0.57488596]]), needle.Tensor([[-0.5384121]]), needle.Tensor([[0.4372473]]), needle.Tensor([[-1.5056164]]))\n",
      "        y          = needle.Tensor([[0.88598603]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.88598603]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4617b0df0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[0.88598603]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.48809624 -0.13845612 -0.3333864   0.19316317]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4617b0df0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.67610335  0.49686754 -0.17198777 -0.27601624]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.67610335  0.49686754 -0.17198777 -0.27601624]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46170e760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.67610335  0.49686754 -0.17198777 -0.27601624]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46170e760>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46170e100>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46170e100>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46170e5e0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46170e5e0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-1-1-1-2-1] _____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[0.92936826]],\n",
      "\n",
      "       [[0.30336887]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0240]],\n",
      "\n",
      "        [[-0.1601]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.2548   ]],\n",
      "\n",
      "       [[ 0.5551163]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0192]],\n",
      "\n",
      "        [[-0.0613]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4617aad30>\n",
      "model_     = LSTM(1, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0613]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.15127915]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.15127915]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617aad30>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.15127915]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617aad30>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.15127915]]),)\n",
      "        y          = needle.Tensor([[-0.15127915]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.15127915]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4617aa790>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.15127915]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.1495013  -0.03107899 -0.12458917 -0.14996044]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4617aa790>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.6249423   0.7699183  -0.00232565 -0.24347055]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.6249423   0.7699183  -0.00232565 -0.24347055]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4616fd520>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.6249423   0.7699183  -0.00232565 -0.24347055]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4616fd520>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4616fd6d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4616fd6d0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4616fd880>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4616fd880>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-1-1-1-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.33343023]],\n",
      "\n",
      "       [[ 1.8669844 ]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.4507]],\n",
      "\n",
      "        [[-0.7148]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.43982396]],\n",
      "\n",
      "       [[-1.3916538 ]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.1295]],\n",
      "\n",
      "        [[-0.1657]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb471377b80>\n",
      "model_     = LSTM(1, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0570]],\n",
      "\n",
      "        [[-0.0952]],\n",
      "\n",
      "        [[-0.1116]],\n",
      "\n",
      "        [[-0.1295]],\n",
      "\n",
      "        [[-0.1377]],\n",
      "\n",
      "        ...1]],\n",
      "\n",
      "        [[-0.1664]],\n",
      "\n",
      "        [[-0.1755]],\n",
      "\n",
      "        [[-0.1732]],\n",
      "\n",
      "        [[-0.1657]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-1.5593898 ]],\n",
      "\n",
      "       [[-0.62981933]],\n",
      "\n",
      "       [[ 2.2323918 ]],\n",
      "\n",
      "       [[ 1.0249803 ]],\n",
      "\n",
      "       [[ 2.091617...]],\n",
      "\n",
      "       [[ 0.2807619 ]],\n",
      "\n",
      "       [[-0.8678962 ]],\n",
      "\n",
      "       [[-0.12550326]],\n",
      "\n",
      "       [[ 1.3114347 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.5593898 ]]\n",
      "\n",
      " [[-0.62981933]]\n",
      "\n",
      " [[ 2.2323918 ]]\n",
      "\n",
      " [[ 1.0249803 ]]\n",
      "\n",
      " [[ 2.0916178 ]]\n",
      "\n",
      " [[-0.6047084...]]\n",
      "\n",
      " [[-0.26624972]]\n",
      "\n",
      " [[ 0.19079426]]\n",
      "\n",
      " [[ 0.2807619 ]]\n",
      "\n",
      " [[-0.8678962 ]]\n",
      "\n",
      " [[-0.12550326]]\n",
      "\n",
      " [[ 1.3114347 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471377b80>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-1.5593898 ]]\n",
      "\n",
      " [[-0.62981933]]\n",
      "\n",
      " [[ 2.2323918 ]]\n",
      "\n",
      " [[ 1.0249803 ]]\n",
      "\n",
      " [[ 2.0916178 ]]\n",
      "\n",
      " [[-0.60470843...0154005]]\n",
      "\n",
      " [[-0.26624972]]\n",
      "\n",
      " [[ 0.19079426]]\n",
      "\n",
      " [[ 0.2807619 ]]\n",
      "\n",
      " [[-0.8678962 ]]\n",
      "\n",
      " [[-0.12550326]]\n",
      "\n",
      " [[ 1.3114347 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471377b80>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.5593898]]), needle.Tensor([[-0.62981933]]), needle.Tensor([[2.2323918]]), needle...dle.Tensor([[0.2807619]]), needle.Tensor([[-0.8678962]]), needle.Tensor([[-0.12550326]]), needle.Tensor([[1.3114347]]))\n",
      "        y          = needle.Tensor([[-1.5593898]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.5593898]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471377d90>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.5593898]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.2678952   0.10505433 -1.3492885  -0.57304037]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471377d90>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.9983641  -0.7805841   0.05432749 -0.98197186]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.9983641  -0.7805841   0.05432749 -0.98197186]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb481210430>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.9983641  -0.7805841   0.05432749 -0.98197186]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb481210430>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb481210280>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb481210280>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb481210400>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb481210400>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-1-1-15-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 0.8857596 ],\n",
      "        [ 0.8677901 ],\n",
      "        [ 1.6106806 ],\n",
      "        [-1.352623  ],\n",
      "        [-0.05626645],\n",
      "   ...0214393 ],\n",
      "        [-1.1603329 ],\n",
      "        [ 0.04826973],\n",
      "        [ 0.7966405 ],\n",
      "        [-0.0538124 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.4355],\n",
      "         [-0.3418],\n",
      "         [-0.4594],\n",
      "         [-0.4266],\n",
      "         [-0.6896],\n",
      "         [-0.3030]... [-0.6495],\n",
      "         [-0.4894],\n",
      "         [-0.0855],\n",
      "         [-0.3703],\n",
      "         [-0.3394]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.47469246],\n",
      "        [-0.72620755],\n",
      "        [-1.1283647 ],\n",
      "        [ 0.95422393],\n",
      "        [ 1.7514583 ],\n",
      "   ...4983254 ],\n",
      "        [ 0.3356843 ],\n",
      "        [-0.82613844],\n",
      "        [ 0.48303303],\n",
      "        [ 0.1974756 ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0587],\n",
      "         [-0.0373],\n",
      "         [-0.0653],\n",
      "         [-0.0564],\n",
      "         [-0.1655],\n",
      "         [-0.0301]... [-0.1415],\n",
      "         [-0.0743],\n",
      "         [-0.0045],\n",
      "         [-0.0431],\n",
      "         [-0.0368]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb461f91430>\n",
      "model_     = LSTM(1, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0587],\n",
      "         [-0.0373],\n",
      "         [-0.0653],\n",
      "         [-0.0564],\n",
      "         [-0.1655],\n",
      "         [-0.0301]... [-0.1415],\n",
      "         [-0.0743],\n",
      "         [-0.0045],\n",
      "         [-0.0431],\n",
      "         [-0.0368]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-9.03772307e-04],\n",
      "        [ 3.89294207e-01],\n",
      "        [-1.02163814e-01],\n",
      "        [ 3.61219496e-02],\n",
      "        [-...   [-2.30483338e-01],\n",
      "        [ 1.59520292e+00],\n",
      "        [ 2.70612270e-01],\n",
      "        [ 3.99318069e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-9.03772307e-04]\n",
      "  [ 3.89294207e-01]\n",
      "  [-1.02163814e-01]\n",
      "  [ 3.61219496e-02]\n",
      "  [-1.20095015e+00]\n",
      "  [...5778e+00]\n",
      "  [-9.82307553e-01]\n",
      "  [-2.30483338e-01]\n",
      "  [ 1.59520292e+00]\n",
      "  [ 2.70612270e-01]\n",
      "  [ 3.99318069e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461f91430>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-9.03772307e-04]\n",
      "  [ 3.89294207e-01]\n",
      "  [-1.02163814e-01]\n",
      "  [ 3.61219496e-02]\n",
      "  [-1.20095015e+00]\n",
      "  [ ...-1.66075778e+00]\n",
      "  [-9.82307553e-01]\n",
      "  [-2.30483338e-01]\n",
      "  [ 1.59520292e+00]\n",
      "  [ 2.70612270e-01]\n",
      "  [ 3.99318069e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461f91430>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-9.03772307e-04]\n",
      " [ 3.89294207e-01]\n",
      " [-1.02163814e-01]\n",
      " [ 3.61219496e-02]\n",
      " [-1.2009...]\n",
      " [-1.66075778e+00]\n",
      " [-9.82307553e-01]\n",
      " [-2.30483338e-01]\n",
      " [ 1.59520292e+00]\n",
      " [ 2.70612270e-01]\n",
      " [ 3.99318069e-01]]),)\n",
      "        y          = needle.Tensor([[-9.03772307e-04]\n",
      " [ 3.89294207e-01]\n",
      " [-1.02163814e-01]\n",
      " [ 3.61219496e-02]\n",
      " [-1.20095015e+00]\n",
      " [ 5.5170...03]\n",
      " [-1.66075778e+00]\n",
      " [-9.82307553e-01]\n",
      " [-2.30483338e-01]\n",
      " [ 1.59520292e+00]\n",
      " [ 2.70612270e-01]\n",
      " [ 3.99318069e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-9.03772307e-04]\n",
      " [ 3.89294207e-01]\n",
      " [-1.02163814e-01]\n",
      " [ 3.61219496e-02]\n",
      " [-1.20095015e+00]\n",
      " [ 5.517...78e+00]\n",
      " [-9.82307553e-01]\n",
      " [-2.30483338e-01]\n",
      " [ 1.59520292e+00]\n",
      " [ 2.70612270e-01]\n",
      " [ 3.99318069e-01]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461f91640>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-9.03772307e-04]\n",
      " [ 3.89294207e-01]\n",
      " [-1.02163814e-01]\n",
      " [ 3.61219496e-02]\n",
      " [-1.20095015e+00]\n",
      " [ 5.5170...03]\n",
      " [-1.66075778e+00]\n",
      " [-9.82307553e-01]\n",
      " [-2.30483338e-01]\n",
      " [ 1.59520292e+00]\n",
      " [ 2.70612270e-01]\n",
      " [ 3.99318069e-01]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 6.52984309e-04  4.17121453e-04 -4.48732986e-04  6.23749918e-04]\n",
      " [-2.81268865e-01 -1.79672435e-01  1....1 -1.24896705e-01  1.34361997e-01 -1.86766490e-01]\n",
      " [-2.88511187e-01 -1.84298784e-01  1.98265851e-01 -2.75594413e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461f91640>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.38743055 -0.3271588  -0.7877455  -0.89670646]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.38743055 -0.3271588  -0.7877455  -0.89670646]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461f91760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.38743055 -0.3271588  -0.7877455  -0.89670646]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461f91760>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461f912e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461f912e0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461f91670>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461f91670>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-1-1-15-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-0.47321537],\n",
      "        [-0.5806496 ],\n",
      "        [ 1.5330119 ],\n",
      "        [ 0.17801572],\n",
      "        [ 1.3401406 ],\n",
      "   ...6807568 ],\n",
      "        [ 0.8206591 ],\n",
      "        [-0.06283059],\n",
      "        [ 1.0783361 ],\n",
      "        [-0.416584  ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.3338],\n",
      "         [-0.1967],\n",
      "         [-0.5303],\n",
      "         [-0.3596],\n",
      "         [-0.2337],\n",
      "         [-0.3416]... [-0.3565],\n",
      "         [-0.4971],\n",
      "         [-0.2653],\n",
      "         [-0.2749],\n",
      "         [-0.4576]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 1.2863551 ],\n",
      "        [-1.6494251 ],\n",
      "        [ 0.01519149],\n",
      "        [ 2.1270585 ],\n",
      "        [ 0.6865092 ],\n",
      "   ...4278327 ],\n",
      "        [-0.20346157],\n",
      "        [-0.69918114],\n",
      "        [ 0.7175818 ],\n",
      "        [ 0.5770448 ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.2422],\n",
      "         [-0.1660],\n",
      "         [-0.2185],\n",
      "         [-0.2338],\n",
      "         [-0.1889],\n",
      "         [-0.2388]... [-0.2402],\n",
      "         [-0.2494],\n",
      "         [-0.2054],\n",
      "         [-0.2138],\n",
      "         [-0.2473]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4588c7760>\n",
      "model_     = LSTM(1, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.1847],\n",
      "         [-0.1938],\n",
      "         [-0.1795],\n",
      "         [-0.1978],\n",
      "         [-0.1897],\n",
      "         [-0.1932]... [-0.2402],\n",
      "         [-0.2494],\n",
      "         [-0.2054],\n",
      "         [-0.2138],\n",
      "         [-0.2473]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.6533503 ],\n",
      "        [-0.65470827],\n",
      "        [ 0.8179666 ],\n",
      "        [-0.09338913],\n",
      "        [ 0.47008815],\n",
      "   ...171235  ],\n",
      "        [-0.9455957 ],\n",
      "        [ 0.9515391 ],\n",
      "        [ 0.99831   ],\n",
      "        [-0.70732677]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.6533503 ]\n",
      "  [-0.65470827]\n",
      "  [ 0.8179666 ]\n",
      "  [-0.09338913]\n",
      "  [ 0.47008815]\n",
      "  [ 0.30538186]\n",
      "  [-0.5...[-0.20545602]\n",
      "  [ 0.8515532 ]\n",
      "  [ 0.171235  ]\n",
      "  [-0.9455957 ]\n",
      "  [ 0.9515391 ]\n",
      "  [ 0.99831   ]\n",
      "  [-0.70732677]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4588c7760>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.6533503 ]\n",
      "  [-0.65470827]\n",
      "  [ 0.8179666 ]\n",
      "  [-0.09338913]\n",
      "  [ 0.47008815]\n",
      "  [ 0.30538186]\n",
      "  [-0.50...532]\n",
      "  [-0.20545602]\n",
      "  [ 0.8515532 ]\n",
      "  [ 0.171235  ]\n",
      "  [-0.9455957 ]\n",
      "  [ 0.9515391 ]\n",
      "  [ 0.99831   ]\n",
      "  [-0.70732677]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4588c7760>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.6533503 ]\n",
      " [-0.65470827]\n",
      " [ 0.8179666 ]\n",
      " [-0.09338913]\n",
      " [ 0.47008815]\n",
      " [ 0.30538...0.27795532]\n",
      " [-0.20545602]\n",
      " [ 0.8515532 ]\n",
      " [ 0.171235  ]\n",
      " [-0.9455957 ]\n",
      " [ 0.9515391 ]\n",
      " [ 0.99831   ]\n",
      " [-0.70732677]]))\n",
      "        y          = needle.Tensor([[ 0.6533503 ]\n",
      " [-0.65470827]\n",
      " [ 0.8179666 ]\n",
      " [-0.09338913]\n",
      " [ 0.47008815]\n",
      " [ 0.30538186]\n",
      " [-0.50765747]\n",
      " [-1.1141828 ]\n",
      " [ 2.131516  ]\n",
      " [-0.17563373]\n",
      " [ 0.4143449 ]\n",
      " [ 1.0571591 ]\n",
      " [ 1.77391   ]\n",
      " [ 0.04410779]\n",
      " [ 1.0892997 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.6533503 ]\n",
      " [-0.65470827]\n",
      " [ 0.8179666 ]\n",
      " [-0.09338913]\n",
      " [ 0.47008815]\n",
      " [ 0.30538186]\n",
      " [-0.50765747... 2.131516  ]\n",
      " [-0.17563373]\n",
      " [ 0.4143449 ]\n",
      " [ 1.0571591 ]\n",
      " [ 1.77391   ]\n",
      " [ 0.04410779]\n",
      " [ 1.0892997 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4588c7fd0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.6533503 ]\n",
      " [-0.65470827]\n",
      " [ 0.8179666 ]\n",
      " [-0.09338913]\n",
      " [ 0.47008815]\n",
      " [ 0.30538186]\n",
      " [-0.50765747]\n",
      " [-1.1141828 ]\n",
      " [ 2.131516  ]\n",
      " [-0.17563373]\n",
      " [ 0.4143449 ]\n",
      " [ 1.0571591 ]\n",
      " [ 1.77391   ]\n",
      " [ 0.04410779]\n",
      " [ 1.0892997 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.4064989  -0.27359265 -0.05848627  0.40369767]\n",
      " [ 0.4073438   0.2741613   0.05860783 -0.40453675]\n",
      " [...95  1.0960788 ]\n",
      " [-0.02744281 -0.01847029 -0.00394842  0.0272537 ]\n",
      " [-0.67773616 -0.45614794 -0.09751136  0.67306584]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4588c7fd0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[0.2018311  0.5918189  0.32430446 0.03661418]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[0.2018311  0.5918189  0.32430446 0.03661418]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46170e220>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[0.2018311  0.5918189  0.32430446 0.03661418]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46170e220>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46170ea90>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46170ea90>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46170e5b0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46170e5b0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-1-1-15-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 0.7793865 ],\n",
      "        [ 1.4825032 ],\n",
      "        [-0.6559368 ],\n",
      "        [-0.78970706],\n",
      "        [ 2.0599382 ],\n",
      "   ...7709372 ],\n",
      "        [-1.3211318 ],\n",
      "        [-0.41816893],\n",
      "        [ 0.5611768 ],\n",
      "        [-0.4952054 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.1306],\n",
      "         [ 0.3008],\n",
      "         [ 0.4881],\n",
      "         [ 0.1664],\n",
      "         [ 0.2555],\n",
      "         [-0.0134]... [-0.6803],\n",
      "         [-0.6722],\n",
      "         [-0.6694],\n",
      "         [-0.6746],\n",
      "         [-0.6604]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-1.0540726 ],\n",
      "        [-1.1043742 ],\n",
      "        [-0.22232749],\n",
      "        [-0.39906907],\n",
      "        [ 0.6970337 ],\n",
      "   ...0176213 ],\n",
      "        [ 0.50584733],\n",
      "        [ 2.2107227 ],\n",
      "        [-0.33671284],\n",
      "        [ 0.7365581 ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0347],\n",
      "         [ 0.0825],\n",
      "         [ 0.1320],\n",
      "         [ 0.0458],\n",
      "         [ 0.0702],\n",
      "         [-0.0036]... [-0.2878],\n",
      "         [-0.2799],\n",
      "         [-0.2772],\n",
      "         [-0.2822],\n",
      "         [-0.2688]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb438471df0>\n",
      "model_     = LSTM(1, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.2879],\n",
      "         [-0.2704],\n",
      "         [-0.2630],\n",
      "         [-0.2759],\n",
      "         [-0.2722],\n",
      "         [-0.2833]... [-0.2878],\n",
      "         [-0.2799],\n",
      "         [-0.2772],\n",
      "         [-0.2822],\n",
      "         [-0.2688]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 1.1428709 ],\n",
      "        [-0.6236845 ],\n",
      "        [-1.6085336 ],\n",
      "        [-0.05975801],\n",
      "        [-0.42600358],\n",
      "   ...1315486 ],\n",
      "        [ 0.32029974],\n",
      "        [ 0.07106901],\n",
      "        [ 0.54912055],\n",
      "        [-0.8062071 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.1428709 ]\n",
      "  [-0.6236845 ]\n",
      "  [-1.6085336 ]\n",
      "  [-0.05975801]\n",
      "  [-0.42600358]\n",
      "  [ 0.6504753 ]\n",
      "  [-0.4...[ 0.03566169]\n",
      "  [-2.1599002 ]\n",
      "  [ 1.1315486 ]\n",
      "  [ 0.32029974]\n",
      "  [ 0.07106901]\n",
      "  [ 0.54912055]\n",
      "  [-0.8062071 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb438471df0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 1.1428709 ]\n",
      "  [-0.6236845 ]\n",
      "  [-1.6085336 ]\n",
      "  [-0.05975801]\n",
      "  [-0.42600358]\n",
      "  [ 0.6504753 ]\n",
      "  [-0.44...34 ]\n",
      "  [ 0.03566169]\n",
      "  [-2.1599002 ]\n",
      "  [ 1.1315486 ]\n",
      "  [ 0.32029974]\n",
      "  [ 0.07106901]\n",
      "  [ 0.54912055]\n",
      "  [-0.8062071 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb438471df0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.1428709 ]\n",
      " [-0.6236845 ]\n",
      " [-1.6085336 ]\n",
      " [-0.05975801]\n",
      " [-0.42600358]\n",
      " [ 0.65047....1713134 ]\n",
      " [ 0.03566169]\n",
      " [-2.1599002 ]\n",
      " [ 1.1315486 ]\n",
      " [ 0.32029974]\n",
      " [ 0.07106901]\n",
      " [ 0.54912055]\n",
      " [-0.8062071 ]]),)\n",
      "        y          = needle.Tensor([[ 1.1428709 ]\n",
      " [-0.6236845 ]\n",
      " [-1.6085336 ]\n",
      " [-0.05975801]\n",
      " [-0.42600358]\n",
      " [ 0.6504753 ]\n",
      " [-0.445423  ]\n",
      " [ 1.1713134 ]\n",
      " [ 0.03566169]\n",
      " [-2.1599002 ]\n",
      " [ 1.1315486 ]\n",
      " [ 0.32029974]\n",
      " [ 0.07106901]\n",
      " [ 0.54912055]\n",
      " [-0.8062071 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.1428709 ]\n",
      " [-0.6236845 ]\n",
      " [-1.6085336 ]\n",
      " [-0.05975801]\n",
      " [-0.42600358]\n",
      " [ 0.6504753 ]\n",
      " [-0.445423  ... 0.03566169]\n",
      " [-2.1599002 ]\n",
      " [ 1.1315486 ]\n",
      " [ 0.32029974]\n",
      " [ 0.07106901]\n",
      " [ 0.54912055]\n",
      " [-0.8062071 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb438471dc0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 1.1428709 ]\n",
      " [-0.6236845 ]\n",
      " [-1.6085336 ]\n",
      " [-0.05975801]\n",
      " [-0.42600358]\n",
      " [ 0.6504753 ]\n",
      " [-0.445423  ]\n",
      " [ 1.1713134 ]\n",
      " [ 0.03566169]\n",
      " [-2.1599002 ]\n",
      " [ 1.1315486 ]\n",
      " [ 0.32029974]\n",
      " [ 0.07106901]\n",
      " [ 0.54912055]\n",
      " [-0.8062071 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.15749943  0.5625472  -0.47335663 -0.05102669]\n",
      " [ 0.08595018 -0.30699182  0.25831896  0.02784615]\n",
      " [...51 -0.00317308]\n",
      " [-0.0756745   0.27028972 -0.22743589 -0.02451703]\n",
      " [ 0.11110368 -0.3968336   0.33391654  0.03599538]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb438471dc0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.42541933 -0.03853917  0.06852829  0.42701292]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.42541933 -0.03853917  0.06852829  0.42701292]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480ed06a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.42541933 -0.03853917  0.06852829  0.42701292]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480ed06a0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480ed0100>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480ed0100>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480ed0be0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480ed0be0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-1-1-15-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-1.5446349 ],\n",
      "        [ 0.14116013],\n",
      "        [-0.11715765],\n",
      "        [-0.2281819 ],\n",
      "        [ 1.3289434 ],\n",
      "   ...28853709],\n",
      "        [-0.27532807],\n",
      "        [ 0.8517132 ],\n",
      "        [-1.5673882 ],\n",
      "        [ 0.85492027]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.1073],\n",
      "         [ 0.0545],\n",
      "         [-0.2101],\n",
      "         [ 0.0220],\n",
      "         [-0.2102],\n",
      "         [-0.0089]... [-1.0172],\n",
      "         [-1.0186],\n",
      "         [-1.0200],\n",
      "         [-1.0163],\n",
      "         [-1.0181]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.16627017],\n",
      "        [ 0.18080628],\n",
      "        [-0.16584486],\n",
      "        [-1.575265  ],\n",
      "        [-0.24236898],\n",
      "   ...6946561 ],\n",
      "        [ 1.7215983 ],\n",
      "        [ 0.22653711],\n",
      "        [ 0.11122365],\n",
      "        [-0.377284  ]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.0779],\n",
      "         [ 0.0434],\n",
      "         [-0.1814],\n",
      "         [ 0.0178],\n",
      "         [-0.1837],\n",
      "         [-0.0073]... [-0.6078],\n",
      "         [-0.5690],\n",
      "         [-0.6075],\n",
      "         [-0.6082],\n",
      "         [-0.6031]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4507403d0>\n",
      "model_     = LSTM(1, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.2689],\n",
      "         [-0.2685],\n",
      "         [-0.2712],\n",
      "         [-0.2806],\n",
      "         [-0.2686],\n",
      "         [-0.2698]... [-0.6078],\n",
      "         [-0.5690],\n",
      "         [-0.6075],\n",
      "         [-0.6082],\n",
      "         [-0.6031]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-1.85111904e+00],\n",
      "        [-1.63817120e+00],\n",
      "        [ 2.96772331e-01],\n",
      "        [ 1.48161221e+00],\n",
      "        [-...   [ 1.53451467e+00],\n",
      "        [-7.72070348e-01],\n",
      "        [-5.24750054e-01],\n",
      "        [ 3.87122929e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.85111904e+00]\n",
      "  [-1.63817120e+00]\n",
      "  [ 2.96772331e-01]\n",
      "  [ 1.48161221e+00]\n",
      "  [-2.57141739e-01]\n",
      "  [...4239e+00]\n",
      "  [-6.47942498e-02]\n",
      "  [ 1.53451467e+00]\n",
      "  [-7.72070348e-01]\n",
      "  [-5.24750054e-01]\n",
      "  [ 3.87122929e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4507403d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-1.85111904e+00]\n",
      "  [-1.63817120e+00]\n",
      "  [ 2.96772331e-01]\n",
      "  [ 1.48161221e+00]\n",
      "  [-2.57141739e-01]\n",
      "  [-... 1.38554239e+00]\n",
      "  [-6.47942498e-02]\n",
      "  [ 1.53451467e+00]\n",
      "  [-7.72070348e-01]\n",
      "  [-5.24750054e-01]\n",
      "  [ 3.87122929e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4507403d0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.851119  ]\n",
      " [-1.6381712 ]\n",
      " [ 0.29677233]\n",
      " [ 1.4816122 ]\n",
      " [-0.25714174]\n",
      " [-2.39920...0.42069823]\n",
      " [-2.0926294 ]\n",
      " [ 1.3855424 ]\n",
      " [-0.06479425]\n",
      " [ 1.5345147 ]\n",
      " [-0.77207035]\n",
      " [-0.52475005]\n",
      " [ 0.38712293]]))\n",
      "        y          = needle.Tensor([[-1.851119  ]\n",
      " [-1.6381712 ]\n",
      " [ 0.29677233]\n",
      " [ 1.4816122 ]\n",
      " [-0.25714174]\n",
      " [-2.3992062 ]\n",
      " [ 0.21856807]\n",
      " [-0.04114111]\n",
      " [ 0.7111419 ]\n",
      " [ 0.4854222 ]\n",
      " [ 2.0358145 ]\n",
      " [-1.1994729 ]\n",
      " [-1.1242207 ]\n",
      " [-0.43444452]\n",
      " [-0.56633985]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.851119  ]\n",
      " [-1.6381712 ]\n",
      " [ 0.29677233]\n",
      " [ 1.4816122 ]\n",
      " [-0.25714174]\n",
      " [-2.3992062 ]\n",
      " [ 0.21856807... 0.7111419 ]\n",
      " [ 0.4854222 ]\n",
      " [ 2.0358145 ]\n",
      " [-1.1994729 ]\n",
      " [-1.1242207 ]\n",
      " [-0.43444452]\n",
      " [-0.56633985]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450740e80>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.851119  ]\n",
      " [-1.6381712 ]\n",
      " [ 0.29677233]\n",
      " [ 1.4816122 ]\n",
      " [-0.25714174]\n",
      " [-2.3992062 ]\n",
      " [ 0.21856807]\n",
      " [-0.04114111]\n",
      " [ 0.7111419 ]\n",
      " [ 0.4854222 ]\n",
      " [ 2.0358145 ]\n",
      " [-1.1994729 ]\n",
      " [-1.1242207 ]\n",
      " [-0.43444452]\n",
      " [-0.56633985]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.1159316  -1.3279024   0.8450033  -1.0220592 ]\n",
      " [-0.98755777 -1.1751441   0.74779636 -0.9044842 ]\n",
      " [...   -0.6207165 ]\n",
      " [-0.26190123 -0.3116493   0.19831628 -0.23987006]\n",
      " [-0.34141323 -0.40626457  0.25852418 -0.31269348]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450740e80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.6011456   0.6054326  -0.25498688  0.2888118 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.6011456   0.6054326  -0.25498688  0.2888118 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46203d2b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.6011456   0.6054326  -0.25498688  0.2888118 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46203d2b0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46203d220>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46203d220>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46203da30>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46203da30>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-1-11-1-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-1.792637]]], dtype=float32)\n",
      "c_         = tensor([[[0.2695]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.18564342]]], dtype=float32)\n",
      "h_         = tensor([[[0.1814]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb46205b0a0>\n",
      "model_     = LSTM(11, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[0.1814]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.665055  , -1.0742302 ,  1.0496345 , -0.04290034,\n",
      "         -1.0026231 ,  1.1442288 ,  2.2986677 , -0.35717994,\n",
      "          0.00260192, -1.0250452 ,  0.45658156]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.665055   -1.0742302   1.0496345  -0.04290034 -1.0026231\n",
      "    1.1442288   2.2986677  -0.35717994  0.00260192 -1.0250452\n",
      "    0.45658156]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46205b0a0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.665055   -1.0742302   1.0496345  -0.04290034 -1.0026231\n",
      "    1.1442288   2.2986677  -0.35717994  0.00260192 -1.0250452\n",
      "    0.45658156]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46205b0a0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.665055   -1.0742302   1.0496345  -0.04290034 -1.0026231   1.1442288\n",
      "   2.2986677  -0.35717994  0.00260192 -1.0250452   0.45658156]]),)\n",
      "        y          = needle.Tensor([[-1.665055   -1.0742302   1.0496345  -0.04290034 -1.0026231   1.1442288\n",
      "   2.2986677  -0.35717994  0.00260192 -1.0250452   0.45658156]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.665055   -1.0742302   1.0496345  -0.04290034 -1.0026231   1.1442288\n",
      "   2.2986677  -0.35717994  0.00260192 -1.0250452   0.45658156]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46205be20>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.665055   -1.0742302   1.0496345  -0.04290034 -1.0026231   1.1442288\n",
      "   2.2986677  -0.35717994  0.00260192 -1.0250452   0.45658156]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[1.8159657  3.831659   0.52844286 1.7548275 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46205be20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.21408641 -0.6081977  -0.12876952  0.07290983]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.21408641 -0.6081977  -0.12876952  0.07290983]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb43837a820>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.21408641 -0.6081977  -0.12876952  0.07290983]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb43837a820>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb43837a160>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb43837a160>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb43837a910>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb43837a910>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-1-11-1-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[0.4907622]]], dtype=float32)\n",
      "c_         = tensor([[[-0.4857]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.40498438]]], dtype=float32)\n",
      "h_         = tensor([[[-0.1447]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb450b4b850>\n",
      "model_     = LSTM(11, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.3840]],\n",
      "\n",
      "        [[-0.0302]],\n",
      "\n",
      "        [[ 0.3612]],\n",
      "\n",
      "        [[-0.1891]],\n",
      "\n",
      "        [[-0.0580]],\n",
      "\n",
      "        ...1]],\n",
      "\n",
      "        [[-0.3885]],\n",
      "\n",
      "        [[-0.0500]],\n",
      "\n",
      "        [[ 0.0754]],\n",
      "\n",
      "        [[-0.1447]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.51593363,  0.92589587, -0.5634218 , -1.26702   ,\n",
      "          0.6889979 , -0.38236248, -1.3309942 ,  0.146682...   0.05163234,  1.4960176 , -0.13233858,  0.44312543,\n",
      "          1.6283612 ,  0.8752537 , -0.1208742 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.51593363  0.92589587 -0.5634218  -1.26702     0.6889979\n",
      "   -0.38236248 -1.3309942   0.1466825   1...187398   0.03089106  0.05163234\n",
      "    1.4960176  -0.13233858  0.44312543  1.6283612   0.8752537\n",
      "   -0.1208742 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450b4b850>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.51593363  0.92589587 -0.5634218  -1.26702     0.6889979\n",
      "   -0.38236248 -1.3309942   0.1466825   1....3  -0.4187398   0.03089106  0.05163234\n",
      "    1.4960176  -0.13233858  0.44312543  1.6283612   0.8752537\n",
      "   -0.1208742 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450b4b850>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.51593363  0.92589587 -0.5634218  -1.26702     0.6889979  -0.38236248\n",
      "  -1.330994...45793  -0.4187398   0.03089106  0.05163234  1.4960176\n",
      "  -0.13233858  0.44312543  1.6283612   0.8752537  -0.1208742 ]]))\n",
      "        y          = needle.Tensor([[-0.51593363  0.92589587 -0.5634218  -1.26702     0.6889979  -0.38236248\n",
      "  -1.3309942   0.1466825   1.7257004  -0.35316953  1.6460774 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.51593363  0.92589587 -0.5634218  -1.26702     0.6889979  -0.38236248\n",
      "  -1.3309942   0.1466825   1.7257004  -0.35316953  1.6460774 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450b4b580>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.51593363  0.92589587 -0.5634218  -1.26702     0.6889979  -0.38236248\n",
      "  -1.3309942   0.1466825   1.7257004  -0.35316953  1.6460774 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.03025249 -0.4699221   5.006127    1.1531564 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450b4b580>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.35700464 -0.45196807  0.89503896  0.43219447]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.35700464 -0.45196807  0.89503896  0.43219447]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb48120af70>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.35700464 -0.45196807  0.89503896  0.43219447]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb48120af70>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb48120a310>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb48120a310>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb48120a370>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb48120a370>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-1-11-1-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 1\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.43310487]],\n",
      "\n",
      "       [[ 0.2559443 ]]], dtype=float32)\n",
      "c_         = tensor([[[0.8731]],\n",
      "\n",
      "        [[0.2345]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.5734072]],\n",
      "\n",
      "       [[ 0.9036412]]], dtype=float32)\n",
      "h_         = tensor([[[0.0131]],\n",
      "\n",
      "        [[0.1250]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4811dd670>\n",
      "model_     = LSTM(11, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[0.1250]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 2.389684  , -1.9203303 , -0.14766438,  0.71713287,\n",
      "         -0.8857299 ,  0.49381468, -1.0626873 ,  0.02562349,\n",
      "         -1.159651  , -0.53992844,  1.1681895 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 2.389684   -1.9203303  -0.14766438  0.71713287 -0.8857299\n",
      "    0.49381468 -1.0626873   0.02562349 -1.159651   -0.53992844\n",
      "    1.1681895 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4811dd670>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 2.389684   -1.9203303  -0.14766438  0.71713287 -0.8857299\n",
      "    0.49381468 -1.0626873   0.02562349 -1.159651   -0.53992844\n",
      "    1.1681895 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4811dd670>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 2.389684   -1.9203303  -0.14766438  0.71713287 -0.8857299   0.49381468\n",
      "  -1.0626873   0.02562349 -1.159651   -0.53992844  1.1681895 ]]),)\n",
      "        y          = needle.Tensor([[ 2.389684   -1.9203303  -0.14766438  0.71713287 -0.8857299   0.49381468\n",
      "  -1.0626873   0.02562349 -1.159651   -0.53992844  1.1681895 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 2.389684   -1.9203303  -0.14766438  0.71713287 -0.8857299   0.49381468\n",
      "  -1.0626873   0.02562349 -1.159651   -0.53992844  1.1681895 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4811dd580>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 2.389684   -1.9203303  -0.14766438  0.71713287 -0.8857299   0.49381468\n",
      "  -1.0626873   0.02562349 -1.159651   -0.53992844  1.1681895 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.868283   1.4577336  1.3562522 -3.5961485]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4811dd580>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.6111622  -0.7167511   0.28525794 -0.5783901 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.6111622  -0.7167511   0.28525794 -0.5783901 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46239d3a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.6111622  -0.7167511   0.28525794 -0.5783901 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46239d3a0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46239dc40>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46239dc40>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46239dbe0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46239dbe0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-1-11-1-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[ 0.01832736]],\n",
      "\n",
      "       [[-0.26754844]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.0026]],\n",
      "\n",
      "        [[-0.3988]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.26219392]],\n",
      "\n",
      "       [[-1.3053764 ]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.0010]],\n",
      "\n",
      "        [[-0.2703]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb471e9b5e0>\n",
      "model_     = LSTM(11, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.1530]],\n",
      "\n",
      "        [[-0.2345]],\n",
      "\n",
      "        [[-0.2509]],\n",
      "\n",
      "        [[-0.2658]],\n",
      "\n",
      "        [[-0.2681]],\n",
      "\n",
      "        ...1]],\n",
      "\n",
      "        [[-0.2693]],\n",
      "\n",
      "        [[-0.2709]],\n",
      "\n",
      "        [[-0.2703]],\n",
      "\n",
      "        [[-0.2703]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 1.8904141 , -0.7288049 , -0.7114094 ,  1.7642932 ,\n",
      "         -0.4898962 , -0.01686178, -1.1369302 ,  2.105566...  -1.8322992 , -0.10846423,  0.62093574,  0.824468  ,\n",
      "          0.4763914 ,  1.9613316 , -1.645865  ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.8904141  -0.7288049  -0.7114094   1.7642932  -0.4898962\n",
      "   -0.01686178 -1.1369302   2.1055665  -0...209005   -0.4892971  -1.8322992\n",
      "   -0.10846423  0.62093574  0.824468    0.4763914   1.9613316\n",
      "   -1.645865  ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471e9b5e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 1.8904141  -0.7288049  -0.7114094   1.7642932  -0.4898962\n",
      "   -0.01686178 -1.1369302   2.1055665  -0....49  -1.209005   -0.4892971  -1.8322992\n",
      "   -0.10846423  0.62093574  0.824468    0.4763914   1.9613316\n",
      "   -1.645865  ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471e9b5e0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.8904141  -0.7288049  -0.7114094   1.7642932  -0.4898962  -0.01686178\n",
      "  -1.136930...0249  -1.209005   -0.4892971  -1.8322992  -0.10846423\n",
      "   0.62093574  0.824468    0.4763914   1.9613316  -1.645865  ]]))\n",
      "        y          = needle.Tensor([[ 1.8904141  -0.7288049  -0.7114094   1.7642932  -0.4898962  -0.01686178\n",
      "  -1.1369302   2.1055665  -0.5302433   0.20369902  1.5755616 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.8904141  -0.7288049  -0.7114094   1.7642932  -0.4898962  -0.01686178\n",
      "  -1.1369302   2.1055665  -0.5302433   0.20369902  1.5755616 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471e9b550>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 1.8904141  -0.7288049  -0.7114094   1.7642932  -0.4898962  -0.01686178\n",
      "  -1.1369302   2.1055665  -0.5302433   0.20369902  1.5755616 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 2.585677   -0.32011634 -1.5273147   3.246086  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471e9b550>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.25370967  0.17282677 -0.18837214  0.5443243 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.25370967  0.17282677 -0.18837214  0.5443243 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461d80310>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.25370967  0.17282677 -0.18837214  0.5443243 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461d80310>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461d80790>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461d80790>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461d801f0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461d801f0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-1-11-15-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-0.28535858],\n",
      "        [-1.1314918 ],\n",
      "        [-0.5461747 ],\n",
      "        [ 0.17219552],\n",
      "        [ 0.2576013 ],\n",
      "   ...14837906],\n",
      "        [ 1.3439009 ],\n",
      "        [ 0.39118585],\n",
      "        [-0.9647304 ],\n",
      "        [-0.5073264 ]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.5179],\n",
      "         [ 0.0674],\n",
      "         [-0.0028],\n",
      "         [-0.0209],\n",
      "         [ 0.1479],\n",
      "         [ 0.1733]... [-0.0069],\n",
      "         [ 0.7695],\n",
      "         [ 0.4380],\n",
      "         [-0.0143],\n",
      "         [ 0.9181]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 1.604076  ],\n",
      "        [ 1.966921  ],\n",
      "        [-0.83164024],\n",
      "        [ 0.93508327],\n",
      "        [-1.2588007 ],\n",
      "   ...289351  ],\n",
      "        [ 0.8760576 ],\n",
      "        [-1.6964664 ],\n",
      "        [ 0.6544011 ],\n",
      "        [ 1.1909217 ]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.2247],\n",
      "         [ 0.0298],\n",
      "         [-0.0016],\n",
      "         [-0.0167],\n",
      "         [ 0.1304],\n",
      "         [ 0.1469]... [-0.0032],\n",
      "         [ 0.0914],\n",
      "         [ 0.3589],\n",
      "         [-0.0100],\n",
      "         [ 0.7125]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb438385280>\n",
      "model_     = LSTM(11, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.2247],\n",
      "         [ 0.0298],\n",
      "         [-0.0016],\n",
      "         [-0.0167],\n",
      "         [ 0.1304],\n",
      "         [ 0.1469]... [-0.0032],\n",
      "         [ 0.0914],\n",
      "         [ 0.3589],\n",
      "         [-0.0100],\n",
      "         [ 0.7125]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.7854171 , -0.49225277, -1.5475792 ,  1.1043152 ,\n",
      "          0.62408245,  1.0638086 ,  0.84384894,  0.477488...   2.076384  ,  0.5231079 , -0.21882746, -0.43096426,\n",
      "          2.3667495 ,  0.8784332 ,  0.32224128]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.7854171  -0.49225277 -1.5475792   1.1043152   0.62408245\n",
      "    1.0638086   0.84384894  0.47748867  ....6162427   0.33319682  2.076384\n",
      "    0.5231079  -0.21882746 -0.43096426  2.3667495   0.8784332\n",
      "    0.32224128]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb438385280>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.7854171  -0.49225277 -1.5475792   1.1043152   0.62408245\n",
      "    1.0638086   0.84384894  0.47748867  0...29    0.6162427   0.33319682  2.076384\n",
      "    0.5231079  -0.21882746 -0.43096426  2.3667495   0.8784332\n",
      "    0.32224128]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb438385280>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.7854171  -0.49225277 -1.5475792   1.1043152   0.62408245  1.0638086\n",
      "   0.8438489...729    0.6162427   0.33319682  2.076384    0.5231079\n",
      "  -0.21882746 -0.43096426  2.3667495   0.8784332   0.32224128]]),)\n",
      "        y          = needle.Tensor([[-1.7854171  -0.49225277 -1.5475792   1.1043152   0.62408245  1.0638086\n",
      "   0.84384894  0.47748867  0.24...58729    0.6162427   0.33319682  2.076384    0.5231079\n",
      "  -0.21882746 -0.43096426  2.3667495   0.8784332   0.32224128]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.7854171  -0.49225277 -1.5475792   1.1043152   0.62408245  1.0638086\n",
      "   0.84384894  0.47748867  0.2...427   0.33319682  2.076384    0.5231079\n",
      "  -0.21882746 -0.43096426  2.3667495   0.8784332   0.32224128]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb438385b50>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.7854171  -0.49225277 -1.5475792   1.1043152   0.62408245  1.0638086\n",
      "   0.84384894  0.47748867  0.24...58729    0.6162427   0.33319682  2.076384    0.5231079\n",
      "  -0.21882746 -0.43096426  2.3667495   0.8784332   0.32224128]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.7726673e+00  2.4331895e-01  2.7939799e+00 -1.1320050e+00]\n",
      " [-9.1868716e-01 -2.0182755e+00  1.280403...2770e+00 -3.5871184e-01 -5.8756990e+00 -1.8294908e-01]\n",
      " [ 5.0402060e+00  6.2506604e-01  3.2240161e-01  3.0194695e+00]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb438385b50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.62706566  0.5360671   0.95290947 -0.56780994]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.62706566  0.5360671   0.95290947 -0.56780994]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4383855b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.62706566  0.5360671   0.95290947 -0.56780994]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4383855b0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb438385d60>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb438385d60>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb438385070>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb438385070>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-1-11-15-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-1.1922514 ],\n",
      "        [-2.4727466 ],\n",
      "        [-0.6778968 ],\n",
      "        [-0.70668834],\n",
      "        [-0.503257  ],\n",
      "   ...03150885],\n",
      "        [ 1.7429874 ],\n",
      "        [ 0.39325365],\n",
      "        [-0.12583895],\n",
      "        [-1.4828303 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0130],\n",
      "         [ 0.1207],\n",
      "         [ 0.5451],\n",
      "         [-0.2216],\n",
      "         [ 0.2642],\n",
      "         [ 0.4524]... [-0.3014],\n",
      "         [-0.0910],\n",
      "         [-0.1550],\n",
      "         [ 0.3499],\n",
      "         [ 0.6444]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.9313468 ],\n",
      "        [ 0.42951304],\n",
      "        [ 0.22058076],\n",
      "        [-0.8073894 ],\n",
      "        [ 0.2898475 ],\n",
      "   ...01011509],\n",
      "        [-1.9771082 ],\n",
      "        [-0.51923287],\n",
      "        [ 0.18681404],\n",
      "        [-0.32615983]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0070],\n",
      "         [ 0.1181],\n",
      "         [ 0.1543],\n",
      "         [-0.1770],\n",
      "         [ 0.2251],\n",
      "         [ 0.0167]... [-0.0663],\n",
      "         [-0.0076],\n",
      "         [-0.0008],\n",
      "         [ 0.2555],\n",
      "         [ 0.3525]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb480b064f0>\n",
      "model_     = LSTM(11, 1)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 1.2613e-02],\n",
      "         [ 5.3955e-02],\n",
      "         [ 4.2173e-02],\n",
      "         [ 7.0782e-02],\n",
      "         [-3.0887e-01]...     [-7.6499e-03],\n",
      "         [-7.9803e-04],\n",
      "         [ 2.5551e-01],\n",
      "         [ 3.5254e-01]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-4.4272068e-01,  3.9020905e-01,  2.8511384e-01, ...,\n",
      "         -1.5256256e+00,  8.7087959e-01,  8.3896977e-01]...75e-01, -1.1832732e+00,  9.3202496e-01, ...,\n",
      "         -9.4825101e-01, -5.4289468e-02,  3.4404838e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-4.4272068e-01  3.9020905e-01  2.8511384e-01 ... -1.5256256e+00\n",
      "    8.7087959e-01  8.3896977e-01]\n",
      "  ...571e+00]\n",
      "  [-6.7895675e-01 -1.1832732e+00  9.3202496e-01 ... -9.4825101e-01\n",
      "   -5.4289468e-02  3.4404838e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480b064f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-4.4272068e-01  3.9020905e-01  2.8511384e-01 ... -1.5256256e+00\n",
      "    8.7087959e-01  8.3896977e-01]\n",
      "  [... 1.3276571e+00]\n",
      "  [-6.7895675e-01 -1.1832732e+00  9.3202496e-01 ... -9.4825101e-01\n",
      "   -5.4289468e-02  3.4404838e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480b064f0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.44272068  0.39020905  0.28511384  0.95032775  0.7984546   0.0087948\n",
      "  -0.1623032...2732   0.93202496 -0.41405705 -0.7903101   0.48381796\n",
      "  -0.61712945  0.18010253 -0.948251   -0.05428947  0.34404838]]))\n",
      "        y          = needle.Tensor([[-0.44272068  0.39020905  0.28511384  0.95032775  0.7984546   0.0087948\n",
      "  -0.16230327 -0.4392785  -1.52...174775 -0.62402946  0.39382127 -1.7723992   0.87199426\n",
      "  -1.6697834   0.6488163  -0.3023254  -0.1877253  -0.15097241]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.44272068  0.39020905  0.28511384  0.95032775  0.7984546   0.0087948\n",
      "  -0.16230327 -0.4392785  -1.5...946  0.39382127 -1.7723992   0.87199426\n",
      "  -1.6697834   0.6488163  -0.3023254  -0.1877253  -0.15097241]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480b06820>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.44272068  0.39020905  0.28511384  0.95032775  0.7984546   0.0087948\n",
      "  -0.16230327 -0.4392785  -1.52...174775 -0.62402946  0.39382127 -1.7723992   0.87199426\n",
      "  -1.6697834   0.6488163  -0.3023254  -0.1877253  -0.15097241]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.4968996  -1.2575887  -0.17468858  0.26159048]\n",
      " [-1.8224691   0.2488054   3.1888633   0.88390285]\n",
      " [...4   0.32175678]\n",
      " [ 1.6809558   0.8151425  -1.7944806   2.308823  ]\n",
      " [ 2.905905    0.75092685  0.6004347  -1.6794276 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480b06820>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.6021941  -0.91123056 -0.18954098 -0.06584597]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.6021941  -0.91123056 -0.18954098 -0.06584597]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4721e8a00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.6021941  -0.91123056 -0.18954098 -0.06584597]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4721e8a00>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4721e8b80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4721e8b80>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4721e8520>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4721e8520>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-1-11-15-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-0.5345598 ],\n",
      "        [-0.20126331],\n",
      "        [-0.35960945],\n",
      "        [-1.1312228 ],\n",
      "        [-1.5327024 ],\n",
      "   ...30099332],\n",
      "        [-0.00321686],\n",
      "        [-1.9152924 ],\n",
      "        [-1.8381485 ],\n",
      "        [ 0.7392267 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.1476],\n",
      "         [-0.1605],\n",
      "         [ 0.8225],\n",
      "         [ 0.4919],\n",
      "         [ 0.0358],\n",
      "         [ 0.6709]... [-0.2429],\n",
      "         [-0.1141],\n",
      "         [-0.2126],\n",
      "         [-0.1918],\n",
      "         [-0.2199]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.9706849 ],\n",
      "        [-1.2316569 ],\n",
      "        [ 0.13513027],\n",
      "        [ 0.5531793 ],\n",
      "        [ 1.9391513 ],\n",
      "   ...0391285 ],\n",
      "        [-1.0727592 ],\n",
      "        [-0.35200626],\n",
      "        [ 0.4376214 ],\n",
      "        [ 0.38645142]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0520],\n",
      "         [-0.0405],\n",
      "         [ 0.0285],\n",
      "         [ 0.0678],\n",
      "         [ 0.0341],\n",
      "         [ 0.0423]... [-0.1293],\n",
      "         [-0.0571],\n",
      "         [-0.1117],\n",
      "         [-0.0998],\n",
      "         [-0.1159]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb461d4a640>\n",
      "model_     = LSTM(11, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0997],\n",
      "         [-0.1025],\n",
      "         [-0.1196],\n",
      "         [-0.1293],\n",
      "         [-0.1210],\n",
      "         [-0.1230]... [-0.1293],\n",
      "         [-0.0571],\n",
      "         [-0.1117],\n",
      "         [-0.0998],\n",
      "         [-0.1159]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.7555617 ,  1.0347857 ,  0.82433546,  1.6642404 ,\n",
      "          0.5725178 ,  1.5718693 ,  0.77030647,  1.602660...   0.7953964 ,  0.01031805,  0.23820084, -0.31076825,\n",
      "         -0.80518425, -1.5905179 ,  1.3930042 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.7555617   1.0347857   0.82433546  1.6642404   0.5725178\n",
      "    1.5718693   0.77030647  1.6026603   1...5800406  -0.66592264  0.7953964\n",
      "    0.01031805  0.23820084 -0.31076825 -0.80518425 -1.5905179\n",
      "    1.3930042 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461d4a640>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.7555617   1.0347857   0.82433546  1.6642404   0.5725178\n",
      "    1.5718693   0.77030647  1.6026603   1....     0.5800406  -0.66592264  0.7953964\n",
      "    0.01031805  0.23820084 -0.31076825 -0.80518425 -1.5905179\n",
      "    1.3930042 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461d4a640>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.7555617   1.0347857   0.82433546  1.6642404   0.5725178   1.5718693\n",
      "   0.7703064...7     0.5800406  -0.66592264  0.7953964   0.01031805\n",
      "   0.23820084 -0.31076825 -0.80518425 -1.5905179   1.3930042 ]]),)\n",
      "        y          = needle.Tensor([[ 0.7555617   1.0347857   0.82433546  1.6642404   0.5725178   1.5718693\n",
      "   0.77030647  1.6026603   1.29...617     0.5800406  -0.66592264  0.7953964   0.01031805\n",
      "   0.23820084 -0.31076825 -0.80518425 -1.5905179   1.3930042 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.7555617   1.0347857   0.82433546  1.6642404   0.5725178   1.5718693\n",
      "   0.77030647  1.6026603   1.2...06  -0.66592264  0.7953964   0.01031805\n",
      "   0.23820084 -0.31076825 -0.80518425 -1.5905179   1.3930042 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461d4a040>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.7555617   1.0347857   0.82433546  1.6642404   0.5725178   1.5718693\n",
      "   0.77030647  1.6026603   1.29...617     0.5800406  -0.66592264  0.7953964   0.01031805\n",
      "   0.23820084 -0.31076825 -0.80518425 -1.5905179   1.3930042 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.953744   -0.6233215  -0.49149492  0.7149063 ]\n",
      " [ 0.3295431  -0.20995775  0.3064316   0.23720984]\n",
      " [...6  -4.0414233 ]\n",
      " [-0.14310803  0.29409713 -0.07355299 -0.31059954]\n",
      " [ 0.9349782  -0.25224748  1.4861087  -2.3385298 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461d4a040>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.70739806 -0.7155751   0.74005425 -0.63331544]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.70739806 -0.7155751   0.74005425 -0.63331544]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4719ecc40>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.70739806 -0.7155751   0.74005425 -0.63331544]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4719ecc40>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4719ecb50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4719ecb50>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4719eccd0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4719eccd0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-1-11-15-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 0.59394014],\n",
      "        [ 1.083935  ],\n",
      "        [ 1.2907848 ],\n",
      "        [-0.42579642],\n",
      "        [ 0.3202176 ],\n",
      "   ...5145684 ],\n",
      "        [-1.0926391 ],\n",
      "        [ 0.57826596],\n",
      "        [ 0.2876441 ],\n",
      "        [-1.8832886 ]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.5665],\n",
      "         [ 0.1390],\n",
      "         [ 0.3002],\n",
      "         [-0.5517],\n",
      "         [-0.4302],\n",
      "         [-0.3992]... [ 0.5640],\n",
      "         [ 0.7704],\n",
      "         [ 0.6498],\n",
      "         [ 0.5780],\n",
      "         [ 0.8535]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.35180074],\n",
      "        [-0.31730148],\n",
      "        [-0.65201193],\n",
      "        [-0.3695492 ],\n",
      "        [-1.3079427 ],\n",
      "   ...46129197],\n",
      "        [ 1.9264364 ],\n",
      "        [ 1.4339309 ],\n",
      "        [ 0.70272213],\n",
      "        [-0.28220135]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.1337],\n",
      "         [ 0.1348],\n",
      "         [ 0.2454],\n",
      "         [-0.1098],\n",
      "         [-0.3430],\n",
      "         [-0.3188]... [ 0.3198],\n",
      "         [ 0.3581],\n",
      "         [ 0.3489],\n",
      "         [ 0.3176],\n",
      "         [ 0.3573]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb46171de80>\n",
      "model_     = LSTM(11, 1, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[0.3098],\n",
      "         [0.3150],\n",
      "         [0.3198],\n",
      "         [0.3215],\n",
      "         [0.3242],\n",
      "         [0.2724],\n",
      "    ...      [0.3198],\n",
      "         [0.3581],\n",
      "         [0.3489],\n",
      "         [0.3176],\n",
      "         [0.3573]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-1.82413578e-01, -1.03423500e+00,  2.65711993e-01, ...,\n",
      "         -1.08945020e-01,  4.75140125e-01, -8.9905738...72437000e-01, -1.18608564e-01, ...,\n",
      "         -1.63142756e-01,  7.29600966e-01,  4.27782178e-01]]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.82413578e-01 -1.03423500e+00  2.65711993e-01 ... -1.08945020e-01\n",
      "    4.75140125e-01 -8.99057388e-...2]\n",
      "  [ 2.52177143e+00 -8.72437000e-01 -1.18608564e-01 ... -1.63142756e-01\n",
      "    7.29600966e-01  4.27782178e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46171de80>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-1.82413578e-01 -1.03423500e+00  2.65711993e-01 ... -1.08945020e-01\n",
      "    4.75140125e-01 -8.99057388e-0...9003e-02]\n",
      "  [ 2.52177143e+00 -8.72437000e-01 -1.18608564e-01 ... -1.63142756e-01\n",
      "    7.29600966e-01  4.27782178e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46171de80>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.18241358 -1.034235    0.265712    0.9287782   0.13456978  0.68699366\n",
      "  -1.919860...2437   -0.11860856 -0.21627043  2.7580955  -1.1534814\n",
      "   0.8111414   0.9892588  -0.16314276  0.72960097  0.42778218]]))\n",
      "        y          = needle.Tensor([[-0.18241358 -1.034235    0.265712    0.9287782   0.13456978  0.68699366\n",
      "  -1.9198604  -0.9193326  -0.1...330651   1.8908234  -0.14386111 -1.3753848   0.7279802\n",
      "  -0.28088903  0.01967682  0.22513755  0.26728398  0.01906409]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.18241358 -1.034235    0.265712    0.9287782   0.13456978  0.68699366\n",
      "  -1.9198604  -0.9193326  -0....234  -0.14386111 -1.3753848   0.7279802\n",
      "  -0.28088903  0.01967682  0.22513755  0.26728398  0.01906409]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46171d730>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.18241358 -1.034235    0.265712    0.9287782   0.13456978  0.68699366\n",
      "  -1.9198604  -0.9193326  -0.1...330651   1.8908234  -0.14386111 -1.3753848   0.7279802\n",
      "  -0.28088903  0.01967682  0.22513755  0.26728398  0.01906409]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.7488378e-01 -7.6761715e-02  4.8928174e-01 -7.5400811e-01]\n",
      " [ 1.3799673e+00  2.7806929e-01 -4.395570...3660e+00 -2.0137324e+00  1.7729989e+00  2.7861571e-01]\n",
      " [ 3.2027712e+00  2.8753855e+00 -1.7696911e+00 -2.7412124e+00]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46171d730>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.73451877 -0.50483334 -0.13132131  0.8170309 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.73451877 -0.50483334 -0.13132131  0.8170309 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4720db490>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.73451877 -0.50483334 -0.13132131  0.8170309 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4720db490>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4720dbb20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4720dbb20>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4720db8b0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4720db8b0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-12-1-1-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 12\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.7174392 ,  0.26913238,  1.2151649 ,  0.13079587,\n",
      "         -1.2885032 , -1.4982384 , -0.54348016,  1.2595143 ,\n",
      "          0.31403044, -0.34005865,  1.3528838 ,  0.43758404]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.2383,  0.1695, -0.1468, -0.0628, -0.2049, -0.0523,  0.2939,\n",
      "          -0.3177,  0.1656, -0.0547, -0.2471, -0.1681]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.7478603 , -0.5712603 , -0.01934574,  1.4673615 ,\n",
      "          0.05825168,  1.2161709 ,  1.6717257 , -0.4455796 ,\n",
      "          0.38799766,  0.10486522, -0.28854397, -0.24961823]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.1230,  0.0633, -0.0593, -0.0308, -0.0787, -0.0288,  0.1738,\n",
      "          -0.1401,  0.1039, -0.0247, -0.1567, -0.0872]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4812598b0>\n",
      "model_     = LSTM(1, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.1230,  0.0633, -0.0593, -0.0308, -0.0787, -0.0288,  0.1738,\n",
      "          -0.1401,  0.1039, -0.0247, -0.1567, -0.0872]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[2.27117]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[2.27117]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4812598b0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[2.27117]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4812598b0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[2.27117]]),)\n",
      "        y          = needle.Tensor([[2.27117]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[2.27117]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb481259880>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[2.27117]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.43791226 -0.28694126  0.4143067   0.02779145  0.5266469   0.16552131\n",
      "  -0.3297071   0.4863762   0.4...4358995  0.25583026 -0.332154    0.5897282\n",
      "   0.4980094   0.17293395  0.5616401  -0.20126267  0.6083064   0.10099658]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb481259880>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.06602807  0.19830441  0.06195158  0.16594887 -0.26988193  0.20841005\n",
      "  -0.27178144  0.09466931 -0.1...860092 -0.06167713  0.20596403 -0.19087937\n",
      "  -0.10281262  0.19196087 -0.02210218  0.001708   -0.21552277  0.18463477]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.06602807  0.19830441  0.06195158  0.16594887 -0.26988193  0.20841005\n",
      "  -0.27178144  0.09466931 -0....-0.06167713  0.20596403 -0.19087937\n",
      "  -0.10281262  0.19196087 -0.02210218  0.001708   -0.21552277  0.18463477]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4812599a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.06602807  0.19830441  0.06195158  0.16594887 -0.26988193  0.20841005\n",
      "  -0.27178144  0.09466931 -0....-0.06167713  0.20596403 -0.19087937\n",
      "  -0.10281262  0.19196087 -0.02210218  0.001708   -0.21552277  0.18463477]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4812599a0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb481259d30>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb481259d30>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb481259be0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb481259be0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-1-1-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-1.0451277 ,  0.12123715,  0.6655663 , -0.40772465,\n",
      "         -1.6160018 ,  1.1290385 , -0.15343846, -1.0659357 ,\n",
      "         -0.23451866,  0.36751097,  0.46959907, -3.3191068 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.3810, -0.1132,  0.0103,  0.4233, -0.7075,  0.0809,  0.1323,\n",
      "          -0.2290, -0.2869, -0.3549, -0.3326,  0.2511]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.44607535, -2.20622   , -1.0541152 , -0.48121044,\n",
      "         -0.2705223 , -0.5435999 , -1.7789018 ,  0.09657757,\n",
      "         -0.8134471 ,  0.11747547,  1.0642072 , -0.6886905 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.1867, -0.0377,  0.0041,  0.2057, -0.3274,  0.0498,  0.0632,\n",
      "          -0.1358, -0.1094, -0.1760, -0.2073,  0.0963]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4617e94c0>\n",
      "model_     = LSTM(1, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-3.6444e-02,  5.1480e-02, -7.8273e-02,  7.5795e-02, -7.2158e-02,\n",
      "          -1.7068e-02,  8.8605e-02,  3.9053...2,  6.3193e-02, -1.3576e-01, -1.0940e-01, -1.7599e-01,\n",
      "          -2.0726e-01,  9.6306e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.6209019 ]],\n",
      "\n",
      "       [[ 0.3194226 ]],\n",
      "\n",
      "       [[-1.2754545 ]],\n",
      "\n",
      "       [[-0.05909514]],\n",
      "\n",
      "       [[ 0.556606...]],\n",
      "\n",
      "       [[-0.65715677]],\n",
      "\n",
      "       [[ 0.32530123]],\n",
      "\n",
      "       [[-0.44506708]],\n",
      "\n",
      "       [[-1.5010184 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.6209019 ]]\n",
      "\n",
      " [[ 0.3194226 ]]\n",
      "\n",
      " [[-1.2754545 ]]\n",
      "\n",
      " [[-0.05909514]]\n",
      "\n",
      " [[ 0.5566065 ]]\n",
      "\n",
      " [[ 0.4636470...]]\n",
      "\n",
      " [[ 0.9086811 ]]\n",
      "\n",
      " [[-0.5289292 ]]\n",
      "\n",
      " [[-0.65715677]]\n",
      "\n",
      " [[ 0.32530123]]\n",
      "\n",
      " [[-0.44506708]]\n",
      "\n",
      " [[-1.5010184 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617e94c0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.6209019 ]]\n",
      "\n",
      " [[ 0.3194226 ]]\n",
      "\n",
      " [[-1.2754545 ]]\n",
      "\n",
      " [[-0.05909514]]\n",
      "\n",
      " [[ 0.5566065 ]]\n",
      "\n",
      " [[ 0.46364707...1460645]]\n",
      "\n",
      " [[ 0.9086811 ]]\n",
      "\n",
      " [[-0.5289292 ]]\n",
      "\n",
      " [[-0.65715677]]\n",
      "\n",
      " [[ 0.32530123]]\n",
      "\n",
      " [[-0.44506708]]\n",
      "\n",
      " [[-1.5010184 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617e94c0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.6209019]]), needle.Tensor([[0.3194226]]), needle.Tensor([[-1.2754545]]), needle.T....Tensor([[-0.65715677]]), needle.Tensor([[0.32530123]]), needle.Tensor([[-0.44506708]]), needle.Tensor([[-1.5010184]]))\n",
      "        y          = needle.Tensor([[0.6209019]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.6209019]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4617e9520>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[0.6209019]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.17447263 -0.1237182   0.09979658 -0.0337464  -0.15111156  0.08022978\n",
      "  -0.15401074 -0.12073576 -0.0...33645   0.05926733  0.0451383  -0.06754036\n",
      "   0.13954554 -0.15309472  0.1495384  -0.06296826 -0.14985639  0.12995645]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4617e9520>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.10222825 -0.12554872 -0.184888    0.00601727 -0.10642093  0.1574707\n",
      "   0.02793133  0.13695592 -0.24...8113148  0.28450406 -0.11278771  0.1591833\n",
      "  -0.22878978 -0.05561446  0.10478285  0.2686944   0.06191126  0.14086866]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.10222825 -0.12554872 -0.184888    0.00601727 -0.10642093  0.1574707\n",
      "   0.02793133  0.13695592 -0.2...  0.28450406 -0.11278771  0.1591833\n",
      "  -0.22878978 -0.05561446  0.10478285  0.2686944   0.06191126  0.14086866]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461d9b490>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.10222825 -0.12554872 -0.184888    0.00601727 -0.10642093  0.1574707\n",
      "   0.02793133  0.13695592 -0.2...  0.28450406 -0.11278771  0.1591833\n",
      "  -0.22878978 -0.05561446  0.10478285  0.2686944   0.06191126  0.14086866]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461d9b490>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461d9b8e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461d9b8e0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461d9b4c0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461d9b4c0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-True-12-1-1-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 12\n",
      "bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[ 1.3975477 , -0.04346084,  0.26121944, -0.8337263 ,\n",
      "          0.690357  , -0.56744045,  0.47459638,  0.486883...0274823, -2.849258  , -0.85258   ,\n",
      "         -0.1379562 ,  0.9200773 , -0.881015  ,  0.0156609 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0522, -0.1309, -0.1922, -0.0763,  0.0948, -0.0324,  0.1626,\n",
      "           0.1487, -0.1021, -0.0774,  0.0424,...,  0.0077,  0.0556, -0.1843,\n",
      "           0.1653, -0.1307, -0.0910,  0.0390,  0.1532]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.7754301 ,  0.21687903, -0.06024526, -1.7714635 ,\n",
      "         -0.26413736, -0.59185076, -0.93827015,  0.012285...005253 , -0.5432974 , -0.50739557,\n",
      "          1.1733866 ,  1.1457402 , -1.595031  ,  1.1198269 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0206, -0.0520, -0.0848, -0.0388,  0.0553, -0.0158,  0.0687,\n",
      "           0.0734, -0.0517, -0.0277,  0.0207,...,  0.0040,  0.0307, -0.0982,\n",
      "           0.0799, -0.0731, -0.0460,  0.0172,  0.0794]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4719ec7f0>\n",
      "model_     = LSTM(1, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0727, -0.0442,  0.0972, -0.0235,  0.0040,  0.0307, -0.0982,\n",
      "           0.0799, -0.0731, -0.0460,  0.0172,  0.0794]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[0.28513506]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[0.28513506]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4719ec7f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[0.28513506]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4719ec7f0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.28513506]]),)\n",
      "        y          = needle.Tensor([[0.28513506]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.28513506]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4719ec160>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[0.28513506]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.01863225 -0.02056855  0.07769789  0.07455038  0.00093135 -0.02861626\n",
      "  -0.05319544  0.03944149 -0.0...096851 -0.01592029 -0.00937131  0.05963451\n",
      "  -0.00547746 -0.00276742 -0.06497269 -0.07339983  0.0535285  -0.01404551]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4719ec160>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.04809603 -0.06838806 -0.280678    0.04925016 -0.08311132 -0.07534584\n",
      "  -0.21074611 -0.18752722 -0.1...81926  -0.04164277  0.21611041 -0.01667577\n",
      "  -0.02321112  0.26490694  0.12254435  0.17855975  0.12875247 -0.05682324]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.04809603 -0.06838806 -0.280678    0.04925016 -0.08311132 -0.07534584\n",
      "  -0.21074611 -0.18752722 -0....-0.04164277  0.21611041 -0.01667577\n",
      "  -0.02321112  0.26490694  0.12254435  0.17855975  0.12875247 -0.05682324]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480ec8490>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.04809603 -0.06838806 -0.280678    0.04925016 -0.08311132 -0.07534584\n",
      "  -0.21074611 -0.18752722 -0....-0.04164277  0.21611041 -0.01667577\n",
      "  -0.02321112  0.26490694  0.12254435  0.17855975  0.12875247 -0.05682324]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480ec8490>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480ec8940>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480ec8940>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480ec8160>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480ec8160>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-1-1-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-0.19923545, -0.02583907,  1.1200116 ,  0.812676  ,\n",
      "          0.04157018,  0.64084774,  1.1934566 , -0.217544...5990049,  0.83942306,  1.0305735 ,\n",
      "         -1.4168856 , -1.0296179 ,  0.99236476,  0.7698078 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 6.8165e-02, -3.2411e-02, -2.2337e-01,  1.9305e-01,  3.2220e-01,\n",
      "           1.9098e-01,  3.2395e-01,  1.8917...2, -5.1890e-02, -1.3302e-02,  2.6623e-01, -5.7213e-01,\n",
      "          -4.1590e-02, -6.0814e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.13857476, -1.8186338 , -0.33518165, -1.8765092 ,\n",
      "         -0.0793776 , -0.70134187, -0.13399024,  0.215132...2205364, -1.8704532 , -1.0813411 ,\n",
      "          0.6734065 ,  0.19136558,  0.8136376 ,  0.3845128 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 3.3947e-02, -1.4480e-02, -1.4203e-01,  8.1177e-02,  1.1786e-01,\n",
      "           1.1930e-01,  1.7079e-01,  1.2374...2, -2.0238e-02, -5.5541e-03,  1.6494e-01, -2.6013e-01,\n",
      "          -2.3936e-02, -3.0851e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4610973a0>\n",
      "model_     = LSTM(1, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-1.5096e-02, -1.5530e-02,  8.3089e-02,  2.3550e-02,  2.5918e-02,\n",
      "          -6.1082e-03, -9.9790e-03, -1.1080...2, -2.0238e-02, -5.5541e-03,  1.6494e-01, -2.6013e-01,\n",
      "          -2.3936e-02, -3.0851e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 3.0871284e-01]],\n",
      "\n",
      "       [[-6.5705663e-01]],\n",
      "\n",
      "       [[ 2.0748912e-01]],\n",
      "\n",
      "       [[-9.5567503e-04]],\n",
      "\n",
      "      ...[[-1.4753785e+00]],\n",
      "\n",
      "       [[-8.9568120e-01]],\n",
      "\n",
      "       [[ 3.2788521e-01]],\n",
      "\n",
      "       [[ 1.8289043e+00]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 3.0871284e-01]]\n",
      "\n",
      " [[-6.5705663e-01]]\n",
      "\n",
      " [[ 2.0748912e-01]]\n",
      "\n",
      " [[-9.5567503e-04]]\n",
      "\n",
      " [[ 5.2311975e-01]]...+00]]\n",
      "\n",
      " [[ 1.4564855e+00]]\n",
      "\n",
      " [[-1.4753785e+00]]\n",
      "\n",
      " [[-8.9568120e-01]]\n",
      "\n",
      " [[ 3.2788521e-01]]\n",
      "\n",
      " [[ 1.8289043e+00]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4610973a0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 3.0871284e-01]]\n",
      "\n",
      " [[-6.5705663e-01]]\n",
      "\n",
      " [[ 2.0748912e-01]]\n",
      "\n",
      " [[-9.5567503e-04]]\n",
      "\n",
      " [[ 5.2311975e-01]]\n",
      "...889238e+00]]\n",
      "\n",
      " [[ 1.4564855e+00]]\n",
      "\n",
      " [[-1.4753785e+00]]\n",
      "\n",
      " [[-8.9568120e-01]]\n",
      "\n",
      " [[ 3.2788521e-01]]\n",
      "\n",
      " [[ 1.8289043e+00]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4610973a0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.30871284]]), needle.Tensor([[-0.6570566]]), needle.Tensor([[0.20748912]]), needle...edle.Tensor([[-1.4753785]]), needle.Tensor([[-0.8956812]]), needle.Tensor([[0.3278852]]), needle.Tensor([[1.8289043]]))\n",
      "        y          = needle.Tensor([[0.30871284]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.30871284]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4610977c0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[0.30871284]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.08311732 -0.02666612 -0.04704934  0.05703871 -0.00470568  0.00543988\n",
      "   0.04173981 -0.08123997 -0.0...835545 -0.05479039 -0.07951001  0.02189588\n",
      "   0.02456793  0.05817321  0.02072062 -0.00544766 -0.04475055 -0.05482881]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4610977c0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.15639538 -0.25173962  0.0264639  -0.20401296 -0.00902766 -0.02602661\n",
      "   0.07466161  0.02543661  0.1...720439  0.08425173  0.13448447  0.17742607\n",
      "   0.12273842 -0.12292516 -0.25532067 -0.05447416 -0.23544978  0.20922047]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.15639538 -0.25173962  0.0264639  -0.20401296 -0.00902766 -0.02602661\n",
      "   0.07466161  0.02543661  0.... 0.08425173  0.13448447  0.17742607\n",
      "   0.12273842 -0.12292516 -0.25532067 -0.05447416 -0.23544978  0.20922047]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450ad1850>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.15639538 -0.25173962  0.0264639  -0.20401296 -0.00902766 -0.02602661\n",
      "   0.07466161  0.02543661  0.... 0.08425173  0.13448447  0.17742607\n",
      "   0.12273842 -0.12292516 -0.25532067 -0.05447416 -0.23544978  0.20922047]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450ad1850>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ad1190>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ad1190>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb450ad1b80>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb450ad1b80>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-1-15-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 2.3582482 ,  1.2588141 , -0.39844063, -1.4670018 ,\n",
      "         -1.0213007 ,  0.60628283,  1.368775  ,  0.352419...1602037, -2.0597372 ,  0.82707983,\n",
      "          1.6138226 ,  0.3908739 , -0.5802096 , -3.5726664 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.1246,  0.2359, -0.1697, -0.1042,  0.0482, -0.1662,  0.0540,\n",
      "           0.0750, -0.0718, -0.0151,  0.0288,...,  0.1061, -0.2052,  0.0564,\n",
      "           0.1078, -0.1200, -0.0057,  0.0703, -0.1591]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-1.4506384 ,  1.6102755 , -0.6901445 ,  0.35034803,\n",
      "          0.73774254, -0.42833775,  0.22135662, -0.254425...770814 , -1.0823342 ,  0.32342798,\n",
      "          0.09055679,  0.35383156,  0.0346817 ,  1.0824305 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0716,  0.1089, -0.0893, -0.0597,  0.0226, -0.0869,  0.0269,\n",
      "           0.0366, -0.0350, -0.0071,  0.0115,...,  0.0525, -0.1044,  0.0282,\n",
      "           0.0537, -0.0618, -0.0028,  0.0275, -0.0743]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4623a5ca0>\n",
      "model_     = LSTM(1, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.0716,  0.1089, -0.0893, -0.0597,  0.0226, -0.0869,  0.0269,\n",
      "           0.0366, -0.0350, -0.0071,  0.0115,...,  0.0525, -0.1044,  0.0282,\n",
      "           0.0537, -0.0618, -0.0028,  0.0275, -0.0743]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.12400985],\n",
      "        [ 0.00281738],\n",
      "        [ 2.5012467 ],\n",
      "        [ 2.0005925 ],\n",
      "        [ 0.47176936],\n",
      "   ...8443333 ],\n",
      "        [ 0.9185465 ],\n",
      "        [-0.12493891],\n",
      "        [ 1.2338504 ],\n",
      "        [-0.5131567 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.12400985]\n",
      "  [ 0.00281738]\n",
      "  [ 2.5012467 ]\n",
      "  [ 2.0005925 ]\n",
      "  [ 0.47176936]\n",
      "  [-0.9053266 ]\n",
      "  [-0.5...[ 0.6504439 ]\n",
      "  [ 0.8459589 ]\n",
      "  [-1.8443333 ]\n",
      "  [ 0.9185465 ]\n",
      "  [-0.12493891]\n",
      "  [ 1.2338504 ]\n",
      "  [-0.5131567 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4623a5ca0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.12400985]\n",
      "  [ 0.00281738]\n",
      "  [ 2.5012467 ]\n",
      "  [ 2.0005925 ]\n",
      "  [ 0.47176936]\n",
      "  [-0.9053266 ]\n",
      "  [-0.50...28 ]\n",
      "  [ 0.6504439 ]\n",
      "  [ 0.8459589 ]\n",
      "  [-1.8443333 ]\n",
      "  [ 0.9185465 ]\n",
      "  [-0.12493891]\n",
      "  [ 1.2338504 ]\n",
      "  [-0.5131567 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4623a5ca0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.12400985]\n",
      " [ 0.00281738]\n",
      " [ 2.5012467 ]\n",
      " [ 2.0005925 ]\n",
      " [ 0.47176936]\n",
      " [-0.90532....6440728 ]\n",
      " [ 0.6504439 ]\n",
      " [ 0.8459589 ]\n",
      " [-1.8443333 ]\n",
      " [ 0.9185465 ]\n",
      " [-0.12493891]\n",
      " [ 1.2338504 ]\n",
      " [-0.5131567 ]]),)\n",
      "        y          = needle.Tensor([[ 0.12400985]\n",
      " [ 0.00281738]\n",
      " [ 2.5012467 ]\n",
      " [ 2.0005925 ]\n",
      " [ 0.47176936]\n",
      " [-0.9053266 ]\n",
      " [-0.5008287 ]\n",
      " [ 1.6440728 ]\n",
      " [ 0.6504439 ]\n",
      " [ 0.8459589 ]\n",
      " [-1.8443333 ]\n",
      " [ 0.9185465 ]\n",
      " [-0.12493891]\n",
      " [ 1.2338504 ]\n",
      " [-0.5131567 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.12400985]\n",
      " [ 0.00281738]\n",
      " [ 2.5012467 ]\n",
      " [ 2.0005925 ]\n",
      " [ 0.47176936]\n",
      " [-0.9053266 ]\n",
      " [-0.5008287 ... 0.6504439 ]\n",
      " [ 0.8459589 ]\n",
      " [-1.8443333 ]\n",
      " [ 0.9185465 ]\n",
      " [-0.12493891]\n",
      " [ 1.2338504 ]\n",
      " [-0.5131567 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4623a5220>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.12400985]\n",
      " [ 0.00281738]\n",
      " [ 2.5012467 ]\n",
      " [ 2.0005925 ]\n",
      " [ 0.47176936]\n",
      " [-0.9053266 ]\n",
      " [-0.5008287 ]\n",
      " [ 1.6440728 ]\n",
      " [ 0.6504439 ]\n",
      " [ 0.8459589 ]\n",
      " [-1.8443333 ]\n",
      " [ 0.9185465 ]\n",
      " [-0.12493891]\n",
      " [ 1.2338504 ]\n",
      " [-0.5131567 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.05097292e-02 -2.32749226e-04 -3.22693512e-02 -5.23853162e-03\n",
      "   9.03756078e-03 -2.76718754e-02 -8.4...02 -3.85617763e-02  8.04402586e-03  3.72230969e-02\n",
      "   9.47593749e-02  6.94994777e-02 -2.85398718e-02 -1.22909896e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4623a5220>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.02985626 -0.25829542 -0.02501628  0.07611057  0.2820207   0.05713624\n",
      "   0.19189304  0.20165777 -0.0...286597 -0.09328538  0.2748263  -0.08708689\n",
      "  -0.17177293  0.03253385  0.2610399  -0.17259532  0.05440837 -0.2542286 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.02985626 -0.25829542 -0.02501628  0.07611057  0.2820207   0.05713624\n",
      "   0.19189304  0.20165777 -0....-0.09328538  0.2748263  -0.08708689\n",
      "  -0.17177293  0.03253385  0.2610399  -0.17259532  0.05440837 -0.2542286 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb458f80340>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.02985626 -0.25829542 -0.02501628  0.07611057  0.2820207   0.05713624\n",
      "   0.19189304  0.20165777 -0....-0.09328538  0.2748263  -0.08708689\n",
      "  -0.17177293  0.03253385  0.2610399  -0.17259532  0.05440837 -0.2542286 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb458f80340>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458f80f70>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458f80f70>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb458f80f40>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb458f80f40>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-1-15-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 1.0777075 , -0.32710776, -0.07586683, -0.3340058 ,\n",
      "          0.845514  ,  0.31799328, -0.7855022 , -0.779459...283263 ,  0.47155815,  1.4042562 ,\n",
      "         -0.22903714,  0.18206109, -0.5823829 , -0.4812065 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-5.1464e-03,  2.2920e-01, -5.8510e-01,  2.3405e-01,  3.2161e-02,\n",
      "           2.5404e-01,  1.4492e-02, -4.0296...1,  1.9234e-01, -1.8409e-01, -2.8710e-01,  4.9615e-02,\n",
      "           7.7437e-01,  2.4502e-01]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.16687135, -0.9367234 ,  1.304043  , -0.34771946,\n",
      "         -0.9509853 ,  0.74508816,  0.4081586 ,  0.384184...388899 , -0.45423737, -0.3906026 ,\n",
      "         -0.6260169 , -1.2103616 ,  0.18510434, -1.5975437 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-2.6061e-03,  1.2826e-01, -3.0066e-01,  9.4441e-02,  1.8566e-02,\n",
      "           1.0745e-01,  7.2676e-03, -2.1276...2,  1.3111e-01, -8.9504e-02, -1.0105e-01,  3.0444e-02,\n",
      "           3.0293e-01,  1.1879e-01]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb43830c100>\n",
      "model_     = LSTM(1, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.0085,  0.0082, -0.1591,  ...,  0.0404,  0.1032,  0.0918],\n",
      "         [-0.0204,  0.0879, -0.0869,  ..., -0.0...53, -0.0647],\n",
      "         [ 0.0083,  0.0978, -0.2776,  ...,  0.0304,  0.3029,  0.1188]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 1.391776  ],\n",
      "        [-1.262056  ],\n",
      "        [ 0.61471176],\n",
      "        [ 0.5875179 ],\n",
      "        [ 0.86884075],\n",
      "   ...53515506],\n",
      "        [-1.8070964 ],\n",
      "        [ 0.08783793],\n",
      "        [-1.9447997 ],\n",
      "        [ 2.4995835 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.391776  ]\n",
      "  [-1.262056  ]\n",
      "  [ 0.61471176]\n",
      "  [ 0.5875179 ]\n",
      "  [ 0.86884075]\n",
      "  [ 0.23672125]\n",
      "  [ 0.0...[-0.3057919 ]\n",
      "  [-0.8978176 ]\n",
      "  [ 0.53515506]\n",
      "  [-1.8070964 ]\n",
      "  [ 0.08783793]\n",
      "  [-1.9447997 ]\n",
      "  [ 2.4995835 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb43830c100>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 1.391776  ]\n",
      "  [-1.262056  ]\n",
      "  [ 0.61471176]\n",
      "  [ 0.5875179 ]\n",
      "  [ 0.86884075]\n",
      "  [ 0.23672125]\n",
      "  [ 0.09...821]\n",
      "  [-0.3057919 ]\n",
      "  [-0.8978176 ]\n",
      "  [ 0.53515506]\n",
      "  [-1.8070964 ]\n",
      "  [ 0.08783793]\n",
      "  [-1.9447997 ]\n",
      "  [ 2.4995835 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb43830c100>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.391776  ]\n",
      " [-1.262056  ]\n",
      " [ 0.61471176]\n",
      " [ 0.5875179 ]\n",
      " [ 0.86884075]\n",
      " [ 0.23672...0.17194821]\n",
      " [-0.3057919 ]\n",
      " [-0.8978176 ]\n",
      " [ 0.53515506]\n",
      " [-1.8070964 ]\n",
      " [ 0.08783793]\n",
      " [-1.9447997 ]\n",
      " [ 2.4995835 ]]))\n",
      "        y          = needle.Tensor([[ 1.391776  ]\n",
      " [-1.262056  ]\n",
      " [ 0.61471176]\n",
      " [ 0.5875179 ]\n",
      " [ 0.86884075]\n",
      " [ 0.23672125]\n",
      " [ 0.09493764]\n",
      " [-1.3510593 ]\n",
      " [ 1.0504389 ]\n",
      " [-0.9630216 ]\n",
      " [-0.31107435]\n",
      " [-1.2265916 ]\n",
      " [ 0.61249334]\n",
      " [-0.9745204 ]\n",
      " [ 2.033431  ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.391776  ]\n",
      " [-1.262056  ]\n",
      " [ 0.61471176]\n",
      " [ 0.5875179 ]\n",
      " [ 0.86884075]\n",
      " [ 0.23672125]\n",
      " [ 0.09493764... 1.0504389 ]\n",
      " [-0.9630216 ]\n",
      " [-0.31107435]\n",
      " [-1.2265916 ]\n",
      " [ 0.61249334]\n",
      " [-0.9745204 ]\n",
      " [ 2.033431  ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb43830cb80>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 1.391776  ]\n",
      " [-1.262056  ]\n",
      " [ 0.61471176]\n",
      " [ 0.5875179 ]\n",
      " [ 0.86884075]\n",
      " [ 0.23672125]\n",
      " [ 0.09493764]\n",
      " [-1.3510593 ]\n",
      " [ 1.0504389 ]\n",
      " [-0.9630216 ]\n",
      " [-0.31107435]\n",
      " [-1.2265916 ]\n",
      " [ 0.61249334]\n",
      " [-0.9745204 ]\n",
      " [ 2.033431  ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.55828148e-01 -8.50015804e-02 -3.17540079e-01 -3.36424530e-01\n",
      "   2.52641737e-01 -2.46222913e-01  8.3...03 -3.59624267e-01  5.75231075e-01 -1.89744443e-01\n",
      "  -4.64401186e-01  5.08657992e-01  1.14069320e-01 -1.41018454e-03]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb43830cb80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 7.42482543e-02 -1.60425112e-01  1.90745503e-01  2.28015959e-01\n",
      "  -1.05033591e-01 -1.84925407e-01 -5.9...03  4.19998765e-02 -1.47965834e-01 -2.00111240e-01\n",
      "  -2.26834789e-01  1.41013622e-01 -1.11876115e-01  9.42911506e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 7.42482543e-02 -1.60425112e-01  1.90745503e-01  2.28015959e-01\n",
      "  -1.05033591e-01 -1.84925407e-01 -5....9998765e-02 -1.47965834e-01 -2.00111240e-01\n",
      "  -2.26834789e-01  1.41013622e-01 -1.11876115e-01  9.42911506e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb472203970>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 7.42482543e-02 -1.60425112e-01  1.90745503e-01  2.28015959e-01\n",
      "  -1.05033591e-01 -1.84925407e-01 -5....9998765e-02 -1.47965834e-01 -2.00111240e-01\n",
      "  -2.26834789e-01  1.41013622e-01 -1.11876115e-01  9.42911506e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb472203970>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4722034f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4722034f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb472203220>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb472203220>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-1-15-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-4.87779200e-01, -7.63887912e-02,  1.46472409e-01,\n",
      "          2.28591308e-01,  1.84502256e+00,  1.17147386e+00..., -1.16472006e+00,  2.02336758e-02,\n",
      "          1.50165796e+00,  9.56072032e-01,  4.07359004e-01]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0750,  0.1546,  0.1278, -0.0908,  0.1132,  0.1306,  0.1601,\n",
      "           0.0824,  0.1101, -0.0259,  0.1507,...,  0.0166,  0.2101,  0.1218,\n",
      "          -0.2027, -0.0368,  0.0295, -0.0908,  0.2628]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-1.00013876e+00, -2.01582432e+00,  7.03810379e-02,\n",
      "          1.77161261e-01, -3.21038455e-01,  4.04481292e-01..., -2.02538162e-01,  5.27741194e-01,\n",
      "         -1.10257423e+00, -1.38745391e+00,  1.84421584e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0413,  0.0933,  0.0706, -0.0422,  0.0694,  0.0727,  0.0698,\n",
      "           0.0416,  0.0524, -0.0098,  0.0837,...,  0.0068,  0.0949,  0.0630,\n",
      "          -0.1015, -0.0171,  0.0165, -0.0414,  0.0951]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb481207e50>\n",
      "model_     = LSTM(1, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0132,  0.0019, -0.0022,  0.0453,  0.0049,  0.0973,  0.0570,\n",
      "          -0.0954, -0.0190,  0.0182, -0.0407,...,  0.0068,  0.0949,  0.0630,\n",
      "          -0.1015, -0.0171,  0.0165, -0.0414,  0.0951]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.02514194],\n",
      "        [ 1.339684  ],\n",
      "        [ 0.9264224 ],\n",
      "        [-0.70224684],\n",
      "        [ 1.6885544 ],\n",
      "   ...37816852],\n",
      "        [ 1.2457895 ],\n",
      "        [-0.86983806],\n",
      "        [ 0.736509  ],\n",
      "        [ 0.62060547]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.02514194]\n",
      "  [ 1.339684  ]\n",
      "  [ 0.9264224 ]\n",
      "  [-0.70224684]\n",
      "  [ 1.6885544 ]\n",
      "  [-0.1106329 ]\n",
      "  [-0.3...[ 1.0176202 ]\n",
      "  [ 0.345274  ]\n",
      "  [-0.37816852]\n",
      "  [ 1.2457895 ]\n",
      "  [-0.86983806]\n",
      "  [ 0.736509  ]\n",
      "  [ 0.62060547]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb481207e50>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.02514194]\n",
      "  [ 1.339684  ]\n",
      "  [ 0.9264224 ]\n",
      "  [-0.70224684]\n",
      "  [ 1.6885544 ]\n",
      "  [-0.1106329 ]\n",
      "  [-0.39...641]\n",
      "  [ 1.0176202 ]\n",
      "  [ 0.345274  ]\n",
      "  [-0.37816852]\n",
      "  [ 1.2457895 ]\n",
      "  [-0.86983806]\n",
      "  [ 0.736509  ]\n",
      "  [ 0.62060547]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb481207e50>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.02514194]\n",
      " [ 1.339684  ]\n",
      " [ 0.9264224 ]\n",
      " [-0.70224684]\n",
      " [ 1.6885544 ]\n",
      " [-0.11063....18609641]\n",
      " [ 1.0176202 ]\n",
      " [ 0.345274  ]\n",
      " [-0.37816852]\n",
      " [ 1.2457895 ]\n",
      " [-0.86983806]\n",
      " [ 0.736509  ]\n",
      " [ 0.62060547]]),)\n",
      "        y          = needle.Tensor([[ 0.02514194]\n",
      " [ 1.339684  ]\n",
      " [ 0.9264224 ]\n",
      " [-0.70224684]\n",
      " [ 1.6885544 ]\n",
      " [-0.1106329 ]\n",
      " [-0.39312696]\n",
      " [ 0.18609641]\n",
      " [ 1.0176202 ]\n",
      " [ 0.345274  ]\n",
      " [-0.37816852]\n",
      " [ 1.2457895 ]\n",
      " [-0.86983806]\n",
      " [ 0.736509  ]\n",
      " [ 0.62060547]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.02514194]\n",
      " [ 1.339684  ]\n",
      " [ 0.9264224 ]\n",
      " [-0.70224684]\n",
      " [ 1.6885544 ]\n",
      " [-0.1106329 ]\n",
      " [-0.39312696... 1.0176202 ]\n",
      " [ 0.345274  ]\n",
      " [-0.37816852]\n",
      " [ 1.2457895 ]\n",
      " [-0.86983806]\n",
      " [ 0.736509  ]\n",
      " [ 0.62060547]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb481207040>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.02514194]\n",
      " [ 1.339684  ]\n",
      " [ 0.9264224 ]\n",
      " [-0.70224684]\n",
      " [ 1.6885544 ]\n",
      " [-0.1106329 ]\n",
      " [-0.39312696]\n",
      " [ 0.18609641]\n",
      " [ 1.0176202 ]\n",
      " [ 0.345274  ]\n",
      " [-0.37816852]\n",
      " [ 1.2457895 ]\n",
      " [-0.86983806]\n",
      " [ 0.736509  ]\n",
      " [ 0.62060547]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 4.37989656e-04 -6.91435952e-03  2.01302930e-03  6.46517321e-04\n",
      "   3.48162302e-03  4.80911275e-03 -6.9...02  2.30110455e-02  1.36298031e-01 -8.42191949e-02\n",
      "   2.55528055e-02  6.90887496e-02 -2.99697686e-02  1.51036412e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb481207040>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.27567366  0.07625073  0.18337873  0.23944825  0.11988717 -0.06856167\n",
      "   0.28689194  0.15972826 -0.1...2863722 -0.2485459   0.2021048   0.1624322\n",
      "  -0.01999995  0.134049   -0.11456306 -0.00148743 -0.11201772 -0.1611132 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.27567366  0.07625073  0.18337873  0.23944825  0.11988717 -0.06856167\n",
      "   0.28689194  0.15972826 -0.... -0.2485459   0.2021048   0.1624322\n",
      "  -0.01999995  0.134049   -0.11456306 -0.00148743 -0.11201772 -0.1611132 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb458b48760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.27567366  0.07625073  0.18337873  0.23944825  0.11988717 -0.06856167\n",
      "   0.28689194  0.15972826 -0.... -0.2485459   0.2021048   0.1624322\n",
      "  -0.01999995  0.134049   -0.11456306 -0.00148743 -0.11201772 -0.1611132 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb458b48760>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458b48580>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458b48580>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb458b48bb0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb458b48bb0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-1-15-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 6.35419965e-01, -1.86549217e-01, -5.06334424e-01,\n",
      "          7.51888812e-01, -8.54223073e-01, -7.03646779e-01...,  2.50241786e-01, -4.39707667e-01,\n",
      "         -1.70805120e+00,  8.93836856e-01,  8.97424698e-01]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-5.5650e-01, -3.0007e-01, -3.7884e-01,  3.2952e-01,  1.4604e-01,\n",
      "          -1.2959e-01,  5.1821e-01,  1.1657...2, -1.9806e-01,  3.1940e-01, -4.4161e-03,  4.2739e-02,\n",
      "           2.1425e-01,  1.0267e-01]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-1.45708776e+00,  6.50445998e-01,  1.20449042e+00,\n",
      "          1.22977637e-01,  2.68581510e-01,  1.35193682e+00...,  4.72587883e-01, -3.78220007e-02,\n",
      "          1.41333568e+00, -3.91365319e-01,  3.49104643e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-2.4415e-01, -1.1164e-01, -1.9814e-01,  1.3259e-01,  7.5232e-02,\n",
      "          -6.2593e-02,  2.5071e-01,  7.0350...2, -9.3556e-02,  1.4563e-01, -2.2345e-03,  1.9809e-02,\n",
      "           1.0996e-01,  5.0613e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4384cf370>\n",
      "model_     = LSTM(1, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0396, -0.0555,  0.0386,  ...,  0.0311,  0.0288,  0.0147],\n",
      "         [-0.0421, -0.0538,  0.0386,  ...,  0.0...15,  0.0593],\n",
      "         [-0.0779, -0.1505,  0.0872,  ...,  0.0198,  0.1100,  0.0506]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 3.3323616e-01],\n",
      "        [-5.7622647e-01],\n",
      "        [ 2.8394717e-01],\n",
      "        [-5.4507017e-01],\n",
      "        [-8.72...       [-9.8635358e-01],\n",
      "        [ 8.4553355e-01],\n",
      "        [-1.5095755e+00],\n",
      "        [ 1.5671020e+00]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 3.3323616e-01]\n",
      "  [-5.7622647e-01]\n",
      "  [ 2.8394717e-01]\n",
      "  [-5.4507017e-01]\n",
      "  [-8.7294704e-01]\n",
      "  [ 3.54...5.9460789e-01]\n",
      "  [ 6.4176601e-01]\n",
      "  [-9.8635358e-01]\n",
      "  [ 8.4553355e-01]\n",
      "  [-1.5095755e+00]\n",
      "  [ 1.5671020e+00]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4384cf370>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 3.3323616e-01]\n",
      "  [-5.7622647e-01]\n",
      "  [ 2.8394717e-01]\n",
      "  [-5.4507017e-01]\n",
      "  [-8.7294704e-01]\n",
      "  [ 3.542...0]\n",
      "  [ 5.9460789e-01]\n",
      "  [ 6.4176601e-01]\n",
      "  [-9.8635358e-01]\n",
      "  [ 8.4553355e-01]\n",
      "  [-1.5095755e+00]\n",
      "  [ 1.5671020e+00]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4384cf370>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.33323616]\n",
      " [-0.5762265 ]\n",
      " [ 0.28394717]\n",
      " [-0.5450702 ]\n",
      " [-0.87294704]\n",
      " [ 0.35420...0.41890398]\n",
      " [ 1.0569719 ]\n",
      " [ 0.5946079 ]\n",
      " [ 0.641766  ]\n",
      " [-0.9863536 ]\n",
      " [ 0.84553355]\n",
      " [-1.5095755 ]\n",
      " [ 1.567102  ]]))\n",
      "        y          = needle.Tensor([[ 0.33323616]\n",
      " [-0.5762265 ]\n",
      " [ 0.28394717]\n",
      " [-0.5450702 ]\n",
      " [-0.87294704]\n",
      " [ 0.35420936]\n",
      " [-0.1522256 ]\n",
      " [ 0.10318593]\n",
      " [ 0.18878706]\n",
      " [-0.89637446]\n",
      " [-2.7536297 ]\n",
      " [-1.1484675 ]\n",
      " [-0.00336145]\n",
      " [ 0.66075   ]\n",
      " [-0.76917744]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.33323616]\n",
      " [-0.5762265 ]\n",
      " [ 0.28394717]\n",
      " [-0.5450702 ]\n",
      " [-0.87294704]\n",
      " [ 0.35420936]\n",
      " [-0.1522256 ... 0.18878706]\n",
      " [-0.89637446]\n",
      " [-2.7536297 ]\n",
      " [-1.1484675 ]\n",
      " [-0.00336145]\n",
      " [ 0.66075   ]\n",
      " [-0.76917744]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384cf610>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.33323616]\n",
      " [-0.5762265 ]\n",
      " [ 0.28394717]\n",
      " [-0.5450702 ]\n",
      " [-0.87294704]\n",
      " [ 0.35420936]\n",
      " [-0.1522256 ]\n",
      " [ 0.10318593]\n",
      " [ 0.18878706]\n",
      " [-0.89637446]\n",
      " [-2.7536297 ]\n",
      " [-1.1484675 ]\n",
      " [-0.00336145]\n",
      " [ 0.66075   ]\n",
      " [-0.76917744]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 3.74567844e-02  3.75852063e-02 -6.10787123e-02 -4.11674231e-02\n",
      "   3.58662829e-02 -4.89836140e-03 -7.7...02  6.59213513e-02 -1.05803654e-01 -5.87359369e-02\n",
      "  -1.86024621e-01 -1.63403153e-01  4.16255593e-02  1.30944014e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4384cf610>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-1.51899666e-01  2.32775152e-01  2.17919588e-01  1.90895408e-01\n",
      "  -6.89259171e-03 -1.31467402e-01  2.2...02 -5.49288541e-02  1.47514552e-01 -2.00975657e-01\n",
      "  -2.17393190e-01  5.32369614e-02 -1.95593745e-01 -1.76383644e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-1.51899666e-01  2.32775152e-01  2.17919588e-01  1.90895408e-01\n",
      "  -6.89259171e-03 -1.31467402e-01  2....9288541e-02  1.47514552e-01 -2.00975657e-01\n",
      "  -2.17393190e-01  5.32369614e-02 -1.95593745e-01 -1.76383644e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450b0e850>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-1.51899666e-01  2.32775152e-01  2.17919588e-01  1.90895408e-01\n",
      "  -6.89259171e-03 -1.31467402e-01  2....9288541e-02  1.47514552e-01 -2.00975657e-01\n",
      "  -2.17393190e-01  5.32369614e-02 -1.95593745e-01 -1.76383644e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450b0e850>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450b0ee20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450b0ee20>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb450b0e760>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb450b0e760>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-11-1-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[-1.9535276 ,  1.3897046 , -0.7032378 , -0.26819953,\n",
      "         -0.4194962 ,  0.37479517,  0.00904278,  1.1009178 ,\n",
      "         -0.26006052,  1.5056902 ,  0.45877174,  0.37794015]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0402,  0.3172, -0.1563, -0.0113,  0.1539, -0.1033,  0.0172,\n",
      "          -0.1913, -0.1897, -0.2489, -0.0815, -0.0491]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.9992575 ,  1.9943334 , -0.9842535 ,  0.689328  ,\n",
      "         -0.9388601 ,  0.17136513,  0.8238672 ,  1.5416358 ,\n",
      "          1.9761972 ,  0.5024374 ,  1.3152229 , -0.48683283]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0195,  0.1974, -0.0670, -0.0062,  0.0524, -0.0662,  0.0077,\n",
      "          -0.0769, -0.1433, -0.1669, -0.0608, -0.0202]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb458d167f0>\n",
      "model_     = LSTM(11, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0195,  0.1974, -0.0670, -0.0062,  0.0524, -0.0662,  0.0077,\n",
      "          -0.0769, -0.1433, -0.1669, -0.0608, -0.0202]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.7665127 ,  0.28591603,  1.1718932 , -0.8146418 ,\n",
      "          0.5873824 ,  0.6187934 , -0.6575316 , -0.9275772 ,\n",
      "          1.7136772 ,  1.3231167 , -0.7336183 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.7665127   0.28591603  1.1718932  -0.8146418   0.5873824\n",
      "    0.6187934  -0.6575316  -0.9275772   1.7136772   1.3231167\n",
      "   -0.7336183 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458d167f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.7665127   0.28591603  1.1718932  -0.8146418   0.5873824\n",
      "    0.6187934  -0.6575316  -0.9275772   1.7136772   1.3231167\n",
      "   -0.7336183 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458d167f0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.7665127   0.28591603  1.1718932  -0.8146418   0.5873824   0.6187934\n",
      "  -0.6575316  -0.9275772   1.7136772   1.3231167  -0.7336183 ]]),)\n",
      "        y          = needle.Tensor([[-0.7665127   0.28591603  1.1718932  -0.8146418   0.5873824   0.6187934\n",
      "  -0.6575316  -0.9275772   1.7136772   1.3231167  -0.7336183 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.7665127   0.28591603  1.1718932  -0.8146418   0.5873824   0.6187934\n",
      "  -0.6575316  -0.9275772   1.7136772   1.3231167  -0.7336183 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458d16df0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.7665127   0.28591603  1.1718932  -0.8146418   0.5873824   0.6187934\n",
      "  -0.6575316  -0.9275772   1.7136772   1.3231167  -0.7336183 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.34517905  0.14164595 -0.7828365  -0.08992228 -0.9537905   0.49953863\n",
      "  -0.48713145  0.05725482 -0.5...8615114  0.14061406 -0.17475037  0.2944912\n",
      "  -0.6545856  -0.6440271   0.799535    0.5165991   0.9945172  -0.37162986]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458d16df0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.23249733 -0.0719932   0.10070446  0.22581118 -0.021837   -0.08473986\n",
      "  -0.14625315  0.23758775 -0.2...252324  0.15947655  0.13102421 -0.01067546\n",
      "   0.27321208 -0.02464163  0.23592228 -0.17100075  0.17327765 -0.0184342 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.23249733 -0.0719932   0.10070446  0.22581118 -0.021837   -0.08473986\n",
      "  -0.14625315  0.23758775 -0.... 0.15947655  0.13102421 -0.01067546\n",
      "   0.27321208 -0.02464163  0.23592228 -0.17100075  0.17327765 -0.0184342 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb458d16370>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.23249733 -0.0719932   0.10070446  0.22581118 -0.021837   -0.08473986\n",
      "  -0.14625315  0.23758775 -0.... 0.15947655  0.13102421 -0.01067546\n",
      "   0.27321208 -0.02464163  0.23592228 -0.17100075  0.17327765 -0.0184342 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb458d16370>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458d16b80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458d16b80>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb458d16580>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb458d16580>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-11-1-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[ 0.77178246, -0.4776628 , -0.16097166, -0.5336423 ,\n",
      "         -0.493166  , -0.40108687, -0.48816046,  0.0866133 ,\n",
      "         -1.4419305 ,  0.6855957 ,  1.4298    , -0.23907614]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0032, -0.7738, -0.5897, -0.3254, -0.0552, -0.5380,  0.4488,\n",
      "           0.2371,  0.3983, -0.6099, -0.4138, -0.1265]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.21005897,  0.25581157,  1.0248598 , -0.37660342,\n",
      "         -1.1531821 , -0.37103915,  0.40748844,  1.3475586 ,\n",
      "          2.867225  , -0.9707204 ,  3.245561  ,  0.6092206 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0010, -0.2893, -0.2727, -0.1513, -0.0432, -0.2122,  0.2446,\n",
      "           0.1443,  0.1459, -0.3303, -0.1075, -0.0683]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb450740400>\n",
      "model_     = LSTM(11, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 1.0096e-02, -2.8588e-02,  2.5783e-02, -4.9024e-02, -8.0999e-02,\n",
      "           8.5808e-02,  2.1101e-01, -1.0658...1,  2.4463e-01,  1.4434e-01,  1.4595e-01, -3.3035e-01,\n",
      "          -1.0748e-01, -6.8291e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.8795432 ,  0.3041761 ,  0.60543656,  0.39610207,\n",
      "         -0.03637303, -0.30839333,  1.3975867 ,  0.029771...  -1.8010514 , -1.0740008 ,  0.7790133 , -0.3160903 ,\n",
      "         -0.34433913, -0.15746784, -0.36428508]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.8795432   0.3041761   0.60543656  0.39610207 -0.03637303\n",
      "   -0.30839333  1.3975867   0.02977183  ...2025435 -1.273022   -1.8010514\n",
      "   -1.0740008   0.7790133  -0.3160903  -0.34433913 -0.15746784\n",
      "   -0.36428508]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450740400>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.8795432   0.3041761   0.60543656  0.39610207 -0.03637303\n",
      "   -0.30839333  1.3975867   0.02977183  1...5  -0.92025435 -1.273022   -1.8010514\n",
      "   -1.0740008   0.7790133  -0.3160903  -0.34433913 -0.15746784\n",
      "   -0.36428508]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450740400>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.8795432   0.3041761   0.60543656  0.39610207 -0.03637303 -0.30839333\n",
      "   1.397586...65805  -0.92025435 -1.273022   -1.8010514  -1.0740008\n",
      "   0.7790133  -0.3160903  -0.34433913 -0.15746784 -0.36428508]]))\n",
      "        y          = needle.Tensor([[ 0.8795432   0.3041761   0.60543656  0.39610207 -0.03637303 -0.30839333\n",
      "   1.3975867   0.02977183  1.9410675  -0.60499775  1.6715475 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.8795432   0.3041761   0.60543656  0.39610207 -0.03637303 -0.30839333\n",
      "   1.3975867   0.02977183  1.9410675  -0.60499775  1.6715475 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450740be0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.8795432   0.3041761   0.60543656  0.39610207 -0.03637303 -0.30839333\n",
      "   1.3975867   0.02977183  1.9410675  -0.60499775  1.6715475 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.88668853  0.13796298 -1.1407492   0.45495877 -1.1246156  -0.43767336\n",
      "  -0.22682747 -0.20913328 -0.0...722117 -0.45712522 -0.5188653   0.17713113\n",
      "  -0.03616136  0.02593078 -0.38127366  1.6386157   0.8419055  -1.041646  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450740be0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-1.77621827e-01 -2.30217636e-01 -1.76916361e-01 -2.81105667e-01\n",
      "   5.94351590e-02 -3.55946422e-02  2.4...02 -2.71526217e-01 -1.19106233e-01  2.03871340e-01\n",
      "  -9.40120667e-02  2.26900458e-01 -1.24588013e-01 -3.80423665e-03]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-1.77621827e-01 -2.30217636e-01 -1.76916361e-01 -2.81105667e-01\n",
      "   5.94351590e-02 -3.55946422e-02  2....1526217e-01 -1.19106233e-01  2.03871340e-01\n",
      "  -9.40120667e-02  2.26900458e-01 -1.24588013e-01 -3.80423665e-03]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb458c9d850>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-1.77621827e-01 -2.30217636e-01 -1.76916361e-01 -2.81105667e-01\n",
      "   5.94351590e-02 -3.55946422e-02  2....1526217e-01 -1.19106233e-01  2.03871340e-01\n",
      "  -9.40120667e-02  2.26900458e-01 -1.24588013e-01 -3.80423665e-03]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb458c9d850>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458c9d820>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458c9d820>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb458c9d0d0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb458c9d0d0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-11-1-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[ 0.16628362, -0.70352274,  0.9039119 ,  0.8104819 ,\n",
      "         -2.143032  , -1.6165034 ,  0.7776471 ,  1.332153...4354366, -1.4131234 , -0.3293647 ,\n",
      "          1.5549357 ,  0.5280281 , -0.94785744,  1.2052984 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0685,  0.2695,  0.1214, -0.0775,  0.1753, -0.2302,  0.2375,\n",
      "          -0.0658, -0.0595, -0.1189,  0.0860,..., -0.0504,  0.0689,  0.1267,\n",
      "           0.1765,  0.0648,  0.0850,  0.0517, -0.0374]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.20594247, -0.09254243,  0.5122671 ,  0.54916954,\n",
      "          0.3386803 , -0.14752136, -0.948463  , -1.172102...944278 ,  0.7902791 ,  1.2541417 ,\n",
      "          0.37687638, -0.9392304 , -0.769462  ,  1.024599  ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0259,  0.1259,  0.0705, -0.0350,  0.1095, -0.0741,  0.1420,\n",
      "          -0.0225, -0.0355, -0.0556,  0.0670,..., -0.0244,  0.0335,  0.0610,\n",
      "           0.0934,  0.0326,  0.0423,  0.0248, -0.0156]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4382ef040>\n",
      "model_     = LSTM(11, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0358, -0.0232, -0.0202, -0.0545, -0.0244,  0.0335,  0.0610,\n",
      "           0.0934,  0.0326,  0.0423,  0.0248, -0.0156]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.37109578,  1.2359495 , -0.32719004,  0.44718438,\n",
      "          0.35848212,  0.6179595 ,  0.30666617,  0.31188497,\n",
      "         -0.41840458,  0.58484685,  0.52324176]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.37109578  1.2359495  -0.32719004  0.44718438  0.35848212\n",
      "    0.6179595   0.30666617  0.31188497 -0.41840458  0.58484685\n",
      "    0.52324176]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4382ef040>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.37109578  1.2359495  -0.32719004  0.44718438  0.35848212\n",
      "    0.6179595   0.30666617  0.31188497 -0.41840458  0.58484685\n",
      "    0.52324176]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4382ef040>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.37109578  1.2359495  -0.32719004  0.44718438  0.35848212  0.6179595\n",
      "   0.30666617  0.31188497 -0.41840458  0.58484685  0.52324176]]),)\n",
      "        y          = needle.Tensor([[ 0.37109578  1.2359495  -0.32719004  0.44718438  0.35848212  0.6179595\n",
      "   0.30666617  0.31188497 -0.41840458  0.58484685  0.52324176]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.37109578  1.2359495  -0.32719004  0.44718438  0.35848212  0.6179595\n",
      "   0.30666617  0.31188497 -0.41840458  0.58484685  0.52324176]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4382efca0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.37109578  1.2359495  -0.32719004  0.44718438  0.35848212  0.6179595\n",
      "   0.30666617  0.31188497 -0.41840458  0.58484685  0.52324176]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.11132988  0.13847443 -0.06703496 -0.59188837 -0.05164207  0.20855527\n",
      "  -0.12751025  0.3629715  -0.0...5065733 -0.23530851  0.06543574 -0.5733931\n",
      "   0.17001429 -0.74393874  0.27567807 -0.03458369  0.7112816  -0.35099998]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4382efca0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.13819323 -0.01756978  0.12608042  0.08705792  0.28205454 -0.00806952\n",
      "   0.08751136  0.21357411 -0.2...452743 -0.11772197  0.12103724 -0.26611942\n",
      "  -0.11039758 -0.08776276  0.08067626 -0.28848833 -0.17957231  0.19906995]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.13819323 -0.01756978  0.12608042  0.08705792  0.28205454 -0.00806952\n",
      "   0.08751136  0.21357411 -0....-0.11772197  0.12103724 -0.26611942\n",
      "  -0.11039758 -0.08776276  0.08067626 -0.28848833 -0.17957231  0.19906995]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46238c3a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.13819323 -0.01756978  0.12608042  0.08705792  0.28205454 -0.00806952\n",
      "   0.08751136  0.21357411 -0....-0.11772197  0.12103724 -0.26611942\n",
      "  -0.11039758 -0.08776276  0.08067626 -0.28848833 -0.17957231  0.19906995]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46238c3a0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46238c160>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46238c160>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46238c220>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46238c220>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-11-1-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = True\n",
      "c0         = array([[[ 0.29047465,  0.80891794,  0.4758746 ,  0.7075396 ,\n",
      "          0.6968371 , -1.226044  ,  1.0573199 , -1.282869...353701 , -0.78033   , -0.88843864,\n",
      "          0.03550734, -0.5514282 , -1.4739906 ,  0.07457845]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.5049, -0.0608,  0.7225, -0.3986,  0.4240,  0.2516, -0.7085,\n",
      "           0.1771, -0.2126,  0.2349,  0.2027,..., -0.4113, -0.3462,  0.2743,\n",
      "           0.0965, -0.2875, -0.0377,  0.0027,  0.3783]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.45001283, -0.26537302,  0.13485417, -0.72258216,\n",
      "         -0.17886452,  0.711365  ,  0.81961095, -0.775656...1535705,  0.05966207,  0.45919222,\n",
      "         -0.406915  ,  0.0992578 ,  1.7550702 , -0.29955772]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.1313, -0.0390,  0.2150, -0.2104,  0.2744,  0.1136, -0.1132,\n",
      "           0.1053, -0.1757,  0.1066,  0.0659,..., -0.2308, -0.1523,  0.1439,\n",
      "           0.0411, -0.1609, -0.0204,  0.0015,  0.2138]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb461261d00>\n",
      "model_     = LSTM(11, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.1001, -0.0944, -0.0051, -0.0119, -0.1010, -0.0724,  0.0702,\n",
      "           0.0205, -0.0364, -0.0452, -0.0120,..., -0.2308, -0.1523,  0.1439,\n",
      "           0.0411, -0.1609, -0.0204,  0.0015,  0.2138]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.2586098 , -1.0848764 ,  0.6415585 ,  1.1701317 ,\n",
      "         -0.6987471 ,  0.01541699, -0.48681414,  1.683224...  -2.5130284 , -0.33494478, -1.7068764 , -1.4958111 ,\n",
      "         -0.7950236 ,  1.6458857 ,  0.5722694 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.2586098  -1.0848764   0.6415585   1.1701317  -0.6987471\n",
      "    0.01541699 -0.48681414  1.6832249   0...641694    0.6952515  -2.5130284\n",
      "   -0.33494478 -1.7068764  -1.4958111  -0.7950236   1.6458857\n",
      "    0.5722694 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461261d00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.2586098  -1.0848764   0.6415585   1.1701317  -0.6987471\n",
      "    0.01541699 -0.48681414  1.6832249   0....7   -0.641694    0.6952515  -2.5130284\n",
      "   -0.33494478 -1.7068764  -1.4958111  -0.7950236   1.6458857\n",
      "    0.5722694 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461261d00>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.2586098  -1.0848764   0.6415585   1.1701317  -0.6987471   0.01541699\n",
      "  -0.486814...977   -0.641694    0.6952515  -2.5130284  -0.33494478\n",
      "  -1.7068764  -1.4958111  -0.7950236   1.6458857   0.5722694 ]]))\n",
      "        y          = needle.Tensor([[ 0.2586098  -1.0848764   0.6415585   1.1701317  -0.6987471   0.01541699\n",
      "  -0.48681414  1.6832249   0.48659143  0.460142   -0.7091205 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.2586098  -1.0848764   0.6415585   1.1701317  -0.6987471   0.01541699\n",
      "  -0.48681414  1.6832249   0.48659143  0.460142   -0.7091205 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461261100>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.2586098  -1.0848764   0.6415585   1.1701317  -0.6987471   0.01541699\n",
      "  -0.48681414  1.6832249   0.48659143  0.460142   -0.7091205 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.4363979   0.37084466  0.5549561   0.0904365   0.10168609 -0.5256993\n",
      "   0.0254465  -0.7096705   0.73...03339  -0.14037596 -0.01240762 -0.42525595\n",
      "  -0.0918858   0.8965045   0.22364828 -0.09806401  0.6482214  -0.6930149 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461261100>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.28267014e-02  2.74364054e-01  2.27197587e-01  2.62125850e-01\n",
      "  -2.72681415e-01 -2.48036072e-01  2.3...01 -2.80594766e-01 -5.71685433e-02 -2.80872375e-01\n",
      "  -1.14287794e-01 -1.49767995e-02 -2.61571884e-01 -2.19838634e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.28267014e-02  2.74364054e-01  2.27197587e-01  2.62125850e-01\n",
      "  -2.72681415e-01 -2.48036072e-01  2....0594766e-01 -5.71685433e-02 -2.80872375e-01\n",
      "  -1.14287794e-01 -1.49767995e-02 -2.61571884e-01 -2.19838634e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb462376940>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.28267014e-02  2.74364054e-01  2.27197587e-01  2.62125850e-01\n",
      "  -2.72681415e-01 -2.48036072e-01  2....0594766e-01 -5.71685433e-02 -2.80872375e-01\n",
      "  -1.14287794e-01 -1.49767995e-02 -2.61571884e-01 -2.19838634e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb462376940>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4623766d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4623766d0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb462376e50>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb462376e50>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-11-15-1-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-2.14941049e+00,  8.47787634e-02,  5.30305862e-01,\n",
      "          3.87532383e-01,  3.69933963e-01,  4.12610710e-01..., -1.68300104e+00,  9.87374187e-01,\n",
      "          9.78395760e-01,  3.26650798e-01, -4.66459304e-01]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 6.8163e-02,  3.1677e-01, -2.3227e-01,  1.2926e-01, -1.1601e-01,\n",
      "          -1.3351e-01,  2.8997e-02,  1.5041...1,  9.7080e-02,  1.0744e-01, -6.5137e-03,  2.5094e-01,\n",
      "          -1.9419e-01,  2.9989e-01]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-8.4426355e-01, -2.4498630e-02,  4.3790263e-01,  1.3245547e-01,\n",
      "         -3.7650743e-01,  1.9385508e+00, -7.7...0e-01,  2.8297412e-01,\n",
      "          6.2572867e-01, -5.9266701e-02, -9.2076677e-01, -3.6052465e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 4.9953e-02,  2.0053e-01, -7.1796e-02,  4.9031e-02, -6.5753e-02,\n",
      "          -5.5580e-02,  2.0447e-02,  9.5797...1,  5.2586e-02,  4.4216e-02, -2.6089e-03,  1.4180e-01,\n",
      "          -9.0915e-02,  1.8943e-01]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb471e03f70>\n",
      "model_     = LSTM(11, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 4.9953e-02,  2.0053e-01, -7.1796e-02,  4.9031e-02, -6.5753e-02,\n",
      "          -5.5580e-02,  2.0447e-02,  9.5797...1,  5.2586e-02,  4.4216e-02, -2.6089e-03,  1.4180e-01,\n",
      "          -9.0915e-02,  1.8943e-01]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.2910686 ,  0.39317194,  0.72708964, -1.0345734 ,\n",
      "          1.4394786 ,  0.6780514 , -1.0045333 ,  2.246035...   1.5826572 ,  0.856692  , -0.4051015 , -0.33459187,\n",
      "         -0.03305938,  0.70455897, -0.86205953]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.2910686   0.39317194  0.72708964 -1.0345734   1.4394786\n",
      "    0.6780514  -1.0045333   2.246035    0...382558   0.89451206  1.5826572\n",
      "    0.856692   -0.4051015  -0.33459187 -0.03305938  0.70455897\n",
      "   -0.86205953]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471e03f70>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.2910686   0.39317194  0.72708964 -1.0345734   1.4394786\n",
      "    0.6780514  -1.0045333   2.246035    0....8  -1.8382558   0.89451206  1.5826572\n",
      "    0.856692   -0.4051015  -0.33459187 -0.03305938  0.70455897\n",
      "   -0.86205953]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471e03f70>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.2910686   0.39317194  0.72708964 -1.0345734   1.4394786   0.6780514\n",
      "  -1.0045333...14268  -1.8382558   0.89451206  1.5826572   0.856692\n",
      "  -0.4051015  -0.33459187 -0.03305938  0.70455897 -0.86205953]]),)\n",
      "        y          = needle.Tensor([[ 0.2910686   0.39317194  0.72708964 -1.0345734   1.4394786   0.6780514\n",
      "  -1.0045333   2.246035    0.09...2014268  -1.8382558   0.89451206  1.5826572   0.856692\n",
      "  -0.4051015  -0.33459187 -0.03305938  0.70455897 -0.86205953]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.2910686   0.39317194  0.72708964 -1.0345734   1.4394786   0.6780514\n",
      "  -1.0045333   2.246035    0.0...2558   0.89451206  1.5826572   0.856692\n",
      "  -0.4051015  -0.33459187 -0.03305938  0.70455897 -0.86205953]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471e03760>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.2910686   0.39317194  0.72708964 -1.0345734   1.4394786   0.6780514\n",
      "  -1.0045333   2.246035    0.09...2014268  -1.8382558   0.89451206  1.5826572   0.856692\n",
      "  -0.4051015  -0.33459187 -0.03305938  0.70455897 -0.86205953]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-4.75259006e-01  4.07691747e-01  2.73265988e-01  8.14027131e-01\n",
      "  -9.74770784e-01 -3.83171260e-01  1.5...01 -2.38699406e-01 -2.96356797e-01 -9.88796875e-02\n",
      "  -1.75553739e-01  4.63418901e-01  2.44763717e-01  5.23486078e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471e03760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 1.89348727e-01  4.27564383e-02 -9.63595062e-02  1.60389155e-01\n",
      "   1.69957876e-01  2.44156361e-01  2.5...01  1.84225053e-01 -7.16009438e-02 -1.54714152e-01\n",
      "  -2.25206167e-01  2.48987913e-01 -2.60090441e-01 -2.72738397e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 1.89348727e-01  4.27564383e-02 -9.63595062e-02  1.60389155e-01\n",
      "   1.69957876e-01  2.44156361e-01  2....4225053e-01 -7.16009438e-02 -1.54714152e-01\n",
      "  -2.25206167e-01  2.48987913e-01 -2.60090441e-01 -2.72738397e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471e03a60>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 1.89348727e-01  4.27564383e-02 -9.63595062e-02  1.60389155e-01\n",
      "   1.69957876e-01  2.44156361e-01  2....4225053e-01 -7.16009438e-02 -1.54714152e-01\n",
      "  -2.25206167e-01  2.48987913e-01 -2.60090441e-01 -2.72738397e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471e03a60>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471e031f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471e031f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471e03280>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471e03280>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-True-12-11-15-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 1.4859352 , -0.5800658 ,  0.47917202, -2.1892552 ,\n",
      "         -1.4268569 , -0.45987055, -1.1763611 , -0.075311...3498144,  1.4703357 ,  0.68200016,\n",
      "          0.5763278 ,  1.8040656 , -1.9142843 ,  0.27255777]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.5957,  0.0269,  0.2784,  0.2463, -0.2766, -0.4315,  0.4197,\n",
      "          -0.4686,  0.2931,  0.3054,  0.2222,...,  0.1790, -0.1277, -0.3361,\n",
      "           0.0509, -0.2162,  0.3195, -0.0310,  0.3648]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 9.22014117e-02,  7.44898438e-01,  9.62611496e-01,\n",
      "         -3.74034137e-01,  1.45311165e+00, -1.36272117e-01...,  6.65191948e-01,  9.47950423e-01,\n",
      "          3.15149873e-01, -6.94261074e-01,  3.03585261e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.3374,  0.0107,  0.1158,  0.1343, -0.0566, -0.2335,  0.1614,\n",
      "          -0.2072,  0.0822,  0.0775,  0.1455,...,  0.1123, -0.0629, -0.1310,\n",
      "           0.0343, -0.1137,  0.2127, -0.0116,  0.1485]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4717efb50>\n",
      "model_     = LSTM(11, 12)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-8.9417e-02,  1.2548e-01, -5.6236e-02,  ..., -2.1434e-01,\n",
      "           1.7578e-01, -3.0920e-01],\n",
      "         [ 1....7650e-01, -1.4874e-01, -1.3392e-01,  ...,  2.1273e-01,\n",
      "          -1.1574e-02,  1.4850e-01]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.49233747,  1.4074277 ,  1.184715  , ..., -1.1704122 ,\n",
      "          0.21885267, -0.8175253 ],\n",
      "        [ 0.1953...\n",
      "        [-0.645894  , -0.9915783 , -0.25779745, ..., -0.6261813 ,\n",
      "         -0.73774964,  0.84797746]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.49233747  1.4074277   1.184715   ... -1.1704122   0.21885267\n",
      "   -0.8175253 ]\n",
      "  [ 0.19538005 -0.06... 2.7417483\n",
      "   -0.43346688]\n",
      "  [-0.645894   -0.9915783  -0.25779745 ... -0.6261813  -0.73774964\n",
      "    0.84797746]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4717efb50>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.49233747  1.4074277   1.184715   ... -1.1704122   0.21885267\n",
      "   -0.8175253 ]\n",
      "  [ 0.19538005 -0.064...835204  2.7417483\n",
      "   -0.43346688]\n",
      "  [-0.645894   -0.9915783  -0.25779745 ... -0.6261813  -0.73774964\n",
      "    0.84797746]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4717efb50>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.49233747  1.4074277   1.184715    0.6812659   0.02566531 -0.49288654\n",
      "   0.786361...5783  -0.25779745  0.17056572  0.20553821  0.04458881\n",
      "  -0.77571476 -0.17805006 -0.6261813  -0.73774964  0.84797746]]))\n",
      "        y          = needle.Tensor([[-0.49233747  1.4074277   1.184715    0.6812659   0.02566531 -0.49288654\n",
      "   0.7863617  -1.6106474  -1.1...94648504  0.69895244 -0.3416764  -0.39312515 -1.644769\n",
      "   0.72188675 -0.12067698 -1.4863166  -0.8400012   0.02937369]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.49233747  1.4074277   1.184715    0.6812659   0.02566531 -0.49288654\n",
      "   0.7863617  -1.6106474  -1....95244 -0.3416764  -0.39312515 -1.644769\n",
      "   0.72188675 -0.12067698 -1.4863166  -0.8400012   0.02937369]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4717ef070>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.49233747  1.4074277   1.184715    0.6812659   0.02566531 -0.49288654\n",
      "   0.7863617  -1.6106474  -1.1...94648504  0.69895244 -0.3416764  -0.39312515 -1.644769\n",
      "   0.72188675 -0.12067698 -1.4863166  -0.8400012   0.02937369]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-5.95396399e-01 -5.46992481e-01 -3.50360610e-02 -1.41604142e-02\n",
      "   1.22757979e-01  6.20688736e-01 -2.9...01  5.14118552e-01  6.39010668e-01  7.60219276e-01\n",
      "   1.20502941e-01 -1.02588594e+00 -1.72017425e-01  8.08635414e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4717ef070>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.00978541  0.10958174  0.01369905 -0.1512496  -0.05703422 -0.15825236\n",
      "   0.17738274 -0.09814198  0.1...751445  0.08437842  0.19441009 -0.21706882\n",
      "  -0.03796843  0.13645965  0.13292688 -0.21190079 -0.12202671 -0.09286323]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.00978541  0.10958174  0.01369905 -0.1512496  -0.05703422 -0.15825236\n",
      "   0.17738274 -0.09814198  0.... 0.08437842  0.19441009 -0.21706882\n",
      "  -0.03796843  0.13645965  0.13292688 -0.21190079 -0.12202671 -0.09286323]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480da0f40>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.00978541  0.10958174  0.01369905 -0.1512496  -0.05703422 -0.15825236\n",
      "   0.17738274 -0.09814198  0.... 0.08437842  0.19441009 -0.21706882\n",
      "  -0.03796843  0.13645965  0.13292688 -0.21190079 -0.12202671 -0.09286323]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480da0f40>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480da0d60>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480da0d60>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480da0640>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480da0640>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-True-12-11-15-2-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[ 9.35739815e-01,  2.29528487e-01,  2.11208716e-01,\n",
      "         -2.24624425e-01,  8.00068378e-01,  6.58877552e-01..., -9.79568839e-01,  5.52507102e-01,\n",
      "         -8.57253075e-02, -3.46580327e-01,  4.74737406e-01]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-1.3972e-02, -2.2527e-03,  2.9610e-01,  3.1526e-02,  1.8009e-01,\n",
      "          -4.7218e-01,  6.7916e-02, -3.3444...2, -6.5704e-02, -1.3327e-02, -1.8857e-01, -9.0944e-02,\n",
      "          -6.4103e-02,  1.1478e-01]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-8.57684016e-02, -1.17234811e-01,  5.20249940e-02,\n",
      "         -1.68074584e+00, -1.40956318e+00, -4.49635059e-01...,  9.75182652e-02,  2.23898864e+00,\n",
      "         -1.62808025e+00, -6.22812748e-01, -4.40870285e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-9.6725e-03, -1.1678e-03,  5.5894e-02,  6.3412e-03,  1.4006e-01,\n",
      "          -2.7351e-01,  4.1206e-02, -2.0556...2, -3.1726e-02, -6.9992e-03, -8.6118e-02, -4.7352e-02,\n",
      "          -3.9731e-02,  5.8602e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb471280f70>\n",
      "model_     = LSTM(11, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.1383, -0.0436,  0.0047,  0.0016,  0.0546,  0.0280, -0.0345,\n",
      "           0.0394, -0.0615, -0.0512, -0.0118,...,  0.0733,  0.0270, -0.0317,\n",
      "          -0.0070, -0.0861, -0.0474, -0.0397,  0.0586]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.2037258 ,  0.98426443,  0.12441908,  1.4239472 ,\n",
      "         -1.671688  ,  2.6934845 ,  0.86025846, -0.628589...  -0.5185478 ,  1.8106613 , -0.24829517, -0.5088744 ,\n",
      "         -1.2739404 ,  0.6150747 ,  0.71464753]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.2037258   0.98426443  0.12441908  1.4239472  -1.671688\n",
      "    2.6934845   0.86025846 -0.62858987  0....3336494   0.6242552  -0.5185478\n",
      "    1.8106613  -0.24829517 -0.5088744  -1.2739404   0.6150747\n",
      "    0.71464753]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471280f70>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.2037258   0.98426443  0.12441908  1.4239472  -1.671688\n",
      "    2.6934845   0.86025846 -0.62858987  0.4...535  1.3336494   0.6242552  -0.5185478\n",
      "    1.8106613  -0.24829517 -0.5088744  -1.2739404   0.6150747\n",
      "    0.71464753]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471280f70>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.2037258   0.98426443  0.12441908  1.4239472  -1.671688    2.6934845\n",
      "   0.8602584...90535  1.3336494   0.6242552  -0.5185478   1.8106613\n",
      "  -0.24829517 -0.5088744  -1.2739404   0.6150747   0.71464753]]),)\n",
      "        y          = needle.Tensor([[-1.2037258   0.98426443  0.12441908  1.4239472  -1.671688    2.6934845\n",
      "   0.86025846 -0.62858987  0.42...2490535  1.3336494   0.6242552  -0.5185478   1.8106613\n",
      "  -0.24829517 -0.5088744  -1.2739404   0.6150747   0.71464753]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.2037258   0.98426443  0.12441908  1.4239472  -1.671688    2.6934845\n",
      "   0.86025846 -0.62858987  0.4...494   0.6242552  -0.5185478   1.8106613\n",
      "  -0.24829517 -0.5088744  -1.2739404   0.6150747   0.71464753]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471280940>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.2037258   0.98426443  0.12441908  1.4239472  -1.671688    2.6934845\n",
      "   0.86025846 -0.62858987  0.42...2490535  1.3336494   0.6242552  -0.5185478   1.8106613\n",
      "  -0.24829517 -0.5088744  -1.2739404   0.6150747   0.71464753]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 2.77572144e-02 -5.02439380e-01  6.95008636e-02 -3.57527792e-01\n",
      "  -8.03509653e-02 -1.65365472e-01 -7.2...01  5.19984722e-01 -5.03917001e-02  1.24596524e+00\n",
      "   5.34301758e-01  1.95195563e-02 -6.23569727e-01 -5.72425306e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471280940>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-1.80290774e-01 -2.08771914e-01 -1.60304815e-01 -2.86625296e-01\n",
      "   4.45128977e-02  1.51360184e-01  1.4...02 -1.38933048e-01 -3.78101468e-02 -2.29043528e-01\n",
      "  -1.65551856e-01 -1.83914810e-01  4.19215560e-02  5.69742322e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-1.80290774e-01 -2.08771914e-01 -1.60304815e-01 -2.86625296e-01\n",
      "   4.45128977e-02  1.51360184e-01  1....8933048e-01 -3.78101468e-02 -2.29043528e-01\n",
      "  -1.65551856e-01 -1.83914810e-01  4.19215560e-02  5.69742322e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471280b50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-1.80290774e-01 -2.08771914e-01 -1.60304815e-01 -2.86625296e-01\n",
      "   4.45128977e-02  1.51360184e-01  1....8933048e-01 -3.78101468e-02 -2.29043528e-01\n",
      "  -1.65551856e-01 -1.83914810e-01  4.19215560e-02  5.69742322e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471280b50>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471280e20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471280e20>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471280850>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471280850>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-True-12-11-15-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = True, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = True\n",
      "c0         = array([[[-3.29143256e-01, -4.06749696e-01,  8.95208418e-01,\n",
      "         -1.44147336e+00, -5.67654610e-01, -7.39296675e-01...,  1.30860162e+00, -5.69503844e-01,\n",
      "          8.10812771e-01, -5.94000995e-01,  9.54558849e-01]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 1.2345e-02,  4.0395e-01,  2.8331e-01, -1.3338e-01, -2.8099e-01,\n",
      "           2.6985e-01, -1.7849e-01,  2.8106...1, -2.1586e-01,  2.5451e-01,  1.5860e-01, -1.2276e-01,\n",
      "          -5.7152e-01, -8.5932e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-7.71757960e-02, -6.72866166e-01, -1.50633073e+00,\n",
      "          1.79243788e-01, -1.25280336e-01,  9.25695300e-01..., -1.14257097e+00,  1.00464426e-01,\n",
      "          1.43697774e+00, -1.97510207e+00,  1.38743770e+00]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 5.0272e-03,  2.2535e-01,  1.0294e-01, -6.2611e-02, -9.6181e-02,\n",
      "           1.4794e-01, -8.7911e-02,  9.1035...1, -1.1708e-01,  1.3192e-01,  8.6811e-02, -6.0100e-02,\n",
      "          -2.5830e-01, -3.7331e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb430100640>\n",
      "model_     = LSTM(11, 12, num_layers=2)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0459, -0.0010,  0.0565,  ..., -0.0280, -0.0923, -0.0124],\n",
      "         [ 0.0434, -0.0525,  0.0448,  ..., -0.0...30, -0.0710],\n",
      "         [ 0.0862, -0.0928,  0.0709,  ..., -0.0601, -0.2583, -0.0373]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.5429142 ,  1.3420632 , -0.11880984, ..., -0.02320482,\n",
      "          0.4462703 ,  0.90821373],\n",
      "        [-1.1883...\n",
      "        [-0.91565114, -0.9947156 ,  0.07699475, ..., -2.881459  ,\n",
      "          1.8540705 , -0.5949667 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.5429142   1.3420632  -0.11880984 ... -0.02320482  0.4462703\n",
      "    0.90821373]\n",
      "  [-1.1883243  -1.047... 0.27148187\n",
      "   -0.8291713 ]\n",
      "  [-0.91565114 -0.9947156   0.07699475 ... -2.881459    1.8540705\n",
      "   -0.5949667 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb430100640>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.5429142   1.3420632  -0.11880984 ... -0.02320482  0.4462703\n",
      "    0.90821373]\n",
      "  [-1.1883243  -1.0478...020056  0.27148187\n",
      "   -0.8291713 ]\n",
      "  [-0.91565114 -0.9947156   0.07699475 ... -2.881459    1.8540705\n",
      "   -0.5949667 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb430100640>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.5429142   1.3420632  -0.11880984  0.23617466  0.82093805 -0.3158635\n",
      "   1.8648239...   4.37291652e-01  6.48181975e-01  2.35850167e+00  8.13203633e-01\n",
      "  -2.88145900e+00  1.85407054e+00 -5.94966710e-01]]))\n",
      "        y          = needle.Tensor([[ 0.5429142   1.3420632  -0.11880984  0.23617466  0.82093805 -0.3158635\n",
      "   1.8648239   0.06236421 -0.02...74482   2.1863463   0.09535562  1.5851661   0.25253627\n",
      "  -0.8651339   0.4310768  -0.6120576   0.531494   -0.75108486]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.5429142   1.3420632  -0.11880984  0.23617466  0.82093805 -0.3158635\n",
      "   1.8648239   0.06236421 -0.0...63   0.09535562  1.5851661   0.25253627\n",
      "  -0.8651339   0.4310768  -0.6120576   0.531494   -0.75108486]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb430100910>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.5429142   1.3420632  -0.11880984  0.23617466  0.82093805 -0.3158635\n",
      "   1.8648239   0.06236421 -0.02...74482   2.1863463   0.09535562  1.5851661   0.25253627\n",
      "  -0.8651339   0.4310768  -0.6120576   0.531494   -0.75108486]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 6.51018739e-01 -6.19076312e-01  6.65580988e-01 -6.06219709e-01\n",
      "  -5.41141152e-01 -1.71236560e-01  2.4...01 -1.36406973e-01  5.21183908e-01  4.56002444e-01\n",
      "  -2.21838951e-01  3.60203534e-01 -2.87132144e-01  3.58454943e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb430100910>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.04939675 -0.24411994  0.02752557  0.09999302  0.13254625 -0.2685385\n",
      "   0.19807914 -0.14529517 -0.01...20368   0.072209   -0.08059929  0.22936016\n",
      "  -0.09211276  0.09910151  0.20921367 -0.11828466 -0.19827165 -0.27395463]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.04939675 -0.24411994  0.02752557  0.09999302  0.13254625 -0.2685385\n",
      "   0.19807914 -0.14529517 -0.0... 0.072209   -0.08059929  0.22936016\n",
      "  -0.09211276  0.09910151  0.20921367 -0.11828466 -0.19827165 -0.27395463]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb43837a8b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.04939675 -0.24411994  0.02752557  0.09999302  0.13254625 -0.2685385\n",
      "   0.19807914 -0.14529517 -0.0... 0.072209   -0.08059929  0.22936016\n",
      "  -0.09211276  0.09910151  0.20921367 -0.11828466 -0.19827165 -0.27395463]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb43837a8b0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb43837a820>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb43837a820>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb43837ab80>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb43837ab80>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-False-1-1-1-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[0.82524633]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0610]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[0.12415625]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0253]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb480edbd00>\n",
      "model_     = LSTM(1, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0253]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.55832297]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.55832297]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480edbd00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.55832297]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480edbd00>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.55832297]]),)\n",
      "        y          = needle.Tensor([[-0.55832297]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.55832297]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480edbe50>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.55832297]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.2943189   0.38219023 -0.1068102  -0.33836472]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480edbe50>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[0.981475   0.97913265 0.2611878  0.44932854]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[0.981475   0.97913265 0.2611878  0.44932854]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480edb6a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[0.981475   0.97913265 0.2611878  0.44932854]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480edb6a0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480edb5e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480edb5e0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480edba60>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480edba60>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-1-1-1-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.16255844]]], dtype=float32)\n",
      "c_         = tensor([[[0.0643]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.39224258]]], dtype=float32)\n",
      "h_         = tensor([[[0.0379]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4623a5b80>\n",
      "model_     = LSTM(1, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.1165]],\n",
      "\n",
      "        [[ 0.0298]],\n",
      "\n",
      "        [[-0.0765]],\n",
      "\n",
      "        [[-0.0768]],\n",
      "\n",
      "        [[-0.1200]],\n",
      "\n",
      "        ...1]],\n",
      "\n",
      "        [[-0.1120]],\n",
      "\n",
      "        [[-0.1056]],\n",
      "\n",
      "        [[-0.1329]],\n",
      "\n",
      "        [[ 0.0379]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.7058594 ]],\n",
      "\n",
      "       [[ 0.18958244]],\n",
      "\n",
      "       [[ 0.95831174]],\n",
      "\n",
      "       [[ 0.15488788]],\n",
      "\n",
      "       [[ 0.751885...]],\n",
      "\n",
      "       [[ 0.18601477]],\n",
      "\n",
      "       [[ 0.31296787]],\n",
      "\n",
      "       [[ 0.6680936 ]],\n",
      "\n",
      "       [[-0.73855156]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.7058594 ]]\n",
      "\n",
      " [[ 0.18958244]]\n",
      "\n",
      " [[ 0.95831174]]\n",
      "\n",
      " [[ 0.15488788]]\n",
      "\n",
      " [[ 0.7518857 ]]\n",
      "\n",
      " [[ 1.02432  ...]]\n",
      "\n",
      " [[ 0.45712742]]\n",
      "\n",
      " [[ 1.3391469 ]]\n",
      "\n",
      " [[ 0.18601477]]\n",
      "\n",
      " [[ 0.31296787]]\n",
      "\n",
      " [[ 0.6680936 ]]\n",
      "\n",
      " [[-0.73855156]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4623a5b80>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.7058594 ]]\n",
      "\n",
      " [[ 0.18958244]]\n",
      "\n",
      " [[ 0.95831174]]\n",
      "\n",
      " [[ 0.15488788]]\n",
      "\n",
      " [[ 0.7518857 ]]\n",
      "\n",
      " [[ 1.02432   ...085017 ]]\n",
      "\n",
      " [[ 0.45712742]]\n",
      "\n",
      " [[ 1.3391469 ]]\n",
      "\n",
      " [[ 0.18601477]]\n",
      "\n",
      " [[ 0.31296787]]\n",
      "\n",
      " [[ 0.6680936 ]]\n",
      "\n",
      " [[-0.73855156]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4623a5b80>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.7058594]]), needle.Tensor([[0.18958244]]), needle.Tensor([[0.95831174]]), needle...le.Tensor([[0.18601477]]), needle.Tensor([[0.31296787]]), needle.Tensor([[0.6680936]]), needle.Tensor([[-0.73855156]]))\n",
      "        y          = needle.Tensor([[-0.7058594]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.7058594]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4623a5eb0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.7058594]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.03003884 -0.58925307  0.41364318  0.38038495]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4623a5eb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.54769504 -0.3140254   0.22308469  0.2710836 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.54769504 -0.3140254   0.22308469  0.2710836 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480f340d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.54769504 -0.3140254   0.22308469  0.2710836 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480f340d0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480f34580>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480f34580>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480f34160>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480f34160>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m____________________ test_lstm[metal-False-False-1-1-1-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.29448938]],\n",
      "\n",
      "       [[-0.44692647]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0698]],\n",
      "\n",
      "        [[ 0.0085]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.69172037]],\n",
      "\n",
      "       [[-0.36443922]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0343]],\n",
      "\n",
      "        [[ 0.0043]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb481082970>\n",
      "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[0.0043]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[0.3011502]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[0.3011502]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb481082970>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[0.3011502]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb481082970>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.3011502]]),)\n",
      "        y          = needle.Tensor([[0.3011502]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.3011502]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb481082b20>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[0.3011502]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.29649532 -0.13518435 -0.16508046 -0.02745344]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb481082b20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.3640914  -0.93809295  0.6231134   0.9679388 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.3640914  -0.93809295  0.6231134   0.9679388 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb481082e20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.3640914  -0.93809295  0.6231134   0.9679388 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb481082e20>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb481082f70>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb481082f70>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4810820a0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4810820a0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-1-1-2-13] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[0.50061566]],\n",
      "\n",
      "       [[1.7258843 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0435]],\n",
      "\n",
      "        [[ 0.0113]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-1.5835804 ]],\n",
      "\n",
      "       [[-0.17180096]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0213]],\n",
      "\n",
      "        [[ 0.0056]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb48118fe20>\n",
      "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0374]],\n",
      "\n",
      "        [[ 0.0067]],\n",
      "\n",
      "        [[-0.0268]],\n",
      "\n",
      "        [[-0.0561]],\n",
      "\n",
      "        [[-0.0780]],\n",
      "\n",
      "        ...4]],\n",
      "\n",
      "        [[ 0.0398]],\n",
      "\n",
      "        [[ 0.0318]],\n",
      "\n",
      "        [[ 0.0172]],\n",
      "\n",
      "        [[ 0.0056]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.98611206]],\n",
      "\n",
      "       [[-0.81332856]],\n",
      "\n",
      "       [[-0.6365144 ]],\n",
      "\n",
      "       [[-0.7966985 ]],\n",
      "\n",
      "       [[-0.613032...]],\n",
      "\n",
      "       [[-0.08055211]],\n",
      "\n",
      "       [[ 0.07411978]],\n",
      "\n",
      "       [[-0.10836184]],\n",
      "\n",
      "       [[-0.08597963]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.98611206]]\n",
      "\n",
      " [[-0.81332856]]\n",
      "\n",
      " [[-0.6365144 ]]\n",
      "\n",
      " [[-0.7966985 ]]\n",
      "\n",
      " [[-0.6130323 ]]\n",
      "\n",
      " [[-0.4959995...]]\n",
      "\n",
      " [[ 1.3957847 ]]\n",
      "\n",
      " [[ 0.782034  ]]\n",
      "\n",
      " [[-0.08055211]]\n",
      "\n",
      " [[ 0.07411978]]\n",
      "\n",
      " [[-0.10836184]]\n",
      "\n",
      " [[-0.08597963]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48118fe20>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.98611206]]\n",
      "\n",
      " [[-0.81332856]]\n",
      "\n",
      " [[-0.6365144 ]]\n",
      "\n",
      " [[-0.7966985 ]]\n",
      "\n",
      " [[-0.6130323 ]]\n",
      "\n",
      " [[-0.49599954...027752 ]]\n",
      "\n",
      " [[ 1.3957847 ]]\n",
      "\n",
      " [[ 0.782034  ]]\n",
      "\n",
      " [[-0.08055211]]\n",
      "\n",
      " [[ 0.07411978]]\n",
      "\n",
      " [[-0.10836184]]\n",
      "\n",
      " [[-0.08597963]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb48118fe20>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.98611206]]), needle.Tensor([[-0.81332856]]), needle.Tensor([[-0.6365144]]), needl...Tensor([[-0.08055211]]), needle.Tensor([[0.07411978]]), needle.Tensor([[-0.10836184]]), needle.Tensor([[-0.08597963]]))\n",
      "        y          = needle.Tensor([[0.98611206]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.98611206]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb48118f790>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[0.98611206]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.30420858 -0.21621455  0.9363265   0.5248699 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb48118f790>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.70752287 -0.9324783  -0.07254124 -0.7406604 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.70752287 -0.9324783  -0.07254124 -0.7406604 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480e4e190>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.70752287 -0.9324783  -0.07254124 -0.7406604 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480e4e190>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480e4e7f0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480e4e7f0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480e4e340>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480e4e340>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-1-15-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-1.527309  ],\n",
      "        [ 0.20225157],\n",
      "        [ 0.50294983],\n",
      "        [-2.74399   ],\n",
      "        [-0.00279291],\n",
      "   ...3948263 ],\n",
      "        [-0.08959846],\n",
      "        [-0.8241842 ],\n",
      "        [ 0.47385213],\n",
      "        [ 0.5031587 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.6278],\n",
      "         [ 0.0332],\n",
      "         [ 0.2643],\n",
      "         [-0.1604],\n",
      "         [-0.1206],\n",
      "         [-0.4663]... [ 0.2437],\n",
      "         [ 0.1158],\n",
      "         [ 0.2644],\n",
      "         [ 0.2584],\n",
      "         [-0.0726]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.87914497],\n",
      "        [ 0.8178903 ],\n",
      "        [ 0.11492862],\n",
      "        [-0.38660967],\n",
      "        [-0.5084844 ],\n",
      "   ...54329306],\n",
      "        [-0.58290476],\n",
      "        [-0.81537616],\n",
      "        [-0.5134235 ],\n",
      "        [-0.14662401]]], dtype=float32)\n",
      "h_         = tensor([[[-0.4357],\n",
      "         [ 0.0161],\n",
      "         [ 0.0736],\n",
      "         [-0.0904],\n",
      "         [-0.0662],\n",
      "         [-0.3042]... [ 0.0800],\n",
      "         [ 0.0509],\n",
      "         [ 0.0734],\n",
      "         [ 0.0773],\n",
      "         [-0.0385]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb450ec3310>\n",
      "model_     = LSTM(1, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.4357],\n",
      "         [ 0.0161],\n",
      "         [ 0.0736],\n",
      "         [-0.0904],\n",
      "         [-0.0662],\n",
      "         [-0.3042]... [ 0.0800],\n",
      "         [ 0.0509],\n",
      "         [ 0.0734],\n",
      "         [ 0.0773],\n",
      "         [-0.0385]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 1.6222656 ],\n",
      "        [-0.07851445],\n",
      "        [-1.1644368 ],\n",
      "        [ 0.34900025],\n",
      "        [ 0.264608  ],\n",
      "   ...86938184],\n",
      "        [-0.2980601 ],\n",
      "        [-1.1679238 ],\n",
      "        [-1.0366    ],\n",
      "        [ 0.1617999 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.6222656 ]\n",
      "  [-0.07851445]\n",
      "  [-1.1644368 ]\n",
      "  [ 0.34900025]\n",
      "  [ 0.264608  ]\n",
      "  [ 1.065473  ]\n",
      "  [ 0.4...[ 0.38863808]\n",
      "  [-0.6192495 ]\n",
      "  [-0.86938184]\n",
      "  [-0.2980601 ]\n",
      "  [-1.1679238 ]\n",
      "  [-1.0366    ]\n",
      "  [ 0.1617999 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450ec3310>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 1.6222656 ]\n",
      "  [-0.07851445]\n",
      "  [-1.1644368 ]\n",
      "  [ 0.34900025]\n",
      "  [ 0.264608  ]\n",
      "  [ 1.065473  ]\n",
      "  [ 0.43...333]\n",
      "  [ 0.38863808]\n",
      "  [-0.6192495 ]\n",
      "  [-0.86938184]\n",
      "  [-0.2980601 ]\n",
      "  [-1.1679238 ]\n",
      "  [-1.0366    ]\n",
      "  [ 0.1617999 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450ec3310>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.6222656 ]\n",
      " [-0.07851445]\n",
      " [-1.1644368 ]\n",
      " [ 0.34900025]\n",
      " [ 0.264608  ]\n",
      " [ 1.06547....98310333]\n",
      " [ 0.38863808]\n",
      " [-0.6192495 ]\n",
      " [-0.86938184]\n",
      " [-0.2980601 ]\n",
      " [-1.1679238 ]\n",
      " [-1.0366    ]\n",
      " [ 0.1617999 ]]),)\n",
      "        y          = needle.Tensor([[ 1.6222656 ]\n",
      " [-0.07851445]\n",
      " [-1.1644368 ]\n",
      " [ 0.34900025]\n",
      " [ 0.264608  ]\n",
      " [ 1.065473  ]\n",
      " [ 0.43459323]\n",
      " [ 0.98310333]\n",
      " [ 0.38863808]\n",
      " [-0.6192495 ]\n",
      " [-0.86938184]\n",
      " [-0.2980601 ]\n",
      " [-1.1679238 ]\n",
      " [-1.0366    ]\n",
      " [ 0.1617999 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.6222656 ]\n",
      " [-0.07851445]\n",
      " [-1.1644368 ]\n",
      " [ 0.34900025]\n",
      " [ 0.264608  ]\n",
      " [ 1.065473  ]\n",
      " [ 0.43459323... 0.38863808]\n",
      " [-0.6192495 ]\n",
      " [-0.86938184]\n",
      " [-0.2980601 ]\n",
      " [-1.1679238 ]\n",
      " [-1.0366    ]\n",
      " [ 0.1617999 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450ec3af0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 1.6222656 ]\n",
      " [-0.07851445]\n",
      " [-1.1644368 ]\n",
      " [ 0.34900025]\n",
      " [ 0.264608  ]\n",
      " [ 1.065473  ]\n",
      " [ 0.43459323]\n",
      " [ 0.98310333]\n",
      " [ 0.38863808]\n",
      " [-0.6192495 ]\n",
      " [-0.86938184]\n",
      " [-0.2980601 ]\n",
      " [-1.1679238 ]\n",
      " [-1.0366    ]\n",
      " [ 0.1617999 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.8887979   1.5656598  -1.4024843   1.2826691 ]\n",
      " [-0.04301606 -0.07577484  0.06787746 -0.06207865]\n",
      " [...8  -0.9234368 ]\n",
      " [-0.56792665 -1.0004299   0.89616346 -0.8196036 ]\n",
      " [ 0.08864602  0.1561542  -0.13987957  0.12792955]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450ec3af0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.8717115 -0.6738373 -0.9426818 -0.7213228]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.8717115 -0.6738373 -0.9426818 -0.7213228]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450ec32e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.8717115 -0.6738373 -0.9426818 -0.7213228]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450ec32e0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ec39a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ec39a0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb450ec3700>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb450ec3700>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-1-15-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-2.326215  ],\n",
      "        [ 0.60749245],\n",
      "        [ 0.84784204],\n",
      "        [-0.49578357],\n",
      "        [ 0.4431236 ],\n",
      "   ...1259034 ],\n",
      "        [-1.5694079 ],\n",
      "        [ 0.54780316],\n",
      "        [ 1.7889758 ],\n",
      "        [-0.29897323]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.0771],\n",
      "         [ 0.3983],\n",
      "         [ 0.0108],\n",
      "         [-0.1342],\n",
      "         [-0.0683],\n",
      "         [-0.0734]... [-0.0857],\n",
      "         [ 0.4628],\n",
      "         [-0.1362],\n",
      "         [-0.0527],\n",
      "         [-0.0681]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.64663327],\n",
      "        [-1.4330024 ],\n",
      "        [-0.31390435],\n",
      "        [ 2.0996072 ],\n",
      "        [-0.74211705],\n",
      "   ...2182295 ],\n",
      "        [-1.1553411 ],\n",
      "        [ 0.7562495 ],\n",
      "        [-1.5575523 ],\n",
      "        [-1.0711074 ]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.0379],\n",
      "         [ 0.2509],\n",
      "         [ 0.0065],\n",
      "         [-0.0717],\n",
      "         [-0.0436],\n",
      "         [-0.0358]... [-0.0363],\n",
      "         [ 0.2716],\n",
      "         [-0.0583],\n",
      "         [-0.0277],\n",
      "         [-0.0324]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4383bdb50>\n",
      "model_     = LSTM(1, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0075],\n",
      "         [ 0.0074],\n",
      "         [-0.0711],\n",
      "         [-0.0657],\n",
      "         [-0.0504],\n",
      "         [ 0.0296]... [-0.0363],\n",
      "         [ 0.2716],\n",
      "         [-0.0583],\n",
      "         [-0.0277],\n",
      "         [-0.0324]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.07115776],\n",
      "        [ 0.06797612],\n",
      "        [-0.88855916],\n",
      "        [-0.78701526],\n",
      "        [-0.55216604],\n",
      "   ...5990853 ],\n",
      "        [ 1.0615735 ],\n",
      "        [-0.5590588 ],\n",
      "        [ 0.20032418],\n",
      "        [-0.19672583]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.07115776]\n",
      "  [ 0.06797612]\n",
      "  [-0.88855916]\n",
      "  [-0.78701526]\n",
      "  [-0.55216604]\n",
      "  [ 0.26017073]\n",
      "  [ 0.8...[ 1.0277464 ]\n",
      "  [-1.602205  ]\n",
      "  [-0.5990853 ]\n",
      "  [ 1.0615735 ]\n",
      "  [-0.5590588 ]\n",
      "  [ 0.20032418]\n",
      "  [-0.19672583]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4383bdb50>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.07115776]\n",
      "  [ 0.06797612]\n",
      "  [-0.88855916]\n",
      "  [-0.78701526]\n",
      "  [-0.55216604]\n",
      "  [ 0.26017073]\n",
      "  [ 0.80...06 ]\n",
      "  [ 1.0277464 ]\n",
      "  [-1.602205  ]\n",
      "  [-0.5990853 ]\n",
      "  [ 1.0615735 ]\n",
      "  [-0.5590588 ]\n",
      "  [ 0.20032418]\n",
      "  [-0.19672583]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4383bdb50>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.07115776]\n",
      " [ 0.06797612]\n",
      " [-0.88855916]\n",
      " [-0.78701526]\n",
      " [-0.55216604]\n",
      " [ 0.26017...1.6754706 ]\n",
      " [ 1.0277464 ]\n",
      " [-1.602205  ]\n",
      " [-0.5990853 ]\n",
      " [ 1.0615735 ]\n",
      " [-0.5590588 ]\n",
      " [ 0.20032418]\n",
      " [-0.19672583]]))\n",
      "        y          = needle.Tensor([[-0.07115776]\n",
      " [ 0.06797612]\n",
      " [-0.88855916]\n",
      " [-0.78701526]\n",
      " [-0.55216604]\n",
      " [ 0.26017073]\n",
      " [ 0.8038528 ]\n",
      " [ 0.14513333]\n",
      " [-2.0793855 ]\n",
      " [-0.13174799]\n",
      " [ 1.3316561 ]\n",
      " [-0.27833596]\n",
      " [ 0.42732376]\n",
      " [-0.1451865 ]\n",
      " [-1.6917167 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.07115776]\n",
      " [ 0.06797612]\n",
      " [-0.88855916]\n",
      " [-0.78701526]\n",
      " [-0.55216604]\n",
      " [ 0.26017073]\n",
      " [ 0.8038528 ...-2.0793855 ]\n",
      " [-0.13174799]\n",
      " [ 1.3316561 ]\n",
      " [-0.27833596]\n",
      " [ 0.42732376]\n",
      " [-0.1451865 ]\n",
      " [-1.6917167 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4383bd2e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.07115776]\n",
      " [ 0.06797612]\n",
      " [-0.88855916]\n",
      " [-0.78701526]\n",
      " [-0.55216604]\n",
      " [ 0.26017073]\n",
      " [ 0.8038528 ]\n",
      " [ 0.14513333]\n",
      " [-2.0793855 ]\n",
      " [-0.13174799]\n",
      " [ 1.3316561 ]\n",
      " [-0.27833596]\n",
      " [ 0.42732376]\n",
      " [-0.1451865 ]\n",
      " [-1.6917167 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.6829864e-03 -6.6760384e-02 -3.0623155e-02 -3.5772134e-02]\n",
      " [-1.6077360e-03  6.3775361e-02  2.925391...8757e-03 -1.3621432e-01 -6.2481850e-02 -7.2987549e-02]\n",
      " [ 4.0011603e-02 -1.5871726e+00 -7.2804004e-01 -8.5045272e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4383bd2e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.07660973  0.60031295  0.6450347  -0.07234061]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.07660973  0.60031295  0.6450347  -0.07234061]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4383bdb80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.07660973  0.60031295  0.6450347  -0.07234061]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4383bdb80>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4383bdd00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4383bdd00>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4383bd970>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4383bd970>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-1-15-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 2.0859497 ],\n",
      "        [ 0.1839023 ],\n",
      "        [-0.5208063 ],\n",
      "        [-0.44237494],\n",
      "        [ 0.8891517 ],\n",
      "   ...3268857 ],\n",
      "        [ 2.1644423 ],\n",
      "        [-0.76748085],\n",
      "        [ 0.06295079],\n",
      "        [ 0.46936607]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.4837],\n",
      "         [ 0.0961],\n",
      "         [-0.1982],\n",
      "         [ 0.7574],\n",
      "         [-0.2044],\n",
      "         [ 0.1811]... [-0.0507],\n",
      "         [ 0.0495],\n",
      "         [ 0.0339],\n",
      "         [ 0.0557],\n",
      "         [ 0.0510]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.55693835],\n",
      "        [-0.03376976],\n",
      "        [-0.68325156],\n",
      "        [ 0.15810773],\n",
      "        [-0.6331569 ],\n",
      "   ...067608  ],\n",
      "        [ 0.8325342 ],\n",
      "        [-0.67867255],\n",
      "        [ 0.36589122],\n",
      "        [ 0.48378116]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.1443],\n",
      "         [ 0.0441],\n",
      "         [-0.1267],\n",
      "         [ 0.1293],\n",
      "         [-0.1403],\n",
      "         [ 0.0769]... [-0.0259],\n",
      "         [ 0.0242],\n",
      "         [ 0.0167],\n",
      "         [ 0.0272],\n",
      "         [ 0.0249]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb450cb0df0>\n",
      "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0272],\n",
      "         [ 0.0083],\n",
      "         [-0.0233],\n",
      "         [ 0.0244],\n",
      "         [-0.0258],\n",
      "         [ 0.0145]... [-0.0259],\n",
      "         [ 0.0242],\n",
      "         [ 0.0167],\n",
      "         [ 0.0272],\n",
      "         [ 0.0249]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 0.9212214 ],\n",
      "        [ 0.19416362],\n",
      "        [-0.74973994],\n",
      "        [ 1.690705  ],\n",
      "        [-1.0202076 ],\n",
      "   ...0736829 ],\n",
      "        [ 0.6960623 ],\n",
      "        [ 2.3894277 ],\n",
      "        [ 0.9138896 ],\n",
      "        [ 1.6374862 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.9212214 ]\n",
      "  [ 0.19416362]\n",
      "  [-0.74973994]\n",
      "  [ 1.690705  ]\n",
      "  [-1.0202076 ]\n",
      "  [ 0.35130417]\n",
      "  [ 2.1...[-0.17716685]\n",
      "  [ 3.7428465 ]\n",
      "  [-1.0736829 ]\n",
      "  [ 0.6960623 ]\n",
      "  [ 2.3894277 ]\n",
      "  [ 0.9138896 ]\n",
      "  [ 1.6374862 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450cb0df0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 0.9212214 ]\n",
      "  [ 0.19416362]\n",
      "  [-0.74973994]\n",
      "  [ 1.690705  ]\n",
      "  [-1.0202076 ]\n",
      "  [ 0.35130417]\n",
      "  [ 2.19...508]\n",
      "  [-0.17716685]\n",
      "  [ 3.7428465 ]\n",
      "  [-1.0736829 ]\n",
      "  [ 0.6960623 ]\n",
      "  [ 2.3894277 ]\n",
      "  [ 0.9138896 ]\n",
      "  [ 1.6374862 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450cb0df0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.9212214 ]\n",
      " [ 0.19416362]\n",
      " [-0.74973994]\n",
      " [ 1.690705  ]\n",
      " [-1.0202076 ]\n",
      " [ 0.35130....08135508]\n",
      " [-0.17716685]\n",
      " [ 3.7428465 ]\n",
      " [-1.0736829 ]\n",
      " [ 0.6960623 ]\n",
      " [ 2.3894277 ]\n",
      " [ 0.9138896 ]\n",
      " [ 1.6374862 ]]),)\n",
      "        y          = needle.Tensor([[ 0.9212214 ]\n",
      " [ 0.19416362]\n",
      " [-0.74973994]\n",
      " [ 1.690705  ]\n",
      " [-1.0202076 ]\n",
      " [ 0.35130417]\n",
      " [ 2.1963854 ]\n",
      " [-0.08135508]\n",
      " [-0.17716685]\n",
      " [ 3.7428465 ]\n",
      " [-1.0736829 ]\n",
      " [ 0.6960623 ]\n",
      " [ 2.3894277 ]\n",
      " [ 0.9138896 ]\n",
      " [ 1.6374862 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.9212214 ]\n",
      " [ 0.19416362]\n",
      " [-0.74973994]\n",
      " [ 1.690705  ]\n",
      " [-1.0202076 ]\n",
      " [ 0.35130417]\n",
      " [ 2.1963854 ...-0.17716685]\n",
      " [ 3.7428465 ]\n",
      " [-1.0736829 ]\n",
      " [ 0.6960623 ]\n",
      " [ 2.3894277 ]\n",
      " [ 0.9138896 ]\n",
      " [ 1.6374862 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450cb03a0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.9212214 ]\n",
      " [ 0.19416362]\n",
      " [-0.74973994]\n",
      " [ 1.690705  ]\n",
      " [-1.0202076 ]\n",
      " [ 0.35130417]\n",
      " [ 2.1963854 ]\n",
      " [-0.08135508]\n",
      " [-0.17716685]\n",
      " [ 3.7428465 ]\n",
      " [-1.0736829 ]\n",
      " [ 0.6960623 ]\n",
      " [ 2.3894277 ]\n",
      " [ 0.9138896 ]\n",
      " [ 1.6374862 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.85862976 -0.14992824  0.845379   -0.748088  ]\n",
      " [ 0.18097134 -0.03160001  0.1781785  -0.15767272]\n",
      " [...6  -1.9403611 ]\n",
      " [ 0.8517961  -0.14873499  0.8386508  -0.74213415]\n",
      " [ 1.5262285  -0.2664999   1.5026752  -1.3297389 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450cb03a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.8126545  -0.8550736  -0.04930043 -0.6585487 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.8126545  -0.8550736  -0.04930043 -0.6585487 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450cb0a30>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.8126545  -0.8550736  -0.04930043 -0.6585487 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450cb0a30>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb47201ad90>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb47201ad90>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb47201a910>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb47201a910>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-1-15-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-0.59031606],\n",
      "        [ 0.05093348],\n",
      "        [ 0.04834417],\n",
      "        [-0.27705377],\n",
      "        [-1.5271273 ],\n",
      "   ...0825653 ],\n",
      "        [ 0.5783873 ],\n",
      "        [ 0.3522647 ],\n",
      "        [ 0.25001603],\n",
      "        [ 0.24177454]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0683],\n",
      "         [ 0.2585],\n",
      "         [-0.1082],\n",
      "         [-0.0788],\n",
      "         [ 0.2066],\n",
      "         [-0.0479]... [-0.2877],\n",
      "         [-0.2029],\n",
      "         [-0.1048],\n",
      "         [-0.0340],\n",
      "         [-0.1366]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.19010232],\n",
      "        [ 1.0082887 ],\n",
      "        [-0.65677136],\n",
      "        [-0.58575   ],\n",
      "        [-0.44009107],\n",
      "   ...185905  ],\n",
      "        [ 0.2911007 ],\n",
      "        [-1.2104919 ],\n",
      "        [-1.3401862 ],\n",
      "        [ 1.0759823 ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0242],\n",
      "         [ 0.1306],\n",
      "         [-0.0452],\n",
      "         [-0.0174],\n",
      "         [ 0.1205],\n",
      "         [-0.0078]... [-0.1423],\n",
      "         [-0.1055],\n",
      "         [-0.0527],\n",
      "         [-0.0169],\n",
      "         [-0.0670]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb458caadc0>\n",
      "model_     = LSTM(1, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 2.4836e-03],\n",
      "         [ 3.1234e-03],\n",
      "         [-3.1543e-02],\n",
      "         [-2.8494e-02],\n",
      "         [ 3.5544e-03]...     [-1.0547e-01],\n",
      "         [-5.2658e-02],\n",
      "         [-1.6857e-02],\n",
      "         [-6.7036e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 2.0633981 ],\n",
      "        [ 0.3093614 ],\n",
      "        [-1.183282  ],\n",
      "        [-1.1022823 ],\n",
      "        [ 1.645262  ],\n",
      "   ...27084994],\n",
      "        [-0.6705151 ],\n",
      "        [ 0.20195572],\n",
      "        [ 0.9355409 ],\n",
      "        [ 0.77042913]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 2.0633981 ]\n",
      "  [ 0.3093614 ]\n",
      "  [-1.183282  ]\n",
      "  [-1.1022823 ]\n",
      "  [ 1.645262  ]\n",
      "  [ 0.51365745]\n",
      "  [ 0.5...[-0.42480406]\n",
      "  [-1.5182827 ]\n",
      "  [ 0.27084994]\n",
      "  [-0.6705151 ]\n",
      "  [ 0.20195572]\n",
      "  [ 0.9355409 ]\n",
      "  [ 0.77042913]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458caadc0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 2.0633981 ]\n",
      "  [ 0.3093614 ]\n",
      "  [-1.183282  ]\n",
      "  [-1.1022823 ]\n",
      "  [ 1.645262  ]\n",
      "  [ 0.51365745]\n",
      "  [ 0.56...234]\n",
      "  [-0.42480406]\n",
      "  [-1.5182827 ]\n",
      "  [ 0.27084994]\n",
      "  [-0.6705151 ]\n",
      "  [ 0.20195572]\n",
      "  [ 0.9355409 ]\n",
      "  [ 0.77042913]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458caadc0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 2.0633981 ]\n",
      " [ 0.3093614 ]\n",
      " [-1.183282  ]\n",
      " [-1.1022823 ]\n",
      " [ 1.645262  ]\n",
      " [ 0.51365...0.15443234]\n",
      " [-0.42480406]\n",
      " [-1.5182827 ]\n",
      " [ 0.27084994]\n",
      " [-0.6705151 ]\n",
      " [ 0.20195572]\n",
      " [ 0.9355409 ]\n",
      " [ 0.77042913]]))\n",
      "        y          = needle.Tensor([[ 2.0633981 ]\n",
      " [ 0.3093614 ]\n",
      " [-1.183282  ]\n",
      " [-1.1022823 ]\n",
      " [ 1.645262  ]\n",
      " [ 0.51365745]\n",
      " [ 0.56680685]\n",
      " [-1.3094467 ]\n",
      " [-0.1195645 ]\n",
      " [ 0.5676951 ]\n",
      " [ 1.9607521 ]\n",
      " [-0.13236582]\n",
      " [-0.5839694 ]\n",
      " [ 1.0369049 ]\n",
      " [ 0.39193243]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 2.0633981 ]\n",
      " [ 0.3093614 ]\n",
      " [-1.183282  ]\n",
      " [-1.1022823 ]\n",
      " [ 1.645262  ]\n",
      " [ 0.51365745]\n",
      " [ 0.56680685...-0.1195645 ]\n",
      " [ 0.5676951 ]\n",
      " [ 1.9607521 ]\n",
      " [-0.13236582]\n",
      " [-0.5839694 ]\n",
      " [ 1.0369049 ]\n",
      " [ 0.39193243]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458caad00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 2.0633981 ]\n",
      " [ 0.3093614 ]\n",
      " [-1.183282  ]\n",
      " [-1.1022823 ]\n",
      " [ 1.645262  ]\n",
      " [ 0.51365745]\n",
      " [ 0.56680685]\n",
      " [-1.3094467 ]\n",
      " [-0.1195645 ]\n",
      " [ 0.5676951 ]\n",
      " [ 1.9607521 ]\n",
      " [-0.13236582]\n",
      " [-0.5839694 ]\n",
      " [ 1.0369049 ]\n",
      " [ 0.39193243]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.007146   -1.6032846  -0.63646567 -1.2751012 ]\n",
      " [-0.3009276  -0.24037744 -0.0954241  -0.19117351]\n",
      " [...35  0.36087078]\n",
      " [-1.0086368  -0.8056873  -0.3198386  -0.6407676 ]\n",
      " [-0.38124758 -0.3045361  -0.12089356 -0.24219926]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458caad00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.02725649 -0.39177096  0.3363583   0.4677968 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.02725649 -0.39177096  0.3363583   0.4677968 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4620dc520>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.02725649 -0.39177096  0.3363583   0.4677968 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4620dc520>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4620dc9d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4620dc9d0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4620dcdf0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4620dcdf0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-11-1-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[0.47179335]]], dtype=float32)\n",
      "c_         = tensor([[[-0.0841]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[0.17225404]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0726]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb450ad1910>\n",
      "model_     = LSTM(11, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0726]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 1.0562351 ,  0.6963302 ,  0.3863077 , -0.65421015,\n",
      "         -0.551753  , -0.7508894 , -0.17814277,  0.66461223,\n",
      "         -0.7964518 ,  0.5986673 ,  0.32144883]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.0562351   0.6963302   0.3863077  -0.65421015 -0.551753\n",
      "   -0.7508894  -0.17814277  0.66461223 -0.7964518   0.5986673\n",
      "    0.32144883]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450ad1910>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 1.0562351   0.6963302   0.3863077  -0.65421015 -0.551753\n",
      "   -0.7508894  -0.17814277  0.66461223 -0.7964518   0.5986673\n",
      "    0.32144883]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450ad1910>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.0562351   0.6963302   0.3863077  -0.65421015 -0.551753   -0.7508894\n",
      "  -0.17814277  0.66461223 -0.7964518   0.5986673   0.32144883]]),)\n",
      "        y          = needle.Tensor([[ 1.0562351   0.6963302   0.3863077  -0.65421015 -0.551753   -0.7508894\n",
      "  -0.17814277  0.66461223 -0.7964518   0.5986673   0.32144883]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.0562351   0.6963302   0.3863077  -0.65421015 -0.551753   -0.7508894\n",
      "  -0.17814277  0.66461223 -0.7964518   0.5986673   0.32144883]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450ad1c70>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 1.0562351   0.6963302   0.3863077  -0.65421015 -0.551753   -0.7508894\n",
      "  -0.17814277  0.66461223 -0.7964518   0.5986673   0.32144883]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.10909113 -0.17634608 -0.17978214  1.8617661 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450ad1c70>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.42936003 -0.08707392  0.35329056 -0.36104918]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.42936003 -0.08707392  0.35329056 -0.36104918]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450ad12b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.42936003 -0.08707392  0.35329056 -0.36104918]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450ad12b0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ad19d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450ad19d0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb450ad1370>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb450ad1370>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-11-1-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[0.47418958]]], dtype=float32)\n",
      "c_         = tensor([[[0.0246]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[0.24377058]]], dtype=float32)\n",
      "h_         = tensor([[[0.0005]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb461d9b820>\n",
      "model_     = LSTM(11, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.0084]],\n",
      "\n",
      "        [[ 0.2173]],\n",
      "\n",
      "        [[ 0.0020]],\n",
      "\n",
      "        [[ 0.0139]],\n",
      "\n",
      "        [[-0.0910]],\n",
      "\n",
      "        ...1]],\n",
      "\n",
      "        [[-0.1610]],\n",
      "\n",
      "        [[ 0.1094]],\n",
      "\n",
      "        [[ 0.2920]],\n",
      "\n",
      "        [[ 0.0005]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-5.24530888e-01,  2.46812892e+00,  5.15685916e-01,\n",
      "         -6.28296256e-01, -1.93318975e+00, -4.13589269e-01...         4.60605025e-01, -4.02977364e-03,  7.66998351e-01,\n",
      "         -3.32228571e-01,  1.29842484e+00]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-5.24530888e-01  2.46812892e+00  5.15685916e-01 -6.28296256e-01\n",
      "   -1.93318975e+00 -4.13589269e-01  ...07897e-01 -1.33529139e+00  4.60605025e-01 -4.02977364e-03\n",
      "    7.66998351e-01 -3.32228571e-01  1.29842484e+00]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461d9b820>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-5.24530888e-01  2.46812892e+00  5.15685916e-01 -6.28296256e-01\n",
      "   -1.93318975e+00 -4.13589269e-01  1...  2.93107897e-01 -1.33529139e+00  4.60605025e-01 -4.02977364e-03\n",
      "    7.66998351e-01 -3.32228571e-01  1.29842484e+00]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461d9b820>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.5245309   2.468129    0.5156859  -0.62829626 -1.9331897  -0.41358927\n",
      "   1.253434...6706    1.7703673  -0.5986758   0.2931079  -1.3352914\n",
      "   0.46060503 -0.00402977  0.76699835 -0.33222857  1.2984248 ]]))\n",
      "        y          = needle.Tensor([[-0.5245309   2.468129    0.5156859  -0.62829626 -1.9331897  -0.41358927\n",
      "   1.2534342   1.4446738  -1.1040597  -0.736301   -0.02785596]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.5245309   2.468129    0.5156859  -0.62829626 -1.9331897  -0.41358927\n",
      "   1.2534342   1.4446738  -1.1040597  -0.736301   -0.02785596]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461d9b100>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.5245309   2.468129    0.5156859  -0.62829626 -1.9331897  -0.41358927\n",
      "   1.2534342   1.4446738  -1.1040597  -0.736301   -0.02785596]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.2647493  1.3180778  0.5357687 -2.466922 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461d9b100>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.5831096  -0.41596746 -0.86149967  0.13873494]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.5831096  -0.41596746 -0.86149967  0.13873494]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb43847da00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.5831096  -0.41596746 -0.86149967  0.13873494]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb43847da00>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb43847dd60>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb43847dd60>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb43847dca0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb43847dca0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-11-1-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 1\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.5374314]],\n",
      "\n",
      "       [[ 1.6644154]]], dtype=float32)\n",
      "c_         = tensor([[[0.2411]],\n",
      "\n",
      "        [[0.0371]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[0.9814182]],\n",
      "\n",
      "       [[1.5335253]]], dtype=float32)\n",
      "h_         = tensor([[[0.0846]],\n",
      "\n",
      "        [[0.0193]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4617315e0>\n",
      "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[0.0193]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.7307609 ,  0.7498096 ,  0.3355134 ,  0.12162946,\n",
      "          1.7520779 , -0.20269142, -0.19761167, -0.3088488 ,\n",
      "         -0.65422624, -0.28638548,  0.4017406 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.7307609   0.7498096   0.3355134   0.12162946  1.7520779\n",
      "   -0.20269142 -0.19761167 -0.3088488  -0.65422624 -0.28638548\n",
      "    0.4017406 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617315e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.7307609   0.7498096   0.3355134   0.12162946  1.7520779\n",
      "   -0.20269142 -0.19761167 -0.3088488  -0.65422624 -0.28638548\n",
      "    0.4017406 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617315e0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.7307609   0.7498096   0.3355134   0.12162946  1.7520779  -0.20269142\n",
      "  -0.19761167 -0.3088488  -0.65422624 -0.28638548  0.4017406 ]]),)\n",
      "        y          = needle.Tensor([[-0.7307609   0.7498096   0.3355134   0.12162946  1.7520779  -0.20269142\n",
      "  -0.19761167 -0.3088488  -0.65422624 -0.28638548  0.4017406 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.7307609   0.7498096   0.3355134   0.12162946  1.7520779  -0.20269142\n",
      "  -0.19761167 -0.3088488  -0.65422624 -0.28638548  0.4017406 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461731b80>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.7307609   0.7498096   0.3355134   0.12162946  1.7520779  -0.20269142\n",
      "  -0.19761167 -0.3088488  -0.65422624 -0.28638548  0.4017406 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.09673705 -1.7910501   0.49731624 -0.58499706]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461731b80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.84702134  0.677572    0.19379294  0.17479002]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.84702134  0.677572    0.19379294  0.17479002]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461731eb0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.84702134  0.677572    0.19379294  0.17479002]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461731eb0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461731100>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461731100>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461731d00>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461731d00>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-11-1-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.9923225 ]],\n",
      "\n",
      "       [[-0.61458176]]], dtype=float32)\n",
      "c_         = tensor([[[-0.3042]],\n",
      "\n",
      "        [[ 0.0389]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-1.5771335]],\n",
      "\n",
      "       [[ 0.7366443]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0034]],\n",
      "\n",
      "        [[ 0.0196]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb458a7fca0>\n",
      "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.1777]],\n",
      "\n",
      "        [[-0.0170]],\n",
      "\n",
      "        [[-0.0020]],\n",
      "\n",
      "        [[ 0.0908]],\n",
      "\n",
      "        [[ 0.0636]],\n",
      "\n",
      "        ...9]],\n",
      "\n",
      "        [[-0.0103]],\n",
      "\n",
      "        [[-0.0215]],\n",
      "\n",
      "        [[ 0.0305]],\n",
      "\n",
      "        [[ 0.0196]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.6680004 ,  1.8340262 ,  0.30829552,  1.1768569 ,\n",
      "          1.1741086 ,  0.65237695,  1.0231866 ,  0.779834...   1.6202048 , -0.5903333 , -2.0166817 , -0.75858474,\n",
      "          1.0003948 , -1.0099531 ,  2.003737  ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.6680004   1.8340262   0.30829552  1.1768569   1.1741086\n",
      "    0.65237695  1.0231866   0.7798348  -0...2946807   1.0743495   1.6202048\n",
      "   -0.5903333  -2.0166817  -0.75858474  1.0003948  -1.0099531\n",
      "    2.003737  ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458a7fca0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.6680004   1.8340262   0.30829552  1.1768569   1.1741086\n",
      "    0.65237695  1.0231866   0.7798348  -0....4    0.2946807   1.0743495   1.6202048\n",
      "   -0.5903333  -2.0166817  -0.75858474  1.0003948  -1.0099531\n",
      "    2.003737  ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458a7fca0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.6680004   1.8340262   0.30829552  1.1768569   1.1741086   0.65237695\n",
      "   1.023186...4864    0.2946807   1.0743495   1.6202048  -0.5903333\n",
      "  -2.0166817  -0.75858474  1.0003948  -1.0099531   2.003737  ]]))\n",
      "        y          = needle.Tensor([[-0.6680004   1.8340262   0.30829552  1.1768569   1.1741086   0.65237695\n",
      "   1.0231866   0.7798348  -0.4895777   0.54280776  0.32707164]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.6680004   1.8340262   0.30829552  1.1768569   1.1741086   0.65237695\n",
      "   1.0231866   0.7798348  -0.4895777   0.54280776  0.32707164]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb438385970>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-0.6680004   1.8340262   0.30829552  1.1768569   1.1741086   0.65237695\n",
      "   1.0231866   0.7798348  -0.4895777   0.54280776  0.32707164]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 4.013755   -0.45474184  1.8042828   3.782056  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb438385970>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.2745608   0.5272553  -0.01440251 -0.9819604 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.2745608   0.5272553  -0.01440251 -0.9819604 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb47137f790>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.2745608   0.5272553  -0.01440251 -0.9819604 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb47137f790>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb47137fb20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb47137fb20>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb47137fb50>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb47137fb50>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-11-15-1-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-0.6601416 ],\n",
      "        [ 0.19858176],\n",
      "        [ 1.7424306 ],\n",
      "        [ 0.549624  ],\n",
      "        [-0.08996557],\n",
      "   ...0068215 ],\n",
      "        [-0.69835496],\n",
      "        [-1.4851823 ],\n",
      "        [-0.434824  ],\n",
      "        [-0.9312925 ]]], dtype=float32)\n",
      "c_         = tensor([[[-0.3470],\n",
      "         [-0.3046],\n",
      "         [ 0.8166],\n",
      "         [ 0.8203],\n",
      "         [ 0.5570],\n",
      "         [-0.2676]... [-0.0151],\n",
      "         [ 0.1856],\n",
      "         [ 0.7012],\n",
      "         [ 0.0560],\n",
      "         [-0.4499]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.47144216],\n",
      "        [-0.41429198],\n",
      "        [-0.85052145],\n",
      "        [-1.7275223 ],\n",
      "        [-0.67251855],\n",
      "   ...38727   ],\n",
      "        [-0.06805599],\n",
      "        [ 1.2316486 ],\n",
      "        [-0.16052437],\n",
      "        [ 0.920908  ]]], dtype=float32)\n",
      "h_         = tensor([[[-0.0704],\n",
      "         [-0.0950],\n",
      "         [ 0.4107],\n",
      "         [ 0.6434],\n",
      "         [ 0.3176],\n",
      "         [-0.0666]... [-0.0102],\n",
      "         [ 0.0671],\n",
      "         [ 0.1284],\n",
      "         [ 0.0057],\n",
      "         [-0.3802]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb471e9bd00>\n",
      "model_     = LSTM(11, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0704],\n",
      "         [-0.0950],\n",
      "         [ 0.4107],\n",
      "         [ 0.6434],\n",
      "         [ 0.3176],\n",
      "         [-0.0666]... [-0.0102],\n",
      "         [ 0.0671],\n",
      "         [ 0.1284],\n",
      "         [ 0.0057],\n",
      "         [-0.3802]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 3.3105126e-01, -5.9388542e-01, -4.9454272e-02,  1.3260270e+00,\n",
      "          8.9871562e-01, -1.2433864e+00,  8.0...1368884e-01,  1.1033213e+00, -1.6575415e+00,\n",
      "          1.4546207e+00, -1.8808073e+00,  6.1115283e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 3.3105126e-01 -5.9388542e-01 -4.9454272e-02  1.3260270e+00\n",
      "    8.9871562e-01 -1.2433864e+00  8.0421... -3.7454081e-01 -1.1368884e-01  1.1033213e+00 -1.6575415e+00\n",
      "    1.4546207e+00 -1.8808073e+00  6.1115283e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471e9bd00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 3.3105126e-01 -5.9388542e-01 -4.9454272e-02  1.3260270e+00\n",
      "    8.9871562e-01 -1.2433864e+00  8.04210...e-01\n",
      "   -3.7454081e-01 -1.1368884e-01  1.1033213e+00 -1.6575415e+00\n",
      "    1.4546207e+00 -1.8808073e+00  6.1115283e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471e9bd00>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 3.3105126e-01 -5.9388542e-01 -4.9454272e-02  1.3260270e+00\n",
      "   8.9871562e-01 -1.243...1e-01\n",
      "  -3.7454081e-01 -1.1368884e-01  1.1033213e+00 -1.6575415e+00\n",
      "   1.4546207e+00 -1.8808073e+00  6.1115283e-01]]),)\n",
      "        y          = needle.Tensor([[ 3.3105126e-01 -5.9388542e-01 -4.9454272e-02  1.3260270e+00\n",
      "   8.9871562e-01 -1.2433864e+00  8.0421060...731e-01\n",
      "  -3.7454081e-01 -1.1368884e-01  1.1033213e+00 -1.6575415e+00\n",
      "   1.4546207e+00 -1.8808073e+00  6.1115283e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 3.3105126e-01 -5.9388542e-01 -4.9454272e-02  1.3260270e+00\n",
      "   8.9871562e-01 -1.2433864e+00  8.042106...54081e-01 -1.1368884e-01  1.1033213e+00 -1.6575415e+00\n",
      "   1.4546207e+00 -1.8808073e+00  6.1115283e-01]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471e9bfa0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 3.3105126e-01 -5.9388542e-01 -4.9454272e-02  1.3260270e+00\n",
      "   8.9871562e-01 -1.2433864e+00  8.0421060...731e-01\n",
      "  -3.7454081e-01 -1.1368884e-01  1.1033213e+00 -1.6575415e+00\n",
      "   1.4546207e+00 -1.8808073e+00  6.1115283e-01]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.2994124   0.5124621  -0.47422606 -1.3191386 ]\n",
      " [-0.3227046  -1.440419   -0.91836035 -0.7473481 ]\n",
      " [...3  -1.3117517 ]\n",
      " [-1.7142326  -1.3000385   0.3850666  -2.1681774 ]\n",
      " [ 0.01850421  2.2361562  -1.4297532   2.2116618 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb471e9bfa0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.68263006 -0.833737    0.15893066 -0.26886868]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.68263006 -0.833737    0.15893066 -0.26886868]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471e9b760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.68263006 -0.833737    0.15893066 -0.26886868]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471e9b760>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471e9ba00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471e9ba00>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471e9b9a0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471e9b9a0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-1-11-15-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 0.47097313],\n",
      "        [ 0.74972373],\n",
      "        [-0.57928866],\n",
      "        [ 0.06331863],\n",
      "        [-0.21071856],\n",
      "   ...12966749],\n",
      "        [ 1.3097278 ],\n",
      "        [-1.504504  ],\n",
      "        [ 0.14273839],\n",
      "        [-1.895856  ]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.6654],\n",
      "         [ 0.0552],\n",
      "         [ 0.0428],\n",
      "         [-1.1128],\n",
      "         [ 0.1510],\n",
      "         [-1.1801]... [ 0.5540],\n",
      "         [-0.1581],\n",
      "         [ 0.0800],\n",
      "         [-0.9698],\n",
      "         [ 0.2095]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-1.2784971 ],\n",
      "        [-0.29652905],\n",
      "        [-0.1322499 ],\n",
      "        [-1.1183956 ],\n",
      "        [-1.3992249 ],\n",
      "   ...02462552],\n",
      "        [ 2.349636  ],\n",
      "        [-0.8309947 ],\n",
      "        [ 1.1477146 ],\n",
      "        [ 0.66179895]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.3676],\n",
      "         [ 0.0288],\n",
      "         [ 0.0012],\n",
      "         [-0.7498],\n",
      "         [ 0.0438],\n",
      "         [-0.0805]... [ 0.0796],\n",
      "         [-0.1475],\n",
      "         [ 0.0158],\n",
      "         [-0.4191],\n",
      "         [ 0.0033]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4719cc1c0>\n",
      "model_     = LSTM(11, 1, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-3.3822e-01],\n",
      "         [-1.5303e-02],\n",
      "         [ 1.5969e-01],\n",
      "         [-5.2783e-02],\n",
      "         [ 5.7532e-04]...     [-1.4753e-01],\n",
      "         [ 1.5772e-02],\n",
      "         [-4.1907e-01],\n",
      "         [ 3.3366e-03]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.87800395, -1.8986175 , -0.66722393, ...,  0.59540206,\n",
      "          0.43577665,  0.37949923],\n",
      "        [-0.6160...\n",
      "        [-1.1717463 ,  1.5841943 ,  1.2899613 , ..., -0.03484584,\n",
      "          1.5189143 , -0.08758169]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.87800395 -1.8986175  -0.66722393 ...  0.59540206  0.43577665\n",
      "    0.37949923]\n",
      "  [-0.616021    1.36... -0.6674986\n",
      "   -1.0777769 ]\n",
      "  [-1.1717463   1.5841943   1.2899613  ... -0.03484584  1.5189143\n",
      "   -0.08758169]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4719cc1c0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.87800395 -1.8986175  -0.66722393 ...  0.59540206  0.43577665\n",
      "    0.37949923]\n",
      "  [-0.616021    1.367...587886  -0.6674986\n",
      "   -1.0777769 ]\n",
      "  [-1.1717463   1.5841943   1.2899613  ... -0.03484584  1.5189143\n",
      "   -0.08758169]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4719cc1c0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.87800395 -1.8986175  -0.66722393  0.20474888  0.7439918  -1.7575005\n",
      "   0.6928509...1943   1.2899613  -0.9211777  -0.5342512   0.61143684\n",
      "  -0.05046987  1.6612117  -0.03484584  1.5189143  -0.08758169]]))\n",
      "        y          = needle.Tensor([[ 0.87800395 -1.8986175  -0.66722393  0.20474888  0.7439918  -1.7575005\n",
      "   0.69285095 -1.0382822   0.59...881314   1.2485098  -0.8536911   1.597928   -2.7627037\n",
      "  -1.5568607  -0.44416946  0.8764375  -0.18872647 -0.67910385]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.87800395 -1.8986175  -0.66722393  0.20474888  0.7439918  -1.7575005\n",
      "   0.69285095 -1.0382822   0.5...098  -0.8536911   1.597928   -2.7627037\n",
      "  -1.5568607  -0.44416946  0.8764375  -0.18872647 -0.67910385]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4719cc2b0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 0.87800395 -1.8986175  -0.66722393  0.20474888  0.7439918  -1.7575005\n",
      "   0.69285095 -1.0382822   0.59...881314   1.2485098  -0.8536911   1.597928   -2.7627037\n",
      "  -1.5568607  -0.44416946  0.8764375  -0.18872647 -0.67910385]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.38740516e+00  1.17075816e-01 -7.64312565e-01  9.13897514e-01]\n",
      " [ 4.47936445e-01  1.55088687e+00 -3....0  6.72529161e-01  1.46280301e+00 -6.25711381e-01]\n",
      " [-2.86276174e+00 -1.25515378e+00  3.21966529e-01 -5.77221012e+00]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4719cc2b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[0.03178585 0.49471557 0.26349545 0.7946247 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[0.03178585 0.49471557 0.26349545 0.7946247 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471e03ee0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[0.03178585 0.49471557 0.26349545 0.7946247 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471e03ee0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471e03e80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471e03e80>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471e03be0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471e03be0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-1-11-15-2-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-1.7656944 ],\n",
      "        [ 0.5732577 ],\n",
      "        [-1.5659747 ],\n",
      "        [ 1.5905434 ],\n",
      "        [ 0.94720054],\n",
      "   ...0799494 ],\n",
      "        [-0.66783166],\n",
      "        [ 0.4060412 ],\n",
      "        [ 0.68839264],\n",
      "        [ 1.3385079 ]]], dtype=float32)\n",
      "c_         = tensor([[[ 1.1938e-01],\n",
      "         [ 1.5889e-01],\n",
      "         [ 3.4384e-02],\n",
      "         [ 1.0765e-01],\n",
      "         [-8.8545e-01]...     [ 8.0460e-02],\n",
      "         [-2.8241e-03],\n",
      "         [-4.4607e-02],\n",
      "         [-6.5200e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.25598484],\n",
      "        [ 0.4388799 ],\n",
      "        [-0.47921464],\n",
      "        [-1.9740121 ],\n",
      "        [ 0.10763578],\n",
      "   ...71125203],\n",
      "        [ 0.8221489 ],\n",
      "        [ 0.6386653 ],\n",
      "        [ 0.0624217 ],\n",
      "        [-2.4081461 ]]], dtype=float32)\n",
      "h_         = tensor([[[ 1.4326e-03],\n",
      "         [ 3.5322e-02],\n",
      "         [ 2.7192e-02],\n",
      "         [ 9.4917e-02],\n",
      "         [-2.8291e-02]...     [ 4.2363e-02],\n",
      "         [-1.4093e-03],\n",
      "         [-2.1603e-02],\n",
      "         [-3.1084e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4723dd430>\n",
      "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0002],\n",
      "         [-0.0060],\n",
      "         [-0.0046],\n",
      "         [-0.0159],\n",
      "         [ 0.0049],\n",
      "         [ 0.0029]... [ 0.0036],\n",
      "         [ 0.0424],\n",
      "         [-0.0014],\n",
      "         [-0.0216],\n",
      "         [-0.0311]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 7.95142353e-01,  1.87451160e+00, -2.13950709e-01,\n",
      "          4.17256147e-01, -4.26663738e-03,  5.92124820e-01...        -4.49951857e-01,  2.57429689e-01, -1.11701131e-01,\n",
      "         -1.32903051e+00, -7.28875458e-01]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 7.95142353e-01  1.87451160e+00 -2.13950709e-01  4.17256147e-01\n",
      "   -4.26663738e-03  5.92124820e-01 -...98516e-01 -7.82733142e-01 -4.49951857e-01  2.57429689e-01\n",
      "   -1.11701131e-01 -1.32903051e+00 -7.28875458e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4723dd430>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 7.95142353e-01  1.87451160e+00 -2.13950709e-01  4.17256147e-01\n",
      "   -4.26663738e-03  5.92124820e-01 -1... -1.64998516e-01 -7.82733142e-01 -4.49951857e-01  2.57429689e-01\n",
      "   -1.11701131e-01 -1.32903051e+00 -7.28875458e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4723dd430>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 7.95142353e-01  1.87451160e+00 -2.13950709e-01  4.17256147e-01\n",
      "  -4.26663738e-03  ... -1.64998516e-01 -7.82733142e-01 -4.49951857e-01  2.57429689e-01\n",
      "  -1.11701131e-01 -1.32903051e+00 -7.28875458e-01]]),)\n",
      "        y          = needle.Tensor([[ 7.95142353e-01  1.87451160e+00 -2.13950709e-01  4.17256147e-01\n",
      "  -4.26663738e-03  5.92124820e-01 -1.2...\n",
      "  -1.64998516e-01 -7.82733142e-01 -4.49951857e-01  2.57429689e-01\n",
      "  -1.11701131e-01 -1.32903051e+00 -7.28875458e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 7.95142353e-01  1.87451160e+00 -2.13950709e-01  4.17256147e-01\n",
      "  -4.26663738e-03  5.92124820e-01 -1....-01 -7.82733142e-01 -4.49951857e-01  2.57429689e-01\n",
      "  -1.11701131e-01 -1.32903051e+00 -7.28875458e-01]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4723ddc10>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[ 7.95142353e-01  1.87451160e+00 -2.13950709e-01  4.17256147e-01\n",
      "  -4.26663738e-03  5.92124820e-01 -1.2...\n",
      "  -1.64998516e-01 -7.82733142e-01 -4.49951857e-01  2.57429689e-01\n",
      "  -1.11701131e-01 -1.32903051e+00 -7.28875458e-01]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.9800043  -0.01571498  2.4100566  -4.405927  ]\n",
      " [-1.6410946   1.0842212   2.271045   -1.241562  ]\n",
      " [...6   2.8177834 ]\n",
      " [-0.45972115 -0.48547488  2.4812264  -0.5792357 ]\n",
      " [ 1.1326537  -0.41581938  1.6478969  -0.76797247]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4723ddc10>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[0.5089443  0.77480793 0.00777507 0.9828154 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[0.5089443  0.77480793 0.00777507 0.9828154 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4723ddc40>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[0.5089443  0.77480793 0.00777507 0.9828154 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4723ddc40>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4723ddac0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4723ddac0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4723dd1c0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4723dd1c0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-1-11-15-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 1, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 0.710086  ],\n",
      "        [-1.1143208 ],\n",
      "        [ 0.8867428 ],\n",
      "        [ 1.3494916 ],\n",
      "        [ 1.2658863 ],\n",
      "   ...9369982 ],\n",
      "        [-0.5263702 ],\n",
      "        [-0.44775727],\n",
      "        [ 0.13298298],\n",
      "        [-0.534451  ]]], dtype=float32)\n",
      "c_         = tensor([[[ 0.0885],\n",
      "         [-0.1191],\n",
      "         [-0.7824],\n",
      "         [ 0.6512],\n",
      "         [-0.1036],\n",
      "         [-0.1528]... [-0.2243],\n",
      "         [-0.0166],\n",
      "         [ 0.0253],\n",
      "         [ 0.1682],\n",
      "         [-0.2773]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.28564912],\n",
      "        [-0.12299512],\n",
      "        [-0.3278148 ],\n",
      "        [-0.561989  ],\n",
      "        [-2.1674016 ],\n",
      "   ...2396106 ],\n",
      "        [-0.6332098 ],\n",
      "        [ 0.53772455],\n",
      "        [ 1.8630148 ],\n",
      "        [ 0.26585612]]], dtype=float32)\n",
      "h_         = tensor([[[ 0.0347],\n",
      "         [-0.0587],\n",
      "         [-0.6372],\n",
      "         [ 0.0834],\n",
      "         [-0.1011],\n",
      "         [-0.0406]... [-0.1077],\n",
      "         [-0.0083],\n",
      "         [ 0.0127],\n",
      "         [ 0.0848],\n",
      "         [-0.1310]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 1\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb450dd0a30>\n",
      "model_     = LSTM(11, 1, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0015],\n",
      "         [ 0.0880],\n",
      "         [ 0.1601],\n",
      "         [-0.0025],\n",
      "         [-0.0765],\n",
      "         [ 0.0083]... [-0.1077],\n",
      "         [-0.0083],\n",
      "         [ 0.0127],\n",
      "         [ 0.0848],\n",
      "         [-0.1310]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-1.6006964 , -0.5873399 , -0.1214745 , ..., -0.29666582,\n",
      "          1.6966965 , -0.8145951 ],\n",
      "        [ 0.0309...\n",
      "        [-0.04994569, -1.9448701 , -1.2883861 , ..., -0.49243146,\n",
      "         -0.83832574, -0.03615476]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.6006964  -0.5873399  -0.1214745  ... -0.29666582  1.6966965\n",
      "   -0.8145951 ]\n",
      "  [ 0.03099206  1.109...0.21936996\n",
      "    1.0540161 ]\n",
      "  [-0.04994569 -1.9448701  -1.2883861  ... -0.49243146 -0.83832574\n",
      "   -0.03615476]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450dd0a30>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 1\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-1.6006964  -0.5873399  -0.1214745  ... -0.29666582  1.6966965\n",
      "   -0.8145951 ]\n",
      "  [ 0.03099206  1.1092...5239   0.21936996\n",
      "    1.0540161 ]\n",
      "  [-0.04994569 -1.9448701  -1.2883861  ... -0.49243146 -0.83832574\n",
      "   -0.03615476]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450dd0a30>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.6006964  -0.5873399  -0.1214745   2.4868367   0.29001725 -0.6368369\n",
      "  -0.0509905...8701  -1.2883861  -2.102502    0.32145718 -0.35299513\n",
      "  -0.2233992   0.80304086 -0.49243146 -0.83832574 -0.03615476]]))\n",
      "        y          = needle.Tensor([[-1.6006964  -0.5873399  -0.1214745   2.4868367   0.29001725 -0.6368369\n",
      "  -0.0509905  -0.58892524 -0.29...9776175  0.2800901  -1.0793169   0.36965543 -1.6074052\n",
      "  -0.90663385 -0.60721177  0.39657733 -0.9327079   1.3389069 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.6006964  -0.5873399  -0.1214745   2.4868367   0.29001725 -0.6368369\n",
      "  -0.0509905  -0.58892524 -0.2...901  -1.0793169   0.36965543 -1.6074052\n",
      "  -0.90663385 -0.60721177  0.39657733 -0.9327079   1.3389069 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450dd0520>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 1\n",
      "        X          = needle.Tensor([[-1.6006964  -0.5873399  -0.1214745   2.4868367   0.29001725 -0.6368369\n",
      "  -0.0509905  -0.58892524 -0.29...9776175  0.2800901  -1.0793169   0.36965543 -1.6074052\n",
      "  -0.90663385 -0.60721177  0.39657733 -0.9327079   1.3389069 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-2.2517862   0.10143691 -4.245175   -2.613126  ]\n",
      " [ 0.0147493  -2.3385477  -1.2802554   1.7887108 ]\n",
      " [...4  -0.1206708 ]\n",
      " [ 1.6243944  -1.3470973   0.17340185  0.99450755]\n",
      " [ 2.3710039   2.081604    0.33784533  0.98736537]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450dd0520>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.18956578  0.2170893  -0.697827    0.84948575]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.18956578  0.2170893  -0.697827    0.84948575]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461247820>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.18956578  0.2170893  -0.697827    0.84948575]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461247820>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461247910>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461247910>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471e63820>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471e63820>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-12-1-1-1-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 12\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[ 2.2538242 ,  0.92979646,  0.4704782 , -0.41433212,\n",
      "          0.3938383 ,  0.5751978 ,  0.7870159 ,  1.4734125 ,\n",
      "         -1.4136882 ,  0.19127245, -0.44056144,  0.05551487]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0883, -0.1001, -0.1136,  0.0048, -0.0196,  0.1285, -0.0672,\n",
      "          -0.1110, -0.0839,  0.0549, -0.0234, -0.0107]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 1.1715662 ,  0.08070967,  1.4078803 ,  0.8100003 ,\n",
      "         -0.8082553 , -0.36716437, -1.0378824 ,  1.2119285 ,\n",
      "         -1.8479195 ,  1.1404339 , -0.5854362 ,  0.34438103]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0431, -0.0457, -0.0630,  0.0023, -0.0095,  0.0599, -0.0299,\n",
      "          -0.0610, -0.0400,  0.0310, -0.0125, -0.0051]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb471866340>\n",
      "model_     = LSTM(1, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0431, -0.0457, -0.0630,  0.0023, -0.0095,  0.0599, -0.0299,\n",
      "          -0.0610, -0.0400,  0.0310, -0.0125, -0.0051]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[0.94973373]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[0.94973373]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471866340>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[0.94973373]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb471866340>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.94973373]]),)\n",
      "        y          = needle.Tensor([[0.94973373]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.94973373]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4718669a0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[0.94973373]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.13913108  0.14185409 -0.2289483  -0.09885725 -0.05708196 -0.04667002\n",
      "   0.17292663  0.27303737 -0.2...030002 -0.11119739 -0.05779664 -0.12377226\n",
      "  -0.21820971  0.20650332 -0.09035368  0.2622604   0.1255177  -0.07520986]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4718669a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.26252103  0.13342014 -0.17325385  0.2211023   0.17119548  0.03527558\n",
      "   0.25505888 -0.27402386 -0.0...45023   0.10968938  0.05631492  0.17144188\n",
      "   0.11584145 -0.20391083 -0.16808708  0.10433909  0.01337615  0.03962564]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.26252103  0.13342014 -0.17325385  0.2211023   0.17119548  0.03527558\n",
      "   0.25505888 -0.27402386 -0.... 0.10968938  0.05631492  0.17144188\n",
      "   0.11584145 -0.20391083 -0.16808708  0.10433909  0.01337615  0.03962564]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb471866a00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.26252103  0.13342014 -0.17325385  0.2211023   0.17119548  0.03527558\n",
      "   0.25505888 -0.27402386 -0.... 0.10968938  0.05631492  0.17144188\n",
      "   0.11584145 -0.20391083 -0.16808708  0.10433909  0.01337615  0.03962564]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb471866a00>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471866af0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb471866af0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb471866610>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb471866610>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-12-1-1-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[ 0.62183684,  1.3365844 ,  1.1794795 ,  0.4092103 ,\n",
      "          0.7638359 , -0.8317876 ,  0.645025  ,  0.05779152,\n",
      "          0.70044756,  0.68061566,  0.00743088, -0.64513654]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0026,  0.0329, -0.0030,  0.0240,  0.0034, -0.0188,  0.0065,\n",
      "           0.0206,  0.0589, -0.0198,  0.0466,  0.0174]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.3162075 , -1.2119846 , -0.20828106,  1.5784794 ,\n",
      "          0.42881468,  1.010441  ,  0.43866023, -0.0630611 ,\n",
      "         -0.1380361 , -0.30280092, -0.07117644, -0.02350494]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0014,  0.0172, -0.0015,  0.0125,  0.0017, -0.0099,  0.0032,\n",
      "           0.0098,  0.0307, -0.0096,  0.0233,  0.0088]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb458f806a0>\n",
      "model_     = LSTM(1, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 4.0597e-02,  2.8777e-02, -3.2563e-03, -3.1947e-02, -2.1227e-02,\n",
      "           4.1898e-02, -1.7194e-02, -4.2546...3,  3.1508e-03,  9.7910e-03,  3.0709e-02, -9.6404e-03,\n",
      "           2.3312e-02,  8.7514e-03]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.67287284]],\n",
      "\n",
      "       [[-1.3662224 ]],\n",
      "\n",
      "       [[-0.47654223]],\n",
      "\n",
      "       [[ 1.0067296 ]],\n",
      "\n",
      "       [[ 1.656990...]],\n",
      "\n",
      "       [[-0.3939224 ]],\n",
      "\n",
      "       [[ 0.3802638 ]],\n",
      "\n",
      "       [[ 0.48408735]],\n",
      "\n",
      "       [[-0.34029132]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.67287284]]\n",
      "\n",
      " [[-1.3662224 ]]\n",
      "\n",
      " [[-0.47654223]]\n",
      "\n",
      " [[ 1.0067296 ]]\n",
      "\n",
      " [[ 1.6569909 ]]\n",
      "\n",
      " [[ 1.9678881...]]\n",
      "\n",
      " [[ 0.3459722 ]]\n",
      "\n",
      " [[ 1.2051528 ]]\n",
      "\n",
      " [[-0.3939224 ]]\n",
      "\n",
      " [[ 0.3802638 ]]\n",
      "\n",
      " [[ 0.48408735]]\n",
      "\n",
      " [[-0.34029132]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458f806a0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.67287284]]\n",
      "\n",
      " [[-1.3662224 ]]\n",
      "\n",
      " [[-0.47654223]]\n",
      "\n",
      " [[ 1.0067296 ]]\n",
      "\n",
      " [[ 1.6569909 ]]\n",
      "\n",
      " [[ 1.9678881 ...65294  ]]\n",
      "\n",
      " [[ 0.3459722 ]]\n",
      "\n",
      " [[ 1.2051528 ]]\n",
      "\n",
      " [[-0.3939224 ]]\n",
      "\n",
      " [[ 0.3802638 ]]\n",
      "\n",
      " [[ 0.48408735]]\n",
      "\n",
      " [[-0.34029132]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458f806a0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.67287284]]), needle.Tensor([[-1.3662224]]), needle.Tensor([[-0.47654223]]), need...le.Tensor([[-0.3939224]]), needle.Tensor([[0.3802638]]), needle.Tensor([[0.48408735]]), needle.Tensor([[-0.34029132]]))\n",
      "        y          = needle.Tensor([[-0.67287284]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.67287284]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458f80610>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.67287284]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.08857022  0.19134916 -0.01131308 -0.09878239  0.04180308 -0.14034596\n",
      "  -0.15666617 -0.07972524 -0.0...3191128  0.10939324 -0.14423561  0.1625923\n",
      "  -0.09533966 -0.14246058  0.18434447 -0.14564776  0.12492728  0.08426911]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458f80610>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.15080889 -0.24903432 -0.21149458 -0.11727214  0.07584772  0.02890903\n",
      "  -0.0146834   0.14623907 -0.0...123794  0.23212928 -0.18883395 -0.10541528\n",
      "   0.15003893  0.27043396 -0.05696051  0.2850803   0.13007718 -0.22240615]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.15080889 -0.24903432 -0.21149458 -0.11727214  0.07584772  0.02890903\n",
      "  -0.0146834   0.14623907 -0.... 0.23212928 -0.18883395 -0.10541528\n",
      "   0.15003893  0.27043396 -0.05696051  0.2850803   0.13007718 -0.22240615]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4617e92b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.15080889 -0.24903432 -0.21149458 -0.11727214  0.07584772  0.02890903\n",
      "  -0.0146834   0.14623907 -0.... 0.23212928 -0.18883395 -0.10541528\n",
      "   0.15003893  0.27043396 -0.05696051  0.2850803   0.13007718 -0.22240615]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4617e92b0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4617e9880>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4617e9880>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4617e9430>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4617e9430>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-12-1-1-2-1] ____________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 12\n",
      "bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-1.137881  , -1.5301943 ,  1.7983291 ,  0.20373076,\n",
      "         -2.0111325 ,  0.23660243,  0.9408488 , -0.059213...973762 ,  0.8242994 ,  0.8370221 ,\n",
      "          0.39453682,  0.4506966 ,  0.44333765, -0.15762904]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0367, -0.0109, -0.0332, -0.0474,  0.0465,  0.0198, -0.0102,\n",
      "          -0.0093,  0.0194, -0.0030,  0.0164,..., -0.0045,  0.0030,  0.0009,\n",
      "          -0.0043, -0.0044,  0.0012, -0.0017,  0.0007]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.38584718, -0.15149833, -0.7174848 , -0.5075288 ,\n",
      "         -0.10414391,  0.38687778,  0.75890046, -0.920890...8857939,  0.3100862 ,  0.8541037 ,\n",
      "          1.3098782 ,  1.1432472 ,  1.4040611 , -0.34958073]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0191, -0.0056, -0.0160, -0.0226,  0.0234,  0.0095, -0.0052,\n",
      "          -0.0046,  0.0097, -0.0016,  0.0085,..., -0.0023,  0.0015,  0.0004,\n",
      "          -0.0021, -0.0022,  0.0006, -0.0008,  0.0003]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4722034c0>\n",
      "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0022, -0.0014, -0.0017, -0.0021, -0.0023,  0.0015,  0.0004,\n",
      "          -0.0021, -0.0022,  0.0006, -0.0008,  0.0003]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[0.36486134]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[0.36486134]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4722034c0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[0.36486134]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4722034c0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.36486134]]),)\n",
      "        y          = needle.Tensor([[0.36486134]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.36486134]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb472203e20>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[0.36486134]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.00892732 -0.04413832  0.01693507  0.03023887 -0.0544566  -0.02539125\n",
      "  -0.01143506 -0.0359341   0.0...625956 -0.0887976   0.01167946 -0.06955767\n",
      "   0.049867   -0.00979428 -0.00152892  0.06324413  0.07880071 -0.09168421]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb472203e20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.2680496   0.1959272   0.23078561 -0.08671299 -0.10977267 -0.08219707\n",
      "  -0.24372977  0.00694111  0.1...12922  -0.14691673  0.19140324 -0.13817768\n",
      "  -0.13138743 -0.10708228  0.24807477  0.20566368 -0.05032542 -0.0868524 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.2680496   0.1959272   0.23078561 -0.08671299 -0.10977267 -0.08219707\n",
      "  -0.24372977  0.00694111  0....-0.14691673  0.19140324 -0.13817768\n",
      "  -0.13138743 -0.10708228  0.24807477  0.20566368 -0.05032542 -0.0868524 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb472203fa0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.2680496   0.1959272   0.23078561 -0.08671299 -0.10977267 -0.08219707\n",
      "  -0.24372977  0.00694111  0....-0.14691673  0.19140324 -0.13817768\n",
      "  -0.13138743 -0.10708228  0.24807477  0.20566368 -0.05032542 -0.0868524 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb472203fa0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb472203220>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb472203220>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4722039a0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4722039a0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-12-1-1-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[ 0.5369976 ,  0.5305617 , -0.9135423 , -0.38095406,\n",
      "         -0.8955245 ,  0.6250386 ,  1.8804625 ,  0.145685...250746 ,  0.75787836,  0.42757285,\n",
      "         -0.2289904 , -1.7926437 , -0.4828753 ,  0.8341195 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.2673, -0.3647, -0.4758,  0.1294,  0.0567,  0.2289, -0.5281,\n",
      "          -0.0177,  0.2806,  0.1283, -0.3340,..., -0.0044, -0.0640,  0.0009,\n",
      "          -0.0084,  0.0755,  0.0773,  0.0479,  0.0198]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 3.2669997e-01,  9.2545831e-01,  7.7066787e-02,  5.5831552e-01,\n",
      "          6.0616589e-01, -1.3750852e+00, -1.3...0e-01, -1.4079072e+00,\n",
      "         -1.4527763e+00,  4.5216155e-01,  3.2653648e-01, -7.2059375e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.1415, -0.1805, -0.2407,  0.0639,  0.0204,  0.0975, -0.2594,\n",
      "          -0.0092,  0.1331,  0.0614, -0.1654,..., -0.0022, -0.0325,  0.0004,\n",
      "          -0.0045,  0.0369,  0.0394,  0.0237,  0.0107]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb46130efa0>\n",
      "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 3.1029e-03, -7.5704e-05, -7.7887e-03, -2.0062e-03,  1.9022e-03,\n",
      "          -5.3140e-03,  9.8694e-04, -3.3154...2,  4.4778e-04, -4.5037e-03,  3.6923e-02,  3.9400e-02,\n",
      "           2.3735e-02,  1.0714e-02]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 0.80167735]],\n",
      "\n",
      "       [[-1.5977813 ]],\n",
      "\n",
      "       [[-1.659676  ]],\n",
      "\n",
      "       [[-0.615433  ]],\n",
      "\n",
      "       [[ 1.778889...]],\n",
      "\n",
      "       [[ 0.92649287]],\n",
      "\n",
      "       [[ 0.77399164]],\n",
      "\n",
      "       [[ 0.64111894]],\n",
      "\n",
      "       [[ 2.2218463 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 0.80167735]]\n",
      "\n",
      " [[-1.5977813 ]]\n",
      "\n",
      " [[-1.659676  ]]\n",
      "\n",
      " [[-0.615433  ]]\n",
      "\n",
      " [[ 1.7788895 ]]\n",
      "\n",
      " [[ 0.8583957...]]\n",
      "\n",
      " [[ 0.08015412]]\n",
      "\n",
      " [[ 1.494589  ]]\n",
      "\n",
      " [[ 0.92649287]]\n",
      "\n",
      " [[ 0.77399164]]\n",
      "\n",
      " [[ 0.64111894]]\n",
      "\n",
      " [[ 2.2218463 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46130efa0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 0.80167735]]\n",
      "\n",
      " [[-1.5977813 ]]\n",
      "\n",
      " [[-1.659676  ]]\n",
      "\n",
      " [[-0.615433  ]]\n",
      "\n",
      " [[ 1.7788895 ]]\n",
      "\n",
      " [[ 0.8583957 ...1640895]]\n",
      "\n",
      " [[ 0.08015412]]\n",
      "\n",
      " [[ 1.494589  ]]\n",
      "\n",
      " [[ 0.92649287]]\n",
      "\n",
      " [[ 0.77399164]]\n",
      "\n",
      " [[ 0.64111894]]\n",
      "\n",
      " [[ 2.2218463 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb46130efa0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[0.80167735]]), needle.Tensor([[-1.5977813]]), needle.Tensor([[-1.659676]]), needle....dle.Tensor([[0.92649287]]), needle.Tensor([[0.77399164]]), needle.Tensor([[0.64111894]]), needle.Tensor([[2.2218463]]))\n",
      "        y          = needle.Tensor([[0.80167735]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[0.80167735]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46130e880>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[0.80167735]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.01058705  0.07756562  0.07754558 -0.07026739 -0.2109043   0.15644477\n",
      "   0.20070718 -0.04742315 -0.0...04990598  0.01467891 -0.21772987 -0.122513\n",
      "   0.04621295  0.03457953 -0.02933888 -0.02033528 -0.00173354 -0.15941885]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb46130e880>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.29091197e-01 -5.24579138e-02  7.00473785e-02  1.82392091e-01\n",
      "   2.32786000e-01  6.24610186e-02 -2.4...01 -1.66361928e-02  1.94348097e-01  2.58885026e-02\n",
      "   2.80362368e-01 -2.02736914e-01 -4.79801893e-02 -7.40671307e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.29091197e-01 -5.24579138e-02  7.00473785e-02  1.82392091e-01\n",
      "   2.32786000e-01  6.24610186e-02 -2....6361928e-02  1.94348097e-01  2.58885026e-02\n",
      "   2.80362368e-01 -2.02736914e-01 -4.79801893e-02 -7.40671307e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46130e340>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.29091197e-01 -5.24579138e-02  7.00473785e-02  1.82392091e-01\n",
      "   2.32786000e-01  6.24610186e-02 -2....6361928e-02  1.94348097e-01  2.58885026e-02\n",
      "   2.80362368e-01 -2.02736914e-01 -4.79801893e-02 -7.40671307e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46130e340>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46130ea00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46130ea00>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46130e1c0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46130e1c0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-12-1-15-1-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-0.03546185, -2.506222  ,  0.51532185, -0.85889214,\n",
      "          1.2764375 , -0.25595766,  0.209731  ,  1.275370...148413 , -0.02097052, -0.6186141 ,\n",
      "         -0.96152794,  0.6862362 ,  0.07552369,  0.28221217]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-1.2684e-01, -1.3005e-01, -2.2358e-02,  1.6895e-01,  6.8353e-04,\n",
      "          -7.8153e-02,  3.6496e-02,  1.1572...2, -5.6904e-03, -2.0864e-02,  1.3592e-02,  2.6280e-02,\n",
      "          -1.4590e-02,  1.4288e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.5143578 , -0.00867302,  1.8194265 , -0.9053974 ,\n",
      "          0.1265891 ,  0.0411993 ,  0.9272771 , -1.94253 ...413672 , -0.6606047 ,  0.02643172,\n",
      "          1.6806192 , -0.5496226 , -1.330779  , -0.8441689 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-6.6855e-02, -5.8989e-02, -9.3324e-03,  9.5068e-02,  3.8950e-04,\n",
      "          -4.1311e-02,  1.9877e-02,  5.2104...3, -2.7993e-03, -1.0609e-02,  6.8449e-03,  1.2843e-02,\n",
      "          -7.4719e-03,  7.3466e-03]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb458909700>\n",
      "model_     = LSTM(1, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-6.6855e-02, -5.8989e-02, -9.3324e-03,  9.5068e-02,  3.8950e-04,\n",
      "          -4.1311e-02,  1.9877e-02,  5.2104...3, -2.7993e-03, -1.0609e-02,  6.8449e-03,  1.2843e-02,\n",
      "          -7.4719e-03,  7.3466e-03]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.1707324 ],\n",
      "        [ 2.0480487 ],\n",
      "        [-2.0436494 ],\n",
      "        [-0.12018888],\n",
      "        [-0.16317411],\n",
      "   ...7391591 ],\n",
      "        [ 1.8082628 ],\n",
      "        [-0.10308614],\n",
      "        [-1.153433  ],\n",
      "        [ 0.20963891]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.1707324 ]\n",
      "  [ 2.0480487 ]\n",
      "  [-2.0436494 ]\n",
      "  [-0.12018888]\n",
      "  [-0.16317411]\n",
      "  [ 0.7809772 ]\n",
      "  [ 1.1...[-0.6096025 ]\n",
      "  [-2.354262  ]\n",
      "  [ 0.7391591 ]\n",
      "  [ 1.8082628 ]\n",
      "  [-0.10308614]\n",
      "  [-1.153433  ]\n",
      "  [ 0.20963891]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458909700>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.1707324 ]\n",
      "  [ 2.0480487 ]\n",
      "  [-2.0436494 ]\n",
      "  [-0.12018888]\n",
      "  [-0.16317411]\n",
      "  [ 0.7809772 ]\n",
      "  [ 1.19...206]\n",
      "  [-0.6096025 ]\n",
      "  [-2.354262  ]\n",
      "  [ 0.7391591 ]\n",
      "  [ 1.8082628 ]\n",
      "  [-0.10308614]\n",
      "  [-1.153433  ]\n",
      "  [ 0.20963891]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458909700>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.1707324 ]\n",
      " [ 2.0480487 ]\n",
      " [-2.0436494 ]\n",
      " [-0.12018888]\n",
      " [-0.16317411]\n",
      " [ 0.78097....56814206]\n",
      " [-0.6096025 ]\n",
      " [-2.354262  ]\n",
      " [ 0.7391591 ]\n",
      " [ 1.8082628 ]\n",
      " [-0.10308614]\n",
      " [-1.153433  ]\n",
      " [ 0.20963891]]),)\n",
      "        y          = needle.Tensor([[-1.1707324 ]\n",
      " [ 2.0480487 ]\n",
      " [-2.0436494 ]\n",
      " [-0.12018888]\n",
      " [-0.16317411]\n",
      " [ 0.7809772 ]\n",
      " [ 1.1975583 ]\n",
      " [-0.56814206]\n",
      " [-0.6096025 ]\n",
      " [-2.354262  ]\n",
      " [ 0.7391591 ]\n",
      " [ 1.8082628 ]\n",
      " [-0.10308614]\n",
      " [-1.153433  ]\n",
      " [ 0.20963891]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.1707324 ]\n",
      " [ 2.0480487 ]\n",
      " [-2.0436494 ]\n",
      " [-0.12018888]\n",
      " [-0.16317411]\n",
      " [ 0.7809772 ]\n",
      " [ 1.1975583 ...-0.6096025 ]\n",
      " [-2.354262  ]\n",
      " [ 0.7391591 ]\n",
      " [ 1.8082628 ]\n",
      " [-0.10308614]\n",
      " [-1.153433  ]\n",
      " [ 0.20963891]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458909430>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.1707324 ]\n",
      " [ 2.0480487 ]\n",
      " [-2.0436494 ]\n",
      " [-0.12018888]\n",
      " [-0.16317411]\n",
      " [ 0.7809772 ]\n",
      " [ 1.1975583 ]\n",
      " [-0.56814206]\n",
      " [-0.6096025 ]\n",
      " [-2.354262  ]\n",
      " [ 0.7391591 ]\n",
      " [ 1.8082628 ]\n",
      " [-0.10308614]\n",
      " [-1.153433  ]\n",
      " [ 0.20963891]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-1.92037895e-01 -3.18330437e-01 -2.48499453e-01  1.28204361e-01\n",
      "  -2.45868430e-01  5.16430996e-02  2.4...02 -2.12709215e-02 -3.22259665e-02  3.42937335e-02\n",
      "   1.44892959e-02 -4.47215885e-02  4.87223193e-02  5.68923950e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb458909430>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.26851413 -0.15995128 -0.17984504 -0.06974173  0.24491775  0.22710723\n",
      "   0.27733773  0.01316291 -0.2...27304   0.01404348  0.22403002 -0.13618776\n",
      "  -0.11025441 -0.2438708   0.14434299  0.1680991   0.21563101 -0.25567874]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.26851413 -0.15995128 -0.17984504 -0.06974173  0.24491775  0.22710723\n",
      "   0.27733773  0.01316291 -0.... 0.01404348  0.22403002 -0.13618776\n",
      "  -0.11025441 -0.2438708   0.14434299  0.1680991   0.21563101 -0.25567874]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb461f69280>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.26851413 -0.15995128 -0.17984504 -0.06974173  0.24491775  0.22710723\n",
      "   0.27733773  0.01316291 -0.... 0.01404348  0.22403002 -0.13618776\n",
      "  -0.11025441 -0.2438708   0.14434299  0.1680991   0.21563101 -0.25567874]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb461f69280>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461f69dc0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb461f69dc0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb461f69ca0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb461f69ca0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-12-1-15-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-2.180204  , -1.1964362 ,  1.594881  , -1.7045511 ,\n",
      "          0.5768251 , -0.5863124 ,  1.7138518 , -0.567992...062168 ,  1.7470506 , -0.8868107 ,\n",
      "         -0.15188123,  0.04239094,  0.32221314, -0.02510654]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-3.0182e-01, -3.5139e-01, -1.3199e-01, -6.3415e-02, -1.5756e-01,\n",
      "           6.7781e-02,  4.7427e-02,  4.6248...3, -2.3118e-03, -2.4476e-03,  3.3840e-03,  5.6781e-03,\n",
      "          -1.1732e-02, -5.5854e-03]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 1.5728221 , -0.6576504 , -2.2767677 ,  1.1579803 ,\n",
      "         -1.4337167 ,  0.8481366 ,  0.63893616,  1.585585...463831 , -1.3934075 ,  0.6575226 ,\n",
      "          0.8293907 , -0.21849482,  1.1719683 , -1.34379   ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-1.3675e-01, -1.6145e-01, -7.1418e-02, -2.9241e-02, -8.9228e-02,\n",
      "           3.6332e-02,  2.5919e-02,  2.2796...3, -1.1451e-03, -1.2275e-03,  1.6772e-03,  2.8199e-03,\n",
      "          -5.8371e-03, -2.7851e-03]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb461fa6a60>\n",
      "model_     = LSTM(1, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.0623,  0.0575,  0.0323,  ...,  0.0240, -0.0204, -0.0181],\n",
      "         [-0.0569, -0.0544, -0.0326,  ..., -0.0...03,  0.0228],\n",
      "         [ 0.0096,  0.0098,  0.0048,  ...,  0.0028, -0.0058, -0.0028]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 9.47858989e-01],\n",
      "        [-7.74062991e-01],\n",
      "        [-9.00641203e-01],\n",
      "        [ 1.84333181e+00],\n",
      "        [ ...   [-1.14882004e+00],\n",
      "        [ 6.43927455e-01],\n",
      "        [-1.09156048e+00],\n",
      "        [ 9.69446972e-02]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 9.47858989e-01]\n",
      "  [-7.74062991e-01]\n",
      "  [-9.00641203e-01]\n",
      "  [ 1.84333181e+00]\n",
      "  [ 1.53017485e+00]\n",
      "  [...4459e-01]\n",
      "  [ 1.16351195e-01]\n",
      "  [-1.14882004e+00]\n",
      "  [ 6.43927455e-01]\n",
      "  [-1.09156048e+00]\n",
      "  [ 9.69446972e-02]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461fa6a60>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 9.47858989e-01]\n",
      "  [-7.74062991e-01]\n",
      "  [-9.00641203e-01]\n",
      "  [ 1.84333181e+00]\n",
      "  [ 1.53017485e+00]\n",
      "  [-... 3.81184459e-01]\n",
      "  [ 1.16351195e-01]\n",
      "  [-1.14882004e+00]\n",
      "  [ 6.43927455e-01]\n",
      "  [-1.09156048e+00]\n",
      "  [ 9.69446972e-02]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb461fa6a60>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 0.947859  ]\n",
      " [-0.774063  ]\n",
      " [-0.9006412 ]\n",
      " [ 1.8433318 ]\n",
      " [ 1.5301749 ]\n",
      " [-0.55411...0.3831479 ]\n",
      " [-0.62134665]\n",
      " [ 0.38118446]\n",
      " [ 0.11635119]\n",
      " [-1.14882   ]\n",
      " [ 0.64392745]\n",
      " [-1.0915605 ]\n",
      " [ 0.0969447 ]]))\n",
      "        y          = needle.Tensor([[ 0.947859  ]\n",
      " [-0.774063  ]\n",
      " [-0.9006412 ]\n",
      " [ 1.8433318 ]\n",
      " [ 1.5301749 ]\n",
      " [-0.55411595]\n",
      " [-0.96293104]\n",
      " [ 0.35726258]\n",
      " [ 1.0451254 ]\n",
      " [ 0.7947111 ]\n",
      " [ 1.0555716 ]\n",
      " [ 0.64329237]\n",
      " [ 1.8116248 ]\n",
      " [-0.3838565 ]\n",
      " [ 1.799023  ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 0.947859  ]\n",
      " [-0.774063  ]\n",
      " [-0.9006412 ]\n",
      " [ 1.8433318 ]\n",
      " [ 1.5301749 ]\n",
      " [-0.55411595]\n",
      " [-0.96293104... 1.0451254 ]\n",
      " [ 0.7947111 ]\n",
      " [ 1.0555716 ]\n",
      " [ 0.64329237]\n",
      " [ 1.8116248 ]\n",
      " [-0.3838565 ]\n",
      " [ 1.799023  ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461fa6e20>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 0.947859  ]\n",
      " [-0.774063  ]\n",
      " [-0.9006412 ]\n",
      " [ 1.8433318 ]\n",
      " [ 1.5301749 ]\n",
      " [-0.55411595]\n",
      " [-0.96293104]\n",
      " [ 0.35726258]\n",
      " [ 1.0451254 ]\n",
      " [ 0.7947111 ]\n",
      " [ 1.0555716 ]\n",
      " [ 0.64329237]\n",
      " [ 1.8116248 ]\n",
      " [-0.3838565 ]\n",
      " [ 1.799023  ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.18122712 -0.21903645 -0.03523341 -0.22429504 -0.11359982 -0.10757288\n",
      "  -0.20019583 -0.04622229  0.2...137476  0.25543633 -0.5058536  -0.25310794\n",
      "  -0.34368747  0.13079229 -0.3624132  -0.28793132 -0.20890287 -0.12251549]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461fa6e20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.07048091 -0.28004175 -0.08145186  0.17371175 -0.2589513  -0.18187311\n",
      "   0.00625914 -0.25308976  0.1...297635 -0.10451859 -0.13881768  0.10196111\n",
      "   0.15135586 -0.2207355   0.13336158  0.12882453 -0.13674824  0.2169761 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.07048091 -0.28004175 -0.08145186  0.17371175 -0.2589513  -0.18187311\n",
      "   0.00625914 -0.25308976  0....-0.10451859 -0.13881768  0.10196111\n",
      "   0.15135586 -0.2207355   0.13336158  0.12882453 -0.13674824  0.2169761 ]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4300f9700>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.07048091 -0.28004175 -0.08145186  0.17371175 -0.2589513  -0.18187311\n",
      "   0.00625914 -0.25308976  0....-0.10451859 -0.13881768  0.10196111\n",
      "   0.15135586 -0.2207355   0.13336158  0.12882453 -0.13674824  0.2169761 ]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4300f9700>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4300f9c40>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4300f9c40>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4300f9460>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4300f9460>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-12-1-15-2-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 2.22016168e+00,  6.42430544e-01,  8.86360332e-02,\n",
      "          5.56245744e-01,  7.64068604e-01,  9.48336005e-01...,  7.81845987e-01,  1.58889353e+00,\n",
      "          9.77628052e-01, -5.92158139e-02, -1.48091543e+00]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 2.0440e-02, -3.4904e-02,  1.9658e-02, -2.1444e-02,  1.9536e-02,\n",
      "           2.9158e-02,  2.0288e-02, -1.3135...3, -1.2192e-03, -3.6193e-04, -1.3863e-03,  4.1652e-04,\n",
      "           2.1439e-04,  1.0145e-03]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 2.4800355 , -2.5380259 , -0.21063003,  0.66644156,\n",
      "          0.22283271, -0.05431047, -0.48998556, -0.146765...755188 ,  0.70237696, -0.65468365,\n",
      "         -0.58069086,  0.1437282 ,  0.11264542, -0.8804181 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 1.0050e-02, -1.8120e-02,  1.0067e-02, -1.0375e-02,  1.0114e-02,\n",
      "           1.4335e-02,  9.9640e-03, -6.3951...3, -6.0885e-04, -1.8118e-04, -6.9504e-04,  2.0879e-04,\n",
      "           1.0721e-04,  5.0716e-04]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb462560130>\n",
      "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 1.2975e-03, -1.9955e-03,  3.6739e-04, -1.8538e-03,  1.6467e-03,\n",
      "          -2.0913e-03,  9.2506e-04,  6.2153...3, -6.0885e-04, -1.8118e-04, -6.9504e-04,  2.0879e-04,\n",
      "           1.0721e-04,  5.0716e-04]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-0.27595338],\n",
      "        [-0.46668157],\n",
      "        [ 0.345803  ],\n",
      "        [-0.6319354 ],\n",
      "        [ 2.0746624 ],\n",
      "   ...5303844 ],\n",
      "        [ 0.08351691],\n",
      "        [-2.000528  ],\n",
      "        [-0.33822903],\n",
      "        [ 0.19277757]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.27595338]\n",
      "  [-0.46668157]\n",
      "  [ 0.345803  ]\n",
      "  [-0.6319354 ]\n",
      "  [ 2.0746624 ]\n",
      "  [ 0.52526593]\n",
      "  [-0.4...[ 0.7945154 ]\n",
      "  [ 0.47468138]\n",
      "  [ 0.5303844 ]\n",
      "  [ 0.08351691]\n",
      "  [-2.000528  ]\n",
      "  [-0.33822903]\n",
      "  [ 0.19277757]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb462560130>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-0.27595338]\n",
      "  [-0.46668157]\n",
      "  [ 0.345803  ]\n",
      "  [-0.6319354 ]\n",
      "  [ 2.0746624 ]\n",
      "  [ 0.52526593]\n",
      "  [-0.45...276]\n",
      "  [ 0.7945154 ]\n",
      "  [ 0.47468138]\n",
      "  [ 0.5303844 ]\n",
      "  [ 0.08351691]\n",
      "  [-2.000528  ]\n",
      "  [-0.33822903]\n",
      "  [ 0.19277757]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb462560130>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.27595338]\n",
      " [-0.46668157]\n",
      " [ 0.345803  ]\n",
      " [-0.6319354 ]\n",
      " [ 2.0746624 ]\n",
      " [ 0.52526....01034276]\n",
      " [ 0.7945154 ]\n",
      " [ 0.47468138]\n",
      " [ 0.5303844 ]\n",
      " [ 0.08351691]\n",
      " [-2.000528  ]\n",
      " [-0.33822903]\n",
      " [ 0.19277757]]),)\n",
      "        y          = needle.Tensor([[-0.27595338]\n",
      " [-0.46668157]\n",
      " [ 0.345803  ]\n",
      " [-0.6319354 ]\n",
      " [ 2.0746624 ]\n",
      " [ 0.52526593]\n",
      " [-0.45529857]\n",
      " [ 0.01034276]\n",
      " [ 0.7945154 ]\n",
      " [ 0.47468138]\n",
      " [ 0.5303844 ]\n",
      " [ 0.08351691]\n",
      " [-2.000528  ]\n",
      " [-0.33822903]\n",
      " [ 0.19277757]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.27595338]\n",
      " [-0.46668157]\n",
      " [ 0.345803  ]\n",
      " [-0.6319354 ]\n",
      " [ 2.0746624 ]\n",
      " [ 0.52526593]\n",
      " [-0.45529857... 0.7945154 ]\n",
      " [ 0.47468138]\n",
      " [ 0.5303844 ]\n",
      " [ 0.08351691]\n",
      " [-2.000528  ]\n",
      " [-0.33822903]\n",
      " [ 0.19277757]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462560520>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.27595338]\n",
      " [-0.46668157]\n",
      " [ 0.345803  ]\n",
      " [-0.6319354 ]\n",
      " [ 2.0746624 ]\n",
      " [ 0.52526593]\n",
      " [-0.45529857]\n",
      " [ 0.01034276]\n",
      " [ 0.7945154 ]\n",
      " [ 0.47468138]\n",
      " [ 0.5303844 ]\n",
      " [ 0.08351691]\n",
      " [-2.000528  ]\n",
      " [-0.33822903]\n",
      " [ 0.19277757]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-7.42051601e-02  6.23084009e-02  4.45606150e-02  6.29317164e-02\n",
      "   7.91569278e-02 -7.37784803e-02  8.3...02  2.30100695e-02  2.46352479e-02  3.66880819e-02\n",
      "  -1.53001975e-02 -3.37867551e-02  1.12844724e-03 -3.05180997e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb462560520>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 0.14781952 -0.27852404  0.06122649  0.07221681  0.10048252  0.19843018\n",
      "  -0.07204889  0.2287094   0.0...658812 -0.16041896 -0.11850071 -0.10813159\n",
      "   0.0958131  -0.22795661  0.26252735  0.02617183  0.20353723  0.07257232]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 0.14781952 -0.27852404  0.06122649  0.07221681  0.10048252  0.19843018\n",
      "  -0.07204889  0.2287094   0....-0.16041896 -0.11850071 -0.10813159\n",
      "   0.0958131  -0.22795661  0.26252735  0.02617183  0.20353723  0.07257232]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb450f53fd0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 0.14781952 -0.27852404  0.06122649  0.07221681  0.10048252  0.19843018\n",
      "  -0.07204889  0.2287094   0....-0.16041896 -0.11850071 -0.10813159\n",
      "   0.0958131  -0.22795661  0.26252735  0.02617183  0.20353723  0.07257232]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb450f53fd0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450f53d00>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb450f53d00>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb450f53ac0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb450f53ac0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-12-1-15-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 0.52529794, -0.3885926 , -0.07556921, -1.498086  ,\n",
      "         -1.1872572 , -0.8596038 , -1.3522557 , -0.531872...8960952, -0.47963536,  0.36378953,\n",
      "          0.27076274,  0.25560588, -0.5540936 , -0.6558661 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-9.0744e-02, -1.2902e-01,  1.7880e-01,  8.5370e-02,  2.0259e-01,\n",
      "          -1.4553e-01, -6.9182e-03, -1.4764...2, -5.0072e-03, -8.6166e-03,  2.3058e-02, -6.5698e-02,\n",
      "          -3.7333e-02, -6.8583e-03]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-2.8096957 ,  0.78234345, -0.6506097 , -1.3245332 ,\n",
      "         -1.2402136 , -0.6714447 ,  0.03518194,  0.472917...2830185,  2.5219002 ,  0.3823822 ,\n",
      "         -2.0664237 , -0.9636579 , -0.79323494, -1.1592146 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-4.5479e-02, -6.5113e-02,  8.0516e-02,  4.2956e-02,  9.6291e-02,\n",
      "          -7.7763e-02, -3.0724e-03, -6.8220...3, -2.4791e-03, -4.4061e-03,  1.1469e-02, -3.2976e-02,\n",
      "          -1.8147e-02, -3.4476e-03]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 1\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4620dca00>\n",
      "model_     = LSTM(1, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-2.1891e-04,  6.3177e-03, -6.1024e-03,  ..., -1.1831e-02,\n",
      "          -6.3711e-03, -4.4783e-03],\n",
      "         [-1....3026e-03,  1.0896e-02, -4.9965e-03,  ..., -3.2976e-02,\n",
      "          -1.8147e-02, -3.4476e-03]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.86793715],\n",
      "        [-0.95407975],\n",
      "        [ 1.4998366 ],\n",
      "        [-0.8330298 ],\n",
      "        [ 0.15546101],\n",
      "   ...2766148 ],\n",
      "        [ 0.38629317],\n",
      "        [ 0.11284703],\n",
      "        [-0.44013944],\n",
      "        [-0.2569959 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.86793715]\n",
      "  [-0.95407975]\n",
      "  [ 1.4998366 ]\n",
      "  [-0.8330298 ]\n",
      "  [ 0.15546101]\n",
      "  [ 0.4215795 ]\n",
      "  [-0.6...[ 0.02544577]\n",
      "  [-0.01270822]\n",
      "  [-1.2766148 ]\n",
      "  [ 0.38629317]\n",
      "  [ 0.11284703]\n",
      "  [-0.44013944]\n",
      "  [-0.2569959 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4620dca00>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 1\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.86793715]\n",
      "  [-0.95407975]\n",
      "  [ 1.4998366 ]\n",
      "  [-0.8330298 ]\n",
      "  [ 0.15546101]\n",
      "  [ 0.4215795 ]\n",
      "  [-0.61...98 ]\n",
      "  [ 0.02544577]\n",
      "  [-0.01270822]\n",
      "  [-1.2766148 ]\n",
      "  [ 0.38629317]\n",
      "  [ 0.11284703]\n",
      "  [-0.44013944]\n",
      "  [-0.2569959 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4620dca00>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.86793715]\n",
      " [-0.95407975]\n",
      " [ 1.4998366 ]\n",
      " [-0.8330298 ]\n",
      " [ 0.15546101]\n",
      " [ 0.42157...3.3841398 ]\n",
      " [ 0.02544577]\n",
      " [-0.01270822]\n",
      " [-1.2766148 ]\n",
      " [ 0.38629317]\n",
      " [ 0.11284703]\n",
      " [-0.44013944]\n",
      " [-0.2569959 ]]))\n",
      "        y          = needle.Tensor([[-0.86793715]\n",
      " [-0.95407975]\n",
      " [ 1.4998366 ]\n",
      " [-0.8330298 ]\n",
      " [ 0.15546101]\n",
      " [ 0.4215795 ]\n",
      " [-0.6111579 ]\n",
      " [-0.75739145]\n",
      " [-0.64881   ]\n",
      " [ 2.0011625 ]\n",
      " [-0.7732367 ]\n",
      " [ 0.30158138]\n",
      " [-0.29752684]\n",
      " [-0.15471792]\n",
      " [ 0.29058436]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.86793715]\n",
      " [-0.95407975]\n",
      " [ 1.4998366 ]\n",
      " [-0.8330298 ]\n",
      " [ 0.15546101]\n",
      " [ 0.4215795 ]\n",
      " [-0.6111579 ...-0.64881   ]\n",
      " [ 2.0011625 ]\n",
      " [-0.7732367 ]\n",
      " [ 0.30158138]\n",
      " [-0.29752684]\n",
      " [-0.15471792]\n",
      " [ 0.29058436]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4620dc370>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.86793715]\n",
      " [-0.95407975]\n",
      " [ 1.4998366 ]\n",
      " [-0.8330298 ]\n",
      " [ 0.15546101]\n",
      " [ 0.4215795 ]\n",
      " [-0.6111579 ]\n",
      " [-0.75739145]\n",
      " [-0.64881   ]\n",
      " [ 2.0011625 ]\n",
      " [-0.7732367 ]\n",
      " [ 0.30158138]\n",
      " [-0.29752684]\n",
      " [-0.15471792]\n",
      " [ 0.29058436]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 0.12529562  0.01849044 -0.09337602  0.05480992 -0.15945975  0.0831625\n",
      "  -0.05985624  0.21410008  0.24...993131  0.00557603 -0.02128853  0.04889322\n",
      "  -0.06816745 -0.04517924 -0.08036616  0.02415425  0.00520812  0.04708034]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4620dc370>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.04177465  0.0940243  -0.05115835 -0.15348265  0.24420679 -0.22931433\n",
      "   0.07115558 -0.19227174  0.1...850472  0.13798273  0.27063334  0.22335857\n",
      "   0.16530466 -0.20487049  0.26648962 -0.1811972  -0.25674605  0.16274002]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.04177465  0.0940243  -0.05115835 -0.15348265  0.24420679 -0.22931433\n",
      "   0.07115558 -0.19227174  0.... 0.13798273  0.27063334  0.22335857\n",
      "   0.16530466 -0.20487049  0.26648962 -0.1811972  -0.25674605  0.16274002]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb458ae98b0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.04177465  0.0940243  -0.05115835 -0.15348265  0.24420679 -0.22931433\n",
      "   0.07115558 -0.19227174  0.... 0.13798273  0.27063334  0.22335857\n",
      "   0.16530466 -0.20487049  0.26648962 -0.1811972  -0.25674605  0.16274002]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb458ae98b0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458ae9d60>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458ae9d60>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb458ae9b80>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb458ae9b80>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-12-11-1-1-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.62202483, -0.17474622,  0.32656762, -0.7162409 ,\n",
      "         -0.40964434, -0.5473378 , -1.3186476 , -1.1436756 ,\n",
      "         -0.31882465, -0.28417546, -2.0688784 ,  0.44391727]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.0150,  0.1769, -0.5232,  0.0527, -0.0572,  0.5220,  0.1255,\n",
      "          -0.1721,  0.0576, -0.1956,  0.2676,  0.6342]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.7594708 ,  1.1340468 , -0.5428031 ,  0.14637473,\n",
      "         -0.97899085, -0.6122304 ,  1.2276706 ,  1.2678214 ,\n",
      "         -0.25049466,  1.76458   ,  0.18467732, -0.2941469 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0100,  0.1012, -0.0660,  0.0167, -0.0384,  0.2376,  0.0617,\n",
      "          -0.1117,  0.0351, -0.1368,  0.1287,  0.2013]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4623a5820>\n",
      "model_     = LSTM(11, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[-0.0100,  0.1012, -0.0660,  0.0167, -0.0384,  0.2376,  0.0617,\n",
      "          -0.1117,  0.0351, -0.1368,  0.1287,  0.2013]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.3202277 , -1.6516143 ,  1.9708707 ,  1.0512873 ,\n",
      "         -1.8735934 , -1.34928   , -1.0819954 ,  0.86870784,\n",
      "         -0.0339466 ,  1.4152277 , -1.2714384 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.3202277  -1.6516143   1.9708707   1.0512873  -1.8735934\n",
      "   -1.34928    -1.0819954   0.86870784 -0.0339466   1.4152277\n",
      "   -1.2714384 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4623a5820>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.3202277  -1.6516143   1.9708707   1.0512873  -1.8735934\n",
      "   -1.34928    -1.0819954   0.86870784 -0.0339466   1.4152277\n",
      "   -1.2714384 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4623a5820>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.3202277  -1.6516143   1.9708707   1.0512873  -1.8735934  -1.34928\n",
      "  -1.0819954   0.86870784 -0.0339466   1.4152277  -1.2714384 ]]),)\n",
      "        y          = needle.Tensor([[-1.3202277  -1.6516143   1.9708707   1.0512873  -1.8735934  -1.34928\n",
      "  -1.0819954   0.86870784 -0.0339466   1.4152277  -1.2714384 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.3202277  -1.6516143   1.9708707   1.0512873  -1.8735934  -1.34928\n",
      "  -1.0819954   0.86870784 -0.0339466   1.4152277  -1.2714384 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4623a52e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.3202277  -1.6516143   1.9708707   1.0512873  -1.8735934  -1.34928\n",
      "  -1.0819954   0.86870784 -0.0339466   1.4152277  -1.2714384 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.50336975 -0.5204564   0.43814492 -1.6561012  -1.0941454   0.5488844\n",
      "   0.26755083 -1.034469   -0.50...63078  -0.7662307   0.7193995  -0.01691184\n",
      "  -0.02359781  0.6442164   0.44986233  0.88746476 -0.03096249 -0.5800825 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4623a52e0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 9.20652747e-02  1.40527487e-01 -7.74136633e-02  1.76373869e-01\n",
      "  -1.74205214e-01 -2.05855876e-01  1.2...01  1.75934941e-01 -4.38752621e-02 -1.80158868e-01\n",
      "  -1.31134421e-01  1.86560750e-02  2.65003324e-01  2.22458780e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 9.20652747e-02  1.40527487e-01 -7.74136633e-02  1.76373869e-01\n",
      "  -1.74205214e-01 -2.05855876e-01  1....5934941e-01 -4.38752621e-02 -1.80158868e-01\n",
      "  -1.31134421e-01  1.86560750e-02  2.65003324e-01  2.22458780e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb438488ee0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 9.20652747e-02  1.40527487e-01 -7.74136633e-02  1.76373869e-01\n",
      "  -1.74205214e-01 -2.05855876e-01  1....5934941e-01 -4.38752621e-02 -1.80158868e-01\n",
      "  -1.31134421e-01  1.86560750e-02  2.65003324e-01  2.22458780e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb438488ee0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb438488730>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb438488730>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb438488310>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb438488310>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-12-11-1-1-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[ 1.28645670e+00,  1.20103337e-01,  8.82885635e-01,\n",
      "         -9.13667679e-02, -1.50582846e-03,  7.79770911e-01...,  1.71587849e+00,  6.83206260e-01,\n",
      "         -4.65910852e-01,  1.07850015e-01,  3.98707658e-01]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-0.1799, -0.0399, -0.4251,  0.0050,  0.2377, -0.3377, -0.0023,\n",
      "           0.1980,  0.0052, -0.1414,  0.2397,  0.2167]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.7080381 , -1.7734174 ,  1.0009623 , -0.21489802,\n",
      "          0.42454484,  0.2178466 ,  0.46813866,  0.22489902,\n",
      "         -0.7255407 , -0.31521836, -0.35455173,  0.78731537]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-0.0846, -0.0188, -0.1756,  0.0020,  0.0913, -0.1119, -0.0012,\n",
      "           0.1109,  0.0017, -0.1030,  0.1155,  0.1075]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4617b0af0>\n",
      "model_     = LSTM(11, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.0736,  0.0294, -0.1656, -0.3247, -0.0749, -0.1515, -0.0269,\n",
      "          -0.1303,  0.1799,  0.0515, -0.0948,...,  0.0913, -0.1119, -0.0012,\n",
      "           0.1109,  0.0017, -0.1030,  0.1155,  0.1075]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[ 1.3081621 ,  0.22765912, -0.7149543 ,  0.31758368,\n",
      "         -1.445905  , -0.80702543,  1.7414559 , -1.731612...   0.67714614, -1.0575924 , -0.29659292, -0.68107235,\n",
      "          0.06045422,  1.1882393 ,  1.2936078 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.3081621   0.22765912 -0.7149543   0.31758368 -1.445905\n",
      "   -0.80702543  1.7414559  -1.7316129   0....27347   -0.03232171  0.67714614\n",
      "   -1.0575924  -0.29659292 -0.68107235  0.06045422  1.1882393\n",
      "    1.2936078 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617b0af0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[ 1.3081621   0.22765912 -0.7149543   0.31758368 -1.445905\n",
      "   -0.80702543  1.7414559  -1.7316129   0.6...47  0.127347   -0.03232171  0.67714614\n",
      "   -1.0575924  -0.29659292 -0.68107235  0.06045422  1.1882393\n",
      "    1.2936078 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4617b0af0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.3081621   0.22765912 -0.7149543   0.31758368 -1.445905   -0.80702543\n",
      "   1.741455...744747  0.127347   -0.03232171  0.67714614 -1.0575924\n",
      "  -0.29659292 -0.68107235  0.06045422  1.1882393   1.2936078 ]]))\n",
      "        y          = needle.Tensor([[ 1.3081621   0.22765912 -0.7149543   0.31758368 -1.445905   -0.80702543\n",
      "   1.7414559  -1.7316129   0.64747024 -0.6959753  -1.0797721 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.3081621   0.22765912 -0.7149543   0.31758368 -1.445905   -0.80702543\n",
      "   1.7414559  -1.7316129   0.64747024 -0.6959753  -1.0797721 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4617b09d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 1.3081621   0.22765912 -0.7149543   0.31758368 -1.445905   -0.80702543\n",
      "   1.7414559  -1.7316129   0.64747024 -0.6959753  -1.0797721 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.6604914   0.09742122 -0.3964405   0.46722296 -1.1331928  -0.4743996\n",
      "  -0.77542764  0.25190976  0.59...81082   1.081445    0.48235035  0.14732632\n",
      "   0.96477425 -0.8601686   0.471105   -0.5694618  -0.1907976   0.6270682 ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4617b09d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.64018804e-01  1.42979056e-01  2.07413226e-01 -2.45803058e-01\n",
      "  -2.21694797e-01  2.61721313e-01  5.5...01  1.66702151e-01  1.63004607e-01 -1.21877804e-01\n",
      "  -1.98611885e-01 -1.65695399e-01  9.63396430e-02  1.35055810e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.64018804e-01  1.42979056e-01  2.07413226e-01 -2.45803058e-01\n",
      "  -2.21694797e-01  2.61721313e-01  5....6702151e-01  1.63004607e-01 -1.21877804e-01\n",
      "  -1.98611885e-01 -1.65695399e-01  9.63396430e-02  1.35055810e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb458caa670>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.64018804e-01  1.42979056e-01  2.07413226e-01 -2.45803058e-01\n",
      "  -2.21694797e-01  2.61721313e-01  5....6702151e-01  1.63004607e-01 -1.21877804e-01\n",
      "  -1.98611885e-01 -1.65695399e-01  9.63396430e-02  1.35055810e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb458caa670>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458caa0d0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb458caa0d0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb458caa640>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb458caa640>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m___________________ test_lstm[metal-False-False-12-11-1-2-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[-0.5960601 , -1.6529744 ,  0.1259313 ,  0.8103501 ,\n",
      "         -1.5366987 , -0.2296902 ,  0.7738455 ,  0.617758...323484 ,  0.4486708 ,  0.9362977 ,\n",
      "         -0.83289945,  1.1140821 ,  1.0428528 , -1.223381  ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0240, -0.4293,  0.5329,  0.0856, -0.1202,  0.3816,  0.3041,\n",
      "          -0.2954,  0.3719, -0.3666,  0.2401,...,  0.0139,  0.0037,  0.1167,\n",
      "           0.0155,  0.0168,  0.0070, -0.0207,  0.1046]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.24782506, -1.0652966 ,  1.0731783 , -0.32380503,\n",
      "          0.23706283,  0.8051166 , -1.4214153 ,  0.885663...4009013, -0.6660866 ,  0.164242  ,\n",
      "         -1.0747957 ,  0.817893  ,  0.7243501 , -0.7052702 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0180, -0.2904,  0.3001,  0.0616, -0.0726,  0.1840,  0.0822,\n",
      "          -0.0424,  0.1608, -0.1193,  0.0844,...,  0.0075,  0.0019,  0.0536,\n",
      "           0.0080,  0.0085,  0.0038, -0.0104,  0.0519]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4615688e0>\n",
      "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[-0.0162, -0.0143,  0.0278, -0.0210,  0.0075,  0.0019,  0.0536,\n",
      "           0.0080,  0.0085,  0.0038, -0.0104,  0.0519]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 1.1785101 ,  0.15288624, -2.014001  , -0.29361963,\n",
      "          0.648528  ,  1.3985448 ,  0.09225406, -0.23519841,\n",
      "         -0.29943126, -3.0118244 , -1.3184309 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.1785101   0.15288624 -2.014001   -0.29361963  0.648528\n",
      "    1.3985448   0.09225406 -0.23519841 -0.29943126 -3.0118244\n",
      "   -1.3184309 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4615688e0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 1.1785101   0.15288624 -2.014001   -0.29361963  0.648528\n",
      "    1.3985448   0.09225406 -0.23519841 -0.29943126 -3.0118244\n",
      "   -1.3184309 ]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4615688e0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.1785101   0.15288624 -2.014001   -0.29361963  0.648528    1.3985448\n",
      "   0.09225406 -0.23519841 -0.29943126 -3.0118244  -1.3184309 ]]),)\n",
      "        y          = needle.Tensor([[ 1.1785101   0.15288624 -2.014001   -0.29361963  0.648528    1.3985448\n",
      "   0.09225406 -0.23519841 -0.29943126 -3.0118244  -1.3184309 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.1785101   0.15288624 -2.014001   -0.29361963  0.648528    1.3985448\n",
      "   0.09225406 -0.23519841 -0.29943126 -3.0118244  -1.3184309 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461568c70>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 1.1785101   0.15288624 -2.014001   -0.29361963  0.648528    1.3985448\n",
      "   0.09225406 -0.23519841 -0.29943126 -3.0118244  -1.3184309 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 1.2616836   1.1506124   0.3004106  -1.0490867   0.55297226  0.15395808\n",
      "  -0.47512227 -0.06701582  0.1...010666  0.94825745  0.43340996  0.02080907\n",
      "  -0.9517245  -1.7540355  -0.19194438 -0.66364616 -0.58333325 -0.877815  ]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb461568c70>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-1.19142920e-01  5.51723838e-02  3.21714878e-02 -4.56162393e-02\n",
      "  -1.67036220e-01 -2.61293858e-01  9.0...01  5.51656485e-02 -7.98246562e-02 -3.81252766e-02\n",
      "  -1.67356163e-01  2.14368403e-02  2.77257740e-01  4.88218665e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-1.19142920e-01  5.51723838e-02  3.21714878e-02 -4.56162393e-02\n",
      "  -1.67036220e-01 -2.61293858e-01  9....1656485e-02 -7.98246562e-02 -3.81252766e-02\n",
      "  -1.67356163e-01  2.14368403e-02  2.77257740e-01  4.88218665e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480d83910>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-1.19142920e-01  5.51723838e-02  3.21714878e-02 -4.56162393e-02\n",
      "  -1.67036220e-01 -2.61293858e-01  9....1656485e-02 -7.98246562e-02 -3.81252766e-02\n",
      "  -1.67356163e-01  2.14368403e-02  2.77257740e-01  4.88218665e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480d83910>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480d83f10>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480d83f10>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480d834f0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480d834f0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-12-11-1-2-13] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 1\n",
      "bias       = False\n",
      "c0         = array([[[ 0.5235556 ,  1.4519761 ,  0.4207088 ,  0.7944211 ,\n",
      "         -2.0089061 , -0.06907614,  0.25301278, -1.386807...3405805,  0.11471681,  0.59725624,\n",
      "         -1.7916528 ,  0.87781256, -0.4488952 ,  1.5402335 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0374, -0.1094, -0.1880, -0.1632, -0.0584,  0.4268,  0.0143,\n",
      "           0.0867,  0.3719, -0.5364, -0.2691,..., -0.1164,  0.0820, -0.1290,\n",
      "           0.1728, -0.0336, -0.0242, -0.0625, -0.0669]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-1.16048254e-01,  9.53590274e-02,  1.36963964e+00,\n",
      "          2.39579812e-01, -6.34990990e-01, -5.50421596e-01...,  1.55404043e+00, -4.66056075e-03,\n",
      "         -1.02554905e+00, -5.61658740e-01,  2.15722159e-01]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0110, -0.0433, -0.1335, -0.1008, -0.0399,  0.1094,  0.0041,\n",
      "           0.0230,  0.2378, -0.3235, -0.1967,..., -0.0591,  0.0398, -0.0640,\n",
      "           0.0840, -0.0166, -0.0123, -0.0339, -0.0331]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb4719d5940>\n",
      "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0029,  0.0127, -0.0038,  0.0063, -0.0032,  0.0060,  0.0035,\n",
      "          -0.0192,  0.0201, -0.0018,  0.0030,..., -0.0591,  0.0398, -0.0640,\n",
      "           0.0840, -0.0166, -0.0123, -0.0339, -0.0331]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.5531745 , -0.6069268 , -0.7165308 , -0.42637902,\n",
      "          0.7544807 , -0.65590763,  2.2328146 , -0.456366...  -1.2111838 , -0.11869977,  1.9479902 ,  1.7157844 ,\n",
      "         -0.81765187,  0.48117965,  0.74203646]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.5531745  -0.6069268  -0.7165308  -0.42637902  0.7544807\n",
      "   -0.65590763  2.2328146  -0.45636666  1...05662    0.4571832  -1.2111838\n",
      "   -0.11869977  1.9479902   1.7157844  -0.81765187  0.48117965\n",
      "    0.74203646]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4719d5940>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.5531745  -0.6069268  -0.7165308  -0.42637902  0.7544807\n",
      "   -0.65590763  2.2328146  -0.45636666  1....3  -1.605662    0.4571832  -1.2111838\n",
      "   -0.11869977  1.9479902   1.7157844  -0.81765187  0.48117965\n",
      "    0.74203646]]])\n",
      "        Y          = []\n",
      "        bs         = 1\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4719d5940>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.5531745  -0.6069268  -0.7165308  -0.42637902  0.7544807  -0.65590763\n",
      "   2.232814...9693  -1.605662    0.4571832  -1.2111838  -0.11869977\n",
      "   1.9479902   1.7157844  -0.81765187  0.48117965  0.74203646]]))\n",
      "        y          = needle.Tensor([[-0.5531745  -0.6069268  -0.7165308  -0.42637902  0.7544807  -0.65590763\n",
      "   2.2328146  -0.45636666  1.0025569  -1.5175352   0.58527106]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.5531745  -0.6069268  -0.7165308  -0.42637902  0.7544807  -0.65590763\n",
      "   2.2328146  -0.45636666  1.0025569  -1.5175352   0.58527106]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4719d5c40>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.5531745  -0.6069268  -0.7165308  -0.42637902  0.7544807  -0.65590763\n",
      "   2.2328146  -0.45636666  1.0025569  -1.5175352   0.58527106]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[-0.13396794 -0.28507346  0.37954968  0.5350664   0.84729064 -0.19780825\n",
      "   0.0511713   0.049982    0.4...54942   0.35915744  0.75090194  0.18846476\n",
      "  -0.3976718  -0.8738979   0.32989815 -0.10250646 -0.58178407  0.95390034]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4719d5c40>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.15191911  0.16544822 -0.2695375   0.21021289 -0.00414419 -0.20290278\n",
      "  -0.13769023  0.17017335 -0.2...088801  0.15760693 -0.14874057  0.10461882\n",
      "   0.09992456 -0.18360052  0.08629364 -0.09865759  0.03028828  0.09676516]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.15191911  0.16544822 -0.2695375   0.21021289 -0.00414419 -0.20290278\n",
      "  -0.13769023  0.17017335 -0.... 0.15760693 -0.14874057  0.10461882\n",
      "   0.09992456 -0.18360052  0.08629364 -0.09865759  0.03028828  0.09676516]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb480ee33a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.15191911  0.16544822 -0.2695375   0.21021289 -0.00414419 -0.20290278\n",
      "  -0.13769023  0.17017335 -0.... 0.15760693 -0.14874057  0.10461882\n",
      "   0.09992456 -0.18360052  0.08629364 -0.09865759  0.03028828  0.09676516]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb480ee33a0>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480ee3af0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb480ee3af0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb480ee34c0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb480ee34c0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-12-11-15-1-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 3.31116080e-01, -4.74382222e-01, -5.03839135e-01,\n",
      "          1.06337108e-01,  5.69015563e-01,  1.52112484e+00...,  8.85029435e-01,  1.17498982e+00,\n",
      "         -5.38340807e-01, -5.41401386e-01,  7.59239078e-01]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.1867, -0.1217,  0.1778, -0.3613,  0.2579,  0.0700, -0.1087,\n",
      "           0.0272, -0.0362, -0.0126, -0.3548,...,  0.1324,  0.0761, -0.0441,\n",
      "           0.2364,  0.2197,  0.1286, -0.0387,  0.0179]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.7114086 ,  2.2753131 ,  0.6733318 ,  1.4119148 ,\n",
      "         -0.21503337, -0.557712  , -0.5150989 , -0.193677...704397 ,  0.27648604, -0.88009274,\n",
      "          0.48050258,  0.20162064,  1.133734  , -0.48230022]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.1062, -0.0445,  0.0807, -0.1963,  0.1069,  0.0473, -0.0678,\n",
      "           0.0099, -0.0312, -0.0060, -0.2430,...,  0.0714,  0.0376, -0.0246,\n",
      "           0.1264,  0.0977,  0.0634, -0.0175,  0.0088]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb4725be1f0>\n",
      "model_     = LSTM(11, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.1062, -0.0445,  0.0807, -0.1963,  0.1069,  0.0473, -0.0678,\n",
      "           0.0099, -0.0312, -0.0060, -0.2430,...,  0.0714,  0.0376, -0.0246,\n",
      "           0.1264,  0.0977,  0.0634, -0.0175,  0.0088]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[-1.9002019 ,  0.49214518,  2.804969  , -0.5083032 ,\n",
      "          0.49754667, -1.4350648 ,  0.87604547, -0.897886...   0.79029095, -0.4853474 , -1.219057  , -0.1472957 ,\n",
      "          0.52252716, -0.04405449, -0.7907661 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-1.9002019   0.49214518  2.804969   -0.5083032   0.49754667\n",
      "   -1.4350648   0.87604547 -0.8978865   ...673424  0.4836535   0.79029095\n",
      "   -0.4853474  -1.219057   -0.1472957   0.52252716 -0.04405449\n",
      "   -0.7907661 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4725be1f0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[-1.9002019   0.49214518  2.804969   -0.5083032   0.49754667\n",
      "   -1.4350648   0.87604547 -0.8978865   0...5  0.45673424  0.4836535   0.79029095\n",
      "   -0.4853474  -1.219057   -0.1472957   0.52252716 -0.04405449\n",
      "   -0.7907661 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb4725be1f0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-1.9002019   0.49214518  2.804969   -0.5083032   0.49754667 -1.4350648\n",
      "   0.8760454...27155  0.45673424  0.4836535   0.79029095 -0.4853474\n",
      "  -1.219057   -0.1472957   0.52252716 -0.04405449 -0.7907661 ]]),)\n",
      "        y          = needle.Tensor([[-1.9002019   0.49214518  2.804969   -0.5083032   0.49754667 -1.4350648\n",
      "   0.87604547 -0.8978865   0.61...1227155  0.45673424  0.4836535   0.79029095 -0.4853474\n",
      "  -1.219057   -0.1472957   0.52252716 -0.04405449 -0.7907661 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-1.9002019   0.49214518  2.804969   -0.5083032   0.49754667 -1.4350648\n",
      "   0.87604547 -0.8978865   0.6...3424  0.4836535   0.79029095 -0.4853474\n",
      "  -1.219057   -0.1472957   0.52252716 -0.04405449 -0.7907661 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4725be370>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-1.9002019   0.49214518  2.804969   -0.5083032   0.49754667 -1.4350648\n",
      "   0.87604547 -0.8978865   0.61...1227155  0.45673424  0.4836535   0.79029095 -0.4853474\n",
      "  -1.219057   -0.1472957   0.52252716 -0.04405449 -0.7907661 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 8.85531843e-01 -2.89596409e-01 -4.73820092e-03  3.25357884e-01\n",
      "  -3.01737100e-01 -1.08462894e+00 -3.7...01 -2.02351566e-02  2.38243282e-01  1.79544300e-01\n",
      "  -1.92365825e-01 -1.69158783e-02 -1.90866470e-01 -2.19999887e-02]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4725be370>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[ 2.71702170e-01 -1.43941343e-01  2.84348786e-01 -2.71141171e-01\n",
      "   1.41202301e-01 -1.13544688e-01  1.6...02  2.30987906e-01 -2.39715248e-01 -2.70470411e-01\n",
      "   1.59967333e-01  1.61181390e-01  2.33140051e-01  5.07717431e-02]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[ 2.71702170e-01 -1.43941343e-01  2.84348786e-01 -2.71141171e-01\n",
      "   1.41202301e-01 -1.13544688e-01  1....0987906e-01 -2.39715248e-01 -2.70470411e-01\n",
      "   1.59967333e-01  1.61181390e-01  2.33140051e-01  5.07717431e-02]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb46203d250>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[ 2.71702170e-01 -1.43941343e-01  2.84348786e-01 -2.71141171e-01\n",
      "   1.41202301e-01 -1.13544688e-01  1....0987906e-01 -2.39715248e-01 -2.70470411e-01\n",
      "   1.59967333e-01  1.61181390e-01  2.33140051e-01  5.07717431e-02]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb46203d250>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46203de20>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb46203de20>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb46203d2e0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb46203d2e0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-12-11-15-1-13] __________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[-0.08210858, -0.20034865,  1.148778  , -0.51443547,\n",
      "          1.034017  ,  0.89685214, -0.2308917 , -0.429583...142177 ,  0.2947652 ,  0.22240864,\n",
      "          0.17885289, -0.8822839 , -0.62754816,  0.9533646 ]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 0.0913,  0.3191,  0.4228, -0.1257, -0.0463,  0.0248,  0.3953,\n",
      "          -0.0508, -0.1005,  0.2268,  0.3066,..., -0.1632,  0.1083, -0.1905,\n",
      "           0.2707,  0.2955, -0.0713, -0.5232,  0.4826]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[-0.33888313, -1.7918321 ,  0.567647  , -1.1852866 ,\n",
      "          0.8130719 , -0.1996919 , -0.84480745,  0.457774...6388023, -1.8492224 ,  0.10731651,\n",
      "          1.3720214 ,  0.10957348, -0.09200212, -1.2703792 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 0.0497,  0.1434,  0.1951, -0.0578, -0.0268,  0.0130,  0.1813,\n",
      "          -0.0243, -0.0581,  0.1134,  0.1646,..., -0.0667,  0.0594, -0.1019,\n",
      "           0.1183,  0.1346, -0.0340, -0.2330,  0.1300]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 0\n",
      "model      = <needle.nn.LSTM object at 0x7fb458a7cc40>\n",
      "model_     = LSTM(11, 12, bias=False)\n",
      "num_layers = 1\n",
      "output_    = tensor([[[ 0.0975, -0.1480, -0.0386,  ..., -0.0092, -0.0497,  0.1604],\n",
      "         [ 0.1125,  0.1009,  0.1484,  ...,  0.0...22,  0.0161],\n",
      "         [-0.0593, -0.0502,  0.0213,  ..., -0.0340, -0.2330,  0.1300]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-0.35655326, -0.16931494, -0.88415784, ..., -0.1706549 ,\n",
      "          1.0146486 ,  0.9738522 ],\n",
      "        [-0.0921...\n",
      "        [-1.9908594 , -0.52109665, -0.32723448, ...,  0.60289127,\n",
      "          0.06870972,  1.5205847 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-0.35655326 -0.16931494 -0.88415784 ... -0.1706549   1.0146486\n",
      "    0.9738522 ]\n",
      "  [-0.09213613  0.672...0.67297524\n",
      "   -0.16399531]\n",
      "  [-1.9908594  -0.52109665 -0.32723448 ...  0.60289127  0.06870972\n",
      "    1.5205847 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458a7cc40>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 1\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-0.35655326 -0.16931494 -0.88415784 ... -0.1706549   1.0146486\n",
      "    0.9738522 ]\n",
      "  [-0.09213613  0.6724...92977  0.67297524\n",
      "   -0.16399531]\n",
      "  [-1.9908594  -0.52109665 -0.32723448 ...  0.60289127  0.06870972\n",
      "    1.5205847 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None]\n",
      "        h          = [None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb458a7cc40>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.35655326 -0.16931494 -0.88415784  0.22004469 -0.18925375  0.13053864\n",
      "   0.980004...109665 -0.32723448 -0.7631713   0.82515526 -0.8040992\n",
      "   1.3587145   0.21335082  0.60289127  0.06870972  1.5205847 ]]))\n",
      "        y          = needle.Tensor([[-0.35655326 -0.16931494 -0.88415784  0.22004469 -0.18925375  0.13053864\n",
      "   0.98000413  0.68707913 -0.1...0008    0.94840056 -0.7065233   0.04422535 -0.12356472\n",
      "  -0.78315586  1.843405    0.765203    0.07265428 -0.2279331 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.35655326 -0.16931494 -0.88415784  0.22004469 -0.18925375  0.13053864\n",
      "   0.98000413  0.68707913 -0....056 -0.7065233   0.04422535 -0.12356472\n",
      "  -0.78315586  1.843405    0.765203    0.07265428 -0.2279331 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4811c0130>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.35655326 -0.16931494 -0.88415784  0.22004469 -0.18925375  0.13053864\n",
      "   0.98000413  0.68707913 -0.1...0008    0.94840056 -0.7065233   0.04422535 -0.12356472\n",
      "  -0.78315586  1.843405    0.765203    0.07265428 -0.2279331 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 3.41086686e-01  2.35016927e-01 -3.61738980e-01 -1.28882453e-01\n",
      "  -5.82325220e-01 -2.27098569e-01  4.3...02 -1.15202293e-02 -9.34522301e-02 -3.13634515e-01\n",
      "  -1.84367999e-01  4.26360130e-01  3.92699510e-01  1.82430908e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb4811c0130>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.2517477  -0.21851832 -0.21228555  0.07908025  0.14308238 -0.09960456\n",
      "   0.1770649  -0.00435057  0.2...526517 -0.05274309  0.12233657  0.03879613\n",
      "   0.24374032  0.05333057 -0.01494351  0.23327345  0.23186111  0.00897568]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.2517477  -0.21851832 -0.21228555  0.07908025  0.14308238 -0.09960456\n",
      "   0.1770649  -0.00435057  0....-0.05274309  0.12233657  0.03879613\n",
      "   0.24374032  0.05333057 -0.01494351  0.23327345  0.23186111  0.00897568]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb4811c0e80>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.2517477  -0.21851832 -0.21228555  0.07908025  0.14308238 -0.09960456\n",
      "   0.1770649  -0.00435057  0....-0.05274309  0.12233657  0.03879613\n",
      "   0.24374032  0.05333057 -0.01494351  0.23327345  0.23186111  0.00897568]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb4811c0e80>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4811c07c0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4811c07c0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4811c0bb0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4811c0bb0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-12-11-15-2-1] ___________________\u001b[0m\n",
      "\n",
      "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 8.45724344e-01,  2.89937735e+00,  3.01147223e+00,\n",
      "          1.43334317e+00,  3.09087157e+00,  9.11329210e-01..., -8.01888108e-01,  5.54874599e-01,\n",
      "         -2.95666933e-01, -1.08223510e+00,  2.05548930e+00]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[ 1.3227e-02,  1.8138e-01, -3.6702e-02,  1.3683e-01,  1.6968e-01,\n",
      "           2.6442e-01,  2.6548e-01, -6.8948...2, -1.5868e-03, -2.5886e-02,  9.7958e-03, -2.7848e-02,\n",
      "           7.0693e-03,  1.9210e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 5.78776002e-01,  5.40893555e-01, -4.72343653e-01,\n",
      "         -1.22492218e+00, -4.67681646e-01, -2.61814308e+00...,  3.90754431e-01, -1.26826212e-01,\n",
      "         -3.56201917e-01,  9.29632485e-01, -1.00309050e+00]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[ 7.1563e-03,  9.5929e-02, -1.1121e-02,  5.4194e-02,  9.5240e-02,\n",
      "           1.4902e-01,  6.7378e-02, -2.1163...3, -8.2818e-04, -1.2769e-02,  4.7820e-03, -1.3588e-02,\n",
      "           3.7396e-03,  9.5985e-03]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb480eb8b80>\n",
      "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 1.5695e-03,  1.3428e-02,  1.6393e-02, -1.5470e-02, -8.6162e-03,\n",
      "          -1.2960e-03, -1.2367e-02,  1.0018...3, -8.2818e-04, -1.2769e-02,  4.7820e-03, -1.3588e-02,\n",
      "           3.7396e-03,  9.5985e-03]]], grad_fn=<StackBackward0>)\n",
      "seq_length = 1\n",
      "x          = array([[[ 1.7053889 , -1.6253638 , -0.10980064,  0.7484398 ,\n",
      "          1.2655613 ,  0.5132827 ,  0.00650213,  1.129245...  -0.32783338, -1.3875796 ,  0.24035741, -0.41576907,\n",
      "          1.1989055 , -0.37441644,  1.3431363 ]]], dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[ 1.7053889  -1.6253638  -0.10980064  0.7484398   1.2655613\n",
      "    0.5132827   0.00650213  1.1292455  -0...84151  -0.6797874  -0.32783338\n",
      "   -1.3875796   0.24035741 -0.41576907  1.1989055  -0.37441644\n",
      "    1.3431363 ]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480eb8b80>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 1\n",
      "        X          = needle.Tensor([[[ 1.7053889  -1.6253638  -0.10980064  0.7484398   1.2655613\n",
      "    0.5132827   0.00650213  1.1292455  -0....  -0.0684151  -0.6797874  -0.32783338\n",
      "   -1.3875796   0.24035741 -0.41576907  1.1989055  -0.37441644\n",
      "    1.3431363 ]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb480eb8b80>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[ 1.7053889  -1.6253638  -0.10980064  0.7484398   1.2655613   0.5132827\n",
      "   0.0065021...3691  -0.0684151  -0.6797874  -0.32783338 -1.3875796\n",
      "   0.24035741 -0.41576907  1.1989055  -0.37441644  1.3431363 ]]),)\n",
      "        y          = needle.Tensor([[ 1.7053889  -1.6253638  -0.10980064  0.7484398   1.2655613   0.5132827\n",
      "   0.00650213  1.1292455  -0.32...213691  -0.0684151  -0.6797874  -0.32783338 -1.3875796\n",
      "   0.24035741 -0.41576907  1.1989055  -0.37441644  1.3431363 ]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[ 1.7053889  -1.6253638  -0.10980064  0.7484398   1.2655613   0.5132827\n",
      "   0.00650213  1.1292455  -0.3...151  -0.6797874  -0.32783338 -1.3875796\n",
      "   0.24035741 -0.41576907  1.1989055  -0.37441644  1.3431363 ]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480eb8280>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[ 1.7053889  -1.6253638  -0.10980064  0.7484398   1.2655613   0.5132827\n",
      "   0.00650213  1.1292455  -0.32...213691  -0.0684151  -0.6797874  -0.32783338 -1.3875796\n",
      "   0.24035741 -0.41576907  1.1989055  -0.37441644  1.3431363 ]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 6.83739960e-01 -5.07392108e-01  1.54451832e-01 -8.16393256e-01\n",
      "   2.94172674e-01  4.32717830e-01 -1.2...01  9.54938114e-01  1.00016809e+00  4.30913150e-01\n",
      "  -6.62930489e-01 -6.98260516e-02 -7.19015822e-02 -8.88305247e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb480eb8280>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-2.86164492e-01 -1.28719509e-01 -1.78454518e-02 -8.26190114e-02\n",
      "   1.24615490e-01 -2.04570562e-01  5.5...01  1.69395447e-01 -1.72286272e-01  2.88585722e-02\n",
      "   1.25027567e-01  9.82012749e-02  2.16734409e-01 -2.63009518e-01]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-2.86164492e-01 -1.28719509e-01 -1.78454518e-02 -8.26190114e-02\n",
      "   1.24615490e-01 -2.04570562e-01  5....9395447e-01 -1.72286272e-01  2.88585722e-02\n",
      "   1.25027567e-01  9.82012749e-02  2.16734409e-01 -2.63009518e-01]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb481210520>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-2.86164492e-01 -1.28719509e-01 -1.78454518e-02 -8.26190114e-02\n",
      "   1.24615490e-01 -2.04570562e-01  5....9395447e-01 -1.72286272e-01  2.88585722e-02\n",
      "   1.25027567e-01  9.82012749e-02  2.16734409e-01 -2.63009518e-01]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb481210520>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb481210100>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb481210100>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb4812105e0>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb4812105e0>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "\u001b[31m\u001b[1m__________________ test_lstm[metal-False-False-12-11-15-2-13] __________________\u001b[0m\n",
      "\n",
      "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11\n",
      "hidden_size = 12, bias = False, init_hidden = False, device = metal()\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmetal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_lstm\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, device):\n",
      "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\n",
      "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "        c0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\n",
      "    \n",
      "        model_ = torch.nn.LSTM(input_size, hidden_size, bias=bias, num_layers=num_layers)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), (torch.tensor(h0), torch.tensor(c0)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      "            output_, (h_, c_) = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\n",
      "    \n",
      "        model = nn.LSTM(input_size, hidden_size, num_layers, bias, device=device)\n",
      "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\n",
      "            model.lstm_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            model.lstm_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\n",
      "            \u001b[94mif\u001b[39;49;00m bias:\n",
      "                model.lstm_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "                model.lstm_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\n",
      "        \u001b[94mif\u001b[39;49;00m init_hidden:\n",
      "            output, (h, c) = model(ndl.Tensor(x, device=device), (ndl.Tensor(h0, device=device), ndl.Tensor(c0, device=device)))\n",
      "        \u001b[94melse\u001b[39;49;00m:\n",
      ">           output, (h, c) = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\n",
      "\n",
      "batch_size = 15\n",
      "bias       = False\n",
      "c0         = array([[[ 3.18823680e-02,  8.23590875e-01,  1.86897099e-01,\n",
      "          2.91174836e-03,  8.43570113e-01, -1.08759254e-01...,  5.43112695e-01, -6.84963524e-01,\n",
      "         -1.62655875e-01, -7.43799031e-01, -2.20088673e+00]]],\n",
      "      dtype=float32)\n",
      "c_         = tensor([[[-1.5304e-01,  8.3741e-02,  2.7981e-02,  1.6300e-01, -1.0258e-01,\n",
      "           8.7627e-02,  2.6333e-01, -1.5631...2, -1.1798e-02,  1.7589e-02, -8.6686e-03,  1.0218e-02,\n",
      "          -1.0696e-01, -3.1583e-02]]], grad_fn=<StackBackward0>)\n",
      "device     = metal()\n",
      "h0         = array([[[ 0.63890517, -0.20576413,  0.37615696, -0.68587464,\n",
      "          1.2269871 ,  0.4785303 , -0.52651167,  0.124449...529791 ,  0.9818188 ,  0.298228  ,\n",
      "         -0.08653174,  0.34078494,  2.1962028 , -1.2148741 ]]],\n",
      "      dtype=float32)\n",
      "h_         = tensor([[[-6.3861e-02,  5.1631e-02,  1.1148e-02,  6.1959e-02, -4.4486e-02,\n",
      "           4.7423e-02,  1.1019e-01, -6.2556...3, -6.0054e-03,  8.9801e-03, -4.3879e-03,  5.2949e-03,\n",
      "          -5.5024e-02, -1.6001e-02]]], grad_fn=<StackBackward0>)\n",
      "hidden_size = 12\n",
      "init_hidden = False\n",
      "input_size = 11\n",
      "k          = 1\n",
      "model      = <needle.nn.LSTM object at 0x7fb450ec30d0>\n",
      "model_     = LSTM(11, 12, num_layers=2, bias=False)\n",
      "num_layers = 2\n",
      "output_    = tensor([[[ 0.0040,  0.0020,  0.0015,  ..., -0.0148, -0.0125, -0.0199],\n",
      "         [-0.0072, -0.0115, -0.0066,  ...,  0.0...80, -0.0400],\n",
      "         [ 0.0562,  0.0433, -0.0049,  ...,  0.0053, -0.0550, -0.0160]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "seq_length = 13\n",
      "x          = array([[[-2.84458458e-01, -3.45870465e-01, -1.15160632e+00, ...,\n",
      "          1.30495465e+00,  4.41180646e-01, -1.0017476...44811261e-01,  1.56513000e+00, ...,\n",
      "          5.69515228e-01,  2.62982100e-01, -5.20514846e-01]]],\n",
      "      dtype=float32)\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_sequence_models.py\u001b[0m:175: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[[-2.84458458e-01 -3.45870465e-01 -1.15160632e+00 ...  1.30495465e+00\n",
      "    4.41180646e-01 -1.00174761e+...1]\n",
      "  [ 1.77219808e+00 -3.44811261e-01  1.56513000e+00 ...  5.69515228e-01\n",
      "    2.62982100e-01 -5.20514846e-01]]]), None)\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450ec30d0>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:562: in forward\n",
      "    hh, cc = \u001b[96mself\u001b[39;49;00m.lstm_cells[l](y, (h[l], c[l]))\n",
      "        H          = 12\n",
      "        I          = 11\n",
      "        L          = 2\n",
      "        T          = 13\n",
      "        X          = needle.Tensor([[[-2.84458458e-01 -3.45870465e-01 -1.15160632e+00 ...  1.30495465e+00\n",
      "    4.41180646e-01 -1.00174761e+0...4833e-01]\n",
      "  [ 1.77219808e+00 -3.44811261e-01  1.56513000e+00 ...  5.69515228e-01\n",
      "    2.62982100e-01 -5.20514846e-01]]])\n",
      "        Y          = []\n",
      "        bs         = 15\n",
      "        c          = [None, None]\n",
      "        h          = [None, None]\n",
      "        l          = 0\n",
      "        self       = <needle.nn.LSTM object at 0x7fb450ec30d0>\n",
      "        t          = 0\n",
      "        x          = needle.TensorTuple(needle.Tensor([[-0.28445846 -0.34587047 -1.1516063  -1.6057881   1.571102   -0.5381208\n",
      "   1.4045857...481126  1.56513     0.6286557   0.03416743  0.8245694\n",
      "  -0.4300321   0.9946502   0.5695152   0.2629821  -0.52051485]]))\n",
      "        y          = needle.Tensor([[-0.28445846 -0.34587047 -1.1516063  -1.6057881   1.571102   -0.5381208\n",
      "   1.4045857  -0.06354193  1.30...772133   1.5118856   0.8023093   0.94255644 -2.5369945\n",
      "  -1.1430758   0.75862896 -0.6776403   0.0747698  -0.18306647]])\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:74: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.forward(*args, **kwargs)\n",
      "        args       = (needle.Tensor([[-0.28445846 -0.34587047 -1.1516063  -1.6057881   1.571102   -0.5381208\n",
      "   1.4045857  -0.06354193  1.3...856   0.8023093   0.94255644 -2.5369945\n",
      "  -1.1430758   0.75862896 -0.6776403   0.0747698  -0.18306647]]), (None, None))\n",
      "        kwargs     = {}\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450ec3760>\n",
      "\u001b[1m\u001b[31mpython/needle/nn.py\u001b[0m:478: in forward\n",
      "    out += h0 @ \u001b[96mself\u001b[39;49;00m.W_hh\n",
      "        H          = 12\n",
      "        X          = needle.Tensor([[-0.28445846 -0.34587047 -1.1516063  -1.6057881   1.571102   -0.5381208\n",
      "   1.4045857  -0.06354193  1.30...772133   1.5118856   0.8023093   0.94255644 -2.5369945\n",
      "  -1.1430758   0.75862896 -0.6776403   0.0747698  -0.18306647]])\n",
      "        c          = None\n",
      "        h          = (None, None)\n",
      "        h0         = None\n",
      "        out        = needle.Tensor([[ 2.44281352e-01 -2.28299230e-01 -6.90429866e-01  7.43477404e-01\n",
      "   2.84632981e-01  7.35548511e-02  8.5...01  7.76517749e-01  1.31628945e-01  7.89380729e-01\n",
      "  -1.65621907e-01  3.32482338e-01  4.17072438e-02 -3.46104324e-01]])\n",
      "        self       = <needle.nn.LSTMCell object at 0x7fb450ec3760>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:334: in __matmul__\n",
      "    \u001b[94mreturn\u001b[39;49;00m needle.ops.MatMul()(\u001b[96mself\u001b[39;49;00m, other)\n",
      "        other      = None\n",
      "        self       = needle.Tensor([[-0.21862318 -0.26458776 -0.19975176 -0.2823459  -0.02070072 -0.00149646\n",
      "  -0.22721027  0.2853436   0.1...193079 -0.11103827 -0.15287457  0.21687913\n",
      "  -0.20727423  0.19996482  0.26448756  0.26500595  0.05805957 -0.14663771]])\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:73: in __call__\n",
      "    \u001b[94mreturn\u001b[39;49;00m Tensor.make_from_op(\u001b[96mself\u001b[39;49;00m, args)\n",
      "        args       = (needle.Tensor([[-0.21862318 -0.26458776 -0.19975176 -0.2823459  -0.02070072 -0.00149646\n",
      "  -0.22721027  0.2853436   0....-0.11103827 -0.15287457  0.21687913\n",
      "  -0.20727423  0.19996482  0.26448756  0.26500595  0.05805957 -0.14663771]]), None)\n",
      "        self       = <needle.ops.MatMul object at 0x7fb430234220>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:242: in make_from_op\n",
      "    tensor.realize_cached_data()\n",
      "        inputs     = (needle.Tensor([[-0.21862318 -0.26458776 -0.19975176 -0.2823459  -0.02070072 -0.00149646\n",
      "  -0.22721027  0.2853436   0....-0.11103827 -0.15287457  0.21687913\n",
      "  -0.20727423  0.19996482  0.26448756  0.26500595  0.05805957 -0.14663771]]), None)\n",
      "        op         = <needle.ops.MatMul object at 0x7fb430234220>\n",
      "        tensor     = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4302349a0>\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: in realize_cached_data\n",
      "    *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "        self       = <[AttributeError(\"'NoneType' object has no attribute 'realize_cached_data'\") raised in repr()] Tensor object at 0x7fb4302349a0>\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      ".0 = <tuple_iterator object at 0x7fb430234250>\n",
      "\n",
      ">       *[x.realize_cached_data() \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.inputs]\n",
      "    )\n",
      "\u001b[1m\u001b[31mE   AttributeError: 'NoneType' object has no attribute 'realize_cached_data'\u001b[0m\n",
      "\n",
      ".0         = <tuple_iterator object at 0x7fb430234250>\n",
      "x          = None\n",
      "\n",
      "\u001b[1m\u001b[31mpython/needle/autograd.py\u001b[0m:101: AttributeError\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-1-1] - A...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-1-13] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-2-1] - A...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-1-2-13] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-1-1] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-2-1] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-1-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-1-1] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-2-1] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-1-11-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-1-1] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-2-1] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-1-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-True-12-11-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-1-1] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-2-1] - ...\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-1-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-1-11-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-1-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[cpu-False-False-12-11-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-1-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-1-11-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-1-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-True-12-11-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-1-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-1-11-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-1-15-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-1-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-1-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-1-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-1-2-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-15-1-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-15-1-13]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-15-2-1]\n",
      "FAILED tests/test_sequence_models.py::test_lstm[metal-False-False-12-11-15-2-13]\n",
      "\u001b[31m== \u001b[31m\u001b[1m128 failed\u001b[0m, \u001b[32m128 passed\u001b[0m, \u001b[33m128 skipped\u001b[0m, \u001b[33m2318 deselected\u001b[0m\u001b[31m in 682.08s (0:11:22)\u001b[0m\u001b[31m ===\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"test_lstm and not lstm_cell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 10 items / 9 deselected / 1 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_sequence_models.py \n",
      "Submitting lstm...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "Grader test 15 passed\n",
      "Grader test 16 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m9 deselected\u001b[0m\u001b[32m in 19.70s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"_rDmFVIBecE4PjPfd2IVS\" -k \"lstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Penn Treebank dataset [10 points]\n",
    "\n",
    "In word-level language modeling tasks, the model predicts the probability of the next word in the sequence, based on the words already observed in the sequence. You will write support for the Penn Treebank dataset, which consists of stories from the Wall Street Journal, to train and evaluate a language model on word-level prediction.\n",
    "\n",
    "In `python/needle/data.py`, start by implementing the `Dictionary` class, which creates a dictionary from a list of words, mapping each word to a unique integer.\n",
    "\n",
    "Next, we will use this `Dictionary` class to create a corpus from the train and test txt files in the Penn Treebank dataset that you downloaded at the beginning of the notebook. Implement the `tokenize` function in the `Corpus` class to do this.\n",
    "\n",
    "In order to prepare the data for training and evaluation, you will next implement the `batchify` function. Starting from sequential data, batchify arranges the dataset into columns. For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "\n",
    "```\n",
    "┌ a g m s ┐\n",
    "│ b h n t │\n",
    "│ c i o u │\n",
    "│ d j p v │\n",
    "│ e k q w │\n",
    "└ f l r x ┘\n",
    "```\n",
    "\n",
    "These columns are treated as independent by the model, which means that the dependence of e. g. 'g' on 'f' cannot be learned, but allows more efficient batch processing.\n",
    "\n",
    "Next, implement the `get_batch` function. `get_batch` subdivides the source data into chunks of length `bptt`. If source is equal to the example output of the batchify function, with a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
    "```\n",
    "┌ a g m s ┐ ┌ b h n t ┐\n",
    "└ b h n t ┘ └ c i o u ┘\n",
    "```\n",
    "Note that despite the name of the function, the subdivison of data is not done along the batch dimension (i.e. dimension 1), since that was handled by the batchify function. The chunks are along dimension 0, corresponding to the seq_len dimension in the LSTM or RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 5],\n",
       "       [2, 6],\n",
       "       [3, 7],\n",
       "       [4, 8]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "a = a.reshape(2, 4)\n",
    "a = a.transpose((1, 0))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- /Users/amo/opt/anaconda3/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 2702 items / 2664 deselected / 38 selected                           \u001b[0m\u001b[1m\u001b[1m\n",
      "\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_dataset[True] \u001b[32mPASSED\u001b[0m\u001b[32m          [  2%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_dataset[False] \u001b[32mPASSED\u001b[0m\u001b[32m         [  5%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m     [  7%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cpu-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 10%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 13%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cpu-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 15%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 18%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cuda-True-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 21%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 23%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[cuda-False-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 26%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[metal-True-1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 28%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[metal-True-15] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 31%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[metal-False-1] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 34%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_cifar10_loader[metal-False-15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 39%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 42%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 44%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cpu-True-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 47%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 50%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 52%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 55%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cpu-False-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 57%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m    [ 60%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-3-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 63%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-32-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 65%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cuda-True-32-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 68%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-3-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m   [ 71%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-3-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 73%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-32-1] \u001b[33mSKIPPED\u001b[0m\u001b[32m  [ 76%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[cuda-False-32-15] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 78%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[metal-True-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 81%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[metal-True-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 84%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[metal-True-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 86%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[metal-True-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 89%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[metal-False-3-1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 92%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[metal-False-3-15] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 94%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[metal-False-32-1] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 97%]\u001b[0m\n",
      "tests/test_cifar_ptb_data.py::test_ptb_dataset[metal-False-32-15] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m=============== \u001b[32m\u001b[1m26 passed\u001b[0m, \u001b[33m12 skipped\u001b[0m, \u001b[33m2664 deselected\u001b[0m\u001b[32m in 10.53s\u001b[0m\u001b[32m ===============\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pytest -l -v -k \"ptb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0\n",
      "rootdir: /Users/amo/Desktop/learn/10-714-dlsys-2022/hw4\n",
      "plugins: anyio-3.5.0\n",
      "collected 10 items / 8 deselected / 2 selected                                 \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_cifar_ptb_data.py \n",
      "Submitting cifar10...\n",
      "train:  True\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "submit ok\n",
      "train:  False\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "Grader test 15 passed\n",
      "Grader test 16 passed\n",
      "Grader test 17 passed\n",
      "Grader test 18 passed\n",
      "submit ok\n",
      "\u001b[32m.\u001b[0m\n",
      "Submitting ptb...\n",
      "Grader test 1 passed\n",
      "Grader test 2 passed\n",
      "Grader test 3 passed\n",
      "Grader test 4 passed\n",
      "Grader test 5 passed\n",
      "Grader test 6 passed\n",
      "Grader test 7 passed\n",
      "Grader test 8 passed\n",
      "Grader test 9 passed\n",
      "Grader test 10 passed\n",
      "Grader test 11 passed\n",
      "Grader test 12 passed\n",
      "Grader test 13 passed\n",
      "Grader test 14 passed\n",
      "Grader test 15 passed\n",
      "Grader test 16 passed\n",
      "Grader test 17 passed\n",
      "Grader test 18 passed\n",
      "Grader test 19 passed\n",
      "Grader test 20 passed\n",
      "Grader test 21 passed\n",
      "Grader test 22 passed\n",
      "Grader test 23 passed\n",
      "Grader test 24 passed\n",
      "Grader test 25 passed\n",
      "Grader test 26 passed\n",
      "Grader test 27 passed\n",
      "Grader test 28 passed\n",
      "Grader test 29 passed\n",
      "Grader test 30 passed\n",
      "Grader test 31 passed\n",
      "Grader test 32 passed\n",
      "Grader test 33 passed\n",
      "Grader test 34 passed\n",
      "Grader test 35 passed\n",
      "Grader test 36 passed\n",
      "Grader test 37 passed\n",
      "Grader test 38 passed\n",
      "Grader test 39 passed\n",
      "Grader test 40 passed\n",
      "Grader test 41 passed\n",
      "Grader test 42 passed\n",
      "Grader test 43 passed\n",
      "Grader test 44 passed\n",
      "Grader test 45 passed\n",
      "Grader test 46 passed\n",
      "Grader test 47 passed\n",
      "Grader test 48 passed\n",
      "Grader test 49 passed\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m======================= \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m8 deselected\u001b[0m\u001b[32m in 37.62s\u001b[0m\u001b[32m =======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mugrade submit \"_rDmFVIBecE4PjPfd2IVS\" -k \"ptb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Training a word-level language model [10 points]\n",
    "\n",
    "Finally, you will use the `RNN` and `LSTM` components you have written to construct a language model that we will train on the Penn Treebank dataset.\n",
    "\n",
    "First, in `python/needle/nn.py` implement `Embedding`. Consider we have a dictionary with 1000 words. Then for a word which indexes into this dictionary, we can represent this word as a one-hot vector of size 1000, and then use a linear layer to project this to a vector of some embedding size.\n",
    "\n",
    "In `apps/models.py`, you can now implement `LanguageModel`. Your language model should consist of \n",
    "\n",
    "- An embedding layer (which maps word IDs to embeddings) \n",
    "- A sequence model (either RNN or LSTM)\n",
    "- A linear layer (which outputs probabilities of the next word)\n",
    "\n",
    "In `apps/simple_training.py` implement `epoch_general_ptb`, `train_ptb`, and `evaluate_ptb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"language_model_implementation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pytest -l -v -k \"language_model_training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"language_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your language model on the Penn Treebank dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import needle as ndl\n",
    "sys.path.append('./apps')\n",
    "from models import LanguageModel\n",
    "from simple_training import train_ptb, evaluate_ptb\n",
    "\n",
    "device = ndl.cpu()\n",
    "corpus = ndl.data.Corpus(\"data/ptb\")\n",
    "train_data = ndl.data.batchify(corpus.train, batch_size=16, device=ndl.cpu(), dtype=\"float32\")\n",
    "model = LanguageModel(30, len(corpus.dictionary), hidden_size=10, num_layers=2, seq_model='rnn', device=ndl.cpu())\n",
    "train_ptb(model, train_data, seq_len=1, n_epochs=1, device=device)\n",
    "evaluate_ptb(model, train_data, seq_len=40, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "15f424d5a25c0b28279cc5dde3c0ce2d37243042d5159ad0f026e088fc4d1ab7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
